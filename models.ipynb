{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893753fe-9a77-499a-b39d-e15831fe0bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dgl.data import DGLDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "\n",
    "\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "from utils import load_data, r2_fun\n",
    "from models import EGAT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020f7202-9a69-45dd-87d5-10771ee76375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([23140, 15])\n",
      "torch.Size([23140, 17])\n",
      "Graph(num_nodes=23140, num_edges=139802,\n",
      "      ndata_schemes={'feat': Scheme(shape=(17,), dtype=torch.float32), 'label': Scheme(shape=(1,), dtype=torch.float32)}\n",
      "      edata_schemes={'weight': Scheme(shape=(4,), dtype=torch.float32)})\n"
     ]
    }
   ],
   "source": [
    "class load_data(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='karate_clube')\n",
    "\n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv('./up/node_data.csv')\n",
    "        edges_data = pd.read_csv('./up/edge_features2.csv')\n",
    "        node_fe_contin = ['std_dem','avg_slope', 'std_slope', 'medi_aspec', 'avg_plan_c', \n",
    "                        'std_plan_c', 'avg_prof_c','std_prof_c', 'avg_maxpre', 'avg_mean a', 'dis2river', \n",
    "                        'max GWS','min GWS', 'differ GWS',  'dis2faults']            #18 ndvi\n",
    "        node_fe_categ = ['land cover','lithology']   #2\n",
    "        edge_fe_name = ['area_ratio','centre distance', 'aspect angle differ', 'elevation differ']\n",
    "        \n",
    "        node_features_contin = nodes_data[node_fe_contin].to_numpy()\n",
    "        node_features_categ = torch.from_numpy(nodes_data[node_fe_categ].astype('category').to_numpy())\n",
    "        \n",
    "        node_labels = nodes_data['max_vel1'].to_numpy()\n",
    "        edge_features = edges_data[edge_fe_name].to_numpy()\n",
    "        edges_src = torch.from_numpy(edges_data['src'].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data['des'].to_numpy()) \n",
    "        \n",
    "        node_labels = np.reshape(node_labels,(-1,1))\n",
    "        ss_node = StandardScaler()\n",
    "        ss_edge = StandardScaler()\n",
    "        ss_y = StandardScaler()\n",
    "\n",
    "        node_features_nor = ss_node.fit_transform(node_features_contin)\n",
    "        edge_features_nor = ss_edge.fit_transform(edge_features)\n",
    "        node_labels_nor = ss_y.fit_transform(node_labels)\n",
    "        print(type(node_features_nor))\n",
    "        self.ss_y = ss_y\n",
    "        self.y_ture = node_labels\n",
    "\n",
    "        \n",
    "        node_features_nor  = torch.from_numpy(node_features_nor.astype('float32'))\n",
    "        node_labels_nor  = torch.from_numpy(node_labels_nor.astype('float32'))\n",
    "        edge_features_nor  = torch.from_numpy(edge_features_nor.astype('float32'))\n",
    "\n",
    "        #cat continues and category features\n",
    "        print(node_features_nor.shape)\n",
    "        cont_cat_fe = torch.cat((node_features_nor,node_features_categ/10),dim = 1)\n",
    "        print(cont_cat_fe.shape)\n",
    "        \n",
    "\n",
    "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])\n",
    "        self.graph.ndata['feat'] = cont_cat_fe\n",
    "        #self.graph.ndata['feat2'] = node_features_categ\n",
    "        self.graph.ndata['label'] = node_labels_nor\n",
    "        self.graph.edata['weight'] = edge_features_nor\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "dataset = load_data()\n",
    "graph = dataset[0]\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fd1c29-ab60-4781-a39b-7038db2b782a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23140, 17])\n",
      "torch.Size([139802, 4])\n",
      "torch.Size([23140, 1])\n",
      "22926\n",
      "[15190 19205 19790 14477  1196   117   913 14799 16235 14408]\n"
     ]
    }
   ],
   "source": [
    "node_features = torch.FloatTensor(np.array(graph.ndata['feat'].detach()))\n",
    "edge_features = torch.FloatTensor(np.array(graph.edata['weight']))\n",
    "labels = torch.FloatTensor(np.array(graph.ndata['label']))\n",
    "\n",
    "print(node_features.shape)\n",
    "print(edge_features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "#import random\n",
    "np.random.seed(113)\n",
    "idx = np.arange(len(labels))   #which is equal to su_id\n",
    "no_points_su_id = pd.read_csv('./up/no_label_id_ERA5.csv')\n",
    "no_points_su_id = list(no_points_su_id['su_id'])\n",
    "idx = np.delete(idx, np.where(np.isin(idx, no_points_su_id)))\n",
    "print(len(idx))\n",
    "\n",
    "\n",
    "part1_size = int(0.4 * len(idx))\n",
    "part2_size = int(0.1 * len(idx))\n",
    "part3_size = int(0.5 * len(idx))\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "idx_train = idx[:part1_size]\n",
    "idx_val = idx[part1_size:part1_size+part2_size]\n",
    "idx_test = idx[part1_size+part2_size:part1_size+part2_size+part3_size]\n",
    "\n",
    "print(idx_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54e5047f-c95f-4899-87a3-5b5d6f744503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressionNN(\n",
      "  (fc1): Linear(in_features=17, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc0): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义神经网络模型\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(RegressionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)  # 输入层到第一个隐藏层\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)  # 第一个隐藏层到第二个隐藏层\n",
    "        self.fc0 = nn.Linear(hidden_dim2, output_dim)  # 第二个隐藏层到输出层\n",
    "        self.relu = nn.ReLU()  # 激活函数\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        #self.embedding_1 = nn.Embedding(10,2)  #9 equal to calsses of land cover\n",
    "        #self.embedding_2 = nn.Embedding(13,2)  #7 equal to calsses of lithology\n",
    "        \n",
    "    def forward(self, x1):\n",
    "        #embedded_1 = self.embedding_1(x1[:,-2].long())\n",
    "        #embedded_2 = self.embedding_2(x1[:,-1].long())\n",
    "\n",
    "        #combined = torch.cat((x1[:,:-2], embedded_1.view(embedded_1.size(0), -1), embedded_2.view(embedded_2.size(0), -1)), dim=1)\n",
    "        \n",
    "        x = self.relu(self.fc1(x1))  # first layer\n",
    "        x= self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))  # second layer\n",
    "        x= self.dropout2(x)\n",
    "\n",
    "        x = self.fc0(x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "input_dim = 17  \n",
    "hidden_dim1 = 128  \n",
    "hidden_dim2 = 128 \n",
    "output_dim = 1  \n",
    "model = RegressionNN(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005,weight_decay = 5e-5)  # Adam\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a855d-9d0d-4950-974a-3688e3183e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e085c36-e36a-4caf-a641-dc412fe5bfb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Epoch [1/400], train_Loss: 1.0197,val_Loss:0.9861\n",
      "-Epoch [2/400], train_Loss: 0.9043,val_Loss:0.8723\n",
      "-Epoch [3/400], train_Loss: 0.8402,val_Loss:0.8201\n",
      "-Epoch [4/400], train_Loss: 0.8170,val_Loss:0.7840\n",
      "-Epoch [5/400], train_Loss: 0.7906,val_Loss:0.7477\n",
      "-Epoch [6/400], train_Loss: 0.7763,val_Loss:0.7247\n",
      "-Epoch [7/400], train_Loss: 0.7559,val_Loss:0.7056\n",
      "-Epoch [8/400], train_Loss: 0.7475,val_Loss:0.7107\n",
      "-Epoch [9/400], train_Loss: 0.7425,val_Loss:0.6815\n",
      "-Epoch [10/400], train_Loss: 0.7304,val_Loss:0.6730\n",
      "-Epoch [11/400], train_Loss: 0.7154,val_Loss:0.6703\n",
      "-Epoch [12/400], train_Loss: 0.7093,val_Loss:0.6784\n",
      "-Epoch [13/400], train_Loss: 0.7037,val_Loss:0.6583\n",
      "-Epoch [14/400], train_Loss: 0.6991,val_Loss:0.6500\n",
      "-Epoch [15/400], train_Loss: 0.6937,val_Loss:0.6497\n",
      "-Epoch [16/400], train_Loss: 0.6955,val_Loss:0.6376\n",
      "-Epoch [17/400], train_Loss: 0.6848,val_Loss:0.6358\n",
      "-Epoch [18/400], train_Loss: 0.6845,val_Loss:0.6368\n",
      "-Epoch [19/400], train_Loss: 0.6794,val_Loss:0.6450\n",
      "-Epoch [20/400], train_Loss: 0.6819,val_Loss:0.6179\n",
      "-Epoch [21/400], train_Loss: 0.6695,val_Loss:0.6221\n",
      "-Epoch [22/400], train_Loss: 0.6686,val_Loss:0.6315\n",
      "-Epoch [23/400], train_Loss: 0.6607,val_Loss:0.6033\n",
      "-Epoch [24/400], train_Loss: 0.6593,val_Loss:0.6161\n",
      "-Epoch [25/400], train_Loss: 0.6546,val_Loss:0.6277\n",
      "-Epoch [26/400], train_Loss: 0.6567,val_Loss:0.6123\n",
      "-Epoch [27/400], train_Loss: 0.6573,val_Loss:0.6088\n",
      "-Epoch [28/400], train_Loss: 0.6571,val_Loss:0.6049\n",
      "-Epoch [29/400], train_Loss: 0.6498,val_Loss:0.6159\n",
      "-Epoch [30/400], train_Loss: 0.6410,val_Loss:0.6028\n",
      "-Epoch [31/400], train_Loss: 0.6398,val_Loss:0.5860\n",
      "-Epoch [32/400], train_Loss: 0.6407,val_Loss:0.6033\n",
      "-Epoch [33/400], train_Loss: 0.6378,val_Loss:0.5799\n",
      "-Epoch [34/400], train_Loss: 0.6424,val_Loss:0.5987\n",
      "-Epoch [35/400], train_Loss: 0.6352,val_Loss:0.6031\n",
      "-Epoch [36/400], train_Loss: 0.6282,val_Loss:0.5814\n",
      "-Epoch [37/400], train_Loss: 0.6316,val_Loss:0.5868\n",
      "-Epoch [38/400], train_Loss: 0.6220,val_Loss:0.5751\n",
      "-Epoch [39/400], train_Loss: 0.6247,val_Loss:0.5916\n",
      "-Epoch [40/400], train_Loss: 0.6228,val_Loss:0.5727\n",
      "-Epoch [41/400], train_Loss: 0.6160,val_Loss:0.5749\n",
      "-Epoch [42/400], train_Loss: 0.6179,val_Loss:0.5771\n",
      "-Epoch [43/400], train_Loss: 0.6155,val_Loss:0.5797\n",
      "-Epoch [44/400], train_Loss: 0.6122,val_Loss:0.5776\n",
      "-Epoch [45/400], train_Loss: 0.6152,val_Loss:0.5705\n",
      "-Epoch [46/400], train_Loss: 0.6125,val_Loss:0.5601\n",
      "-Epoch [47/400], train_Loss: 0.6072,val_Loss:0.5722\n",
      "-Epoch [48/400], train_Loss: 0.6137,val_Loss:0.5759\n",
      "-Epoch [49/400], train_Loss: 0.6023,val_Loss:0.5649\n",
      "-Epoch [50/400], train_Loss: 0.6030,val_Loss:0.5625\n",
      "-Epoch [51/400], train_Loss: 0.6043,val_Loss:0.5554\n",
      "-Epoch [52/400], train_Loss: 0.5979,val_Loss:0.5524\n",
      "-Epoch [53/400], train_Loss: 0.5978,val_Loss:0.5617\n",
      "-Epoch [54/400], train_Loss: 0.6013,val_Loss:0.5515\n",
      "-Epoch [55/400], train_Loss: 0.5881,val_Loss:0.5628\n",
      "-Epoch [56/400], train_Loss: 0.5953,val_Loss:0.5551\n",
      "-Epoch [57/400], train_Loss: 0.5928,val_Loss:0.5570\n",
      "-Epoch [58/400], train_Loss: 0.5953,val_Loss:0.5449\n",
      "-Epoch [59/400], train_Loss: 0.5936,val_Loss:0.5469\n",
      "-Epoch [60/400], train_Loss: 0.5909,val_Loss:0.5441\n",
      "-Epoch [61/400], train_Loss: 0.5891,val_Loss:0.5541\n",
      "-Epoch [62/400], train_Loss: 0.5860,val_Loss:0.5575\n",
      "-Epoch [63/400], train_Loss: 0.5898,val_Loss:0.5400\n",
      "-Epoch [64/400], train_Loss: 0.5867,val_Loss:0.5528\n",
      "-Epoch [65/400], train_Loss: 0.5877,val_Loss:0.5553\n",
      "-Epoch [66/400], train_Loss: 0.5790,val_Loss:0.5458\n",
      "-Epoch [67/400], train_Loss: 0.5819,val_Loss:0.5441\n",
      "-Epoch [68/400], train_Loss: 0.5812,val_Loss:0.5404\n",
      "-Epoch [69/400], train_Loss: 0.5788,val_Loss:0.5448\n",
      "-Epoch [70/400], train_Loss: 0.5751,val_Loss:0.5503\n",
      "-Epoch [71/400], train_Loss: 0.5803,val_Loss:0.5391\n",
      "-Epoch [72/400], train_Loss: 0.5680,val_Loss:0.5383\n",
      "-Epoch [73/400], train_Loss: 0.5718,val_Loss:0.5289\n",
      "-Epoch [74/400], train_Loss: 0.5652,val_Loss:0.5411\n",
      "-Epoch [75/400], train_Loss: 0.5712,val_Loss:0.5495\n",
      "-Epoch [76/400], train_Loss: 0.5733,val_Loss:0.5442\n",
      "-Epoch [77/400], train_Loss: 0.5647,val_Loss:0.5314\n",
      "-Epoch [78/400], train_Loss: 0.5670,val_Loss:0.5298\n",
      "-Epoch [79/400], train_Loss: 0.5721,val_Loss:0.5455\n",
      "-Epoch [80/400], train_Loss: 0.5624,val_Loss:0.5378\n",
      "-Epoch [81/400], train_Loss: 0.5576,val_Loss:0.5427\n",
      "-Epoch [82/400], train_Loss: 0.5629,val_Loss:0.5453\n",
      "-Epoch [83/400], train_Loss: 0.5600,val_Loss:0.5331\n",
      "-Epoch [84/400], train_Loss: 0.5566,val_Loss:0.5363\n",
      "-Epoch [85/400], train_Loss: 0.5543,val_Loss:0.5414\n",
      "-Epoch [86/400], train_Loss: 0.5591,val_Loss:0.5371\n",
      "-Epoch [87/400], train_Loss: 0.5559,val_Loss:0.5442\n",
      "-Epoch [88/400], train_Loss: 0.5511,val_Loss:0.5314\n",
      "-Epoch [89/400], train_Loss: 0.5568,val_Loss:0.5316\n",
      "-Epoch [90/400], train_Loss: 0.5586,val_Loss:0.5270\n",
      "-Epoch [91/400], train_Loss: 0.5562,val_Loss:0.5327\n",
      "-Epoch [92/400], train_Loss: 0.5577,val_Loss:0.5234\n",
      "-Epoch [93/400], train_Loss: 0.5546,val_Loss:0.5239\n",
      "-Epoch [94/400], train_Loss: 0.5539,val_Loss:0.5333\n",
      "-Epoch [95/400], train_Loss: 0.5506,val_Loss:0.5314\n",
      "-Epoch [96/400], train_Loss: 0.5451,val_Loss:0.5360\n",
      "-Epoch [97/400], train_Loss: 0.5529,val_Loss:0.5331\n",
      "-Epoch [98/400], train_Loss: 0.5507,val_Loss:0.5218\n",
      "-Epoch [99/400], train_Loss: 0.5451,val_Loss:0.5150\n",
      "-Epoch [100/400], train_Loss: 0.5461,val_Loss:0.5234\n",
      "-Epoch [101/400], train_Loss: 0.5452,val_Loss:0.5276\n",
      "-Epoch [102/400], train_Loss: 0.5437,val_Loss:0.5179\n",
      "-Epoch [103/400], train_Loss: 0.5351,val_Loss:0.5156\n",
      "-Epoch [104/400], train_Loss: 0.5457,val_Loss:0.5179\n",
      "-Epoch [105/400], train_Loss: 0.5423,val_Loss:0.5372\n",
      "-Epoch [106/400], train_Loss: 0.5405,val_Loss:0.5226\n",
      "-Epoch [107/400], train_Loss: 0.5501,val_Loss:0.5295\n",
      "-Epoch [108/400], train_Loss: 0.5456,val_Loss:0.5129\n",
      "-Epoch [109/400], train_Loss: 0.5429,val_Loss:0.5321\n",
      "-Epoch [110/400], train_Loss: 0.5428,val_Loss:0.5198\n",
      "-Epoch [111/400], train_Loss: 0.5282,val_Loss:0.5157\n",
      "-Epoch [112/400], train_Loss: 0.5379,val_Loss:0.5146\n",
      "-Epoch [113/400], train_Loss: 0.5349,val_Loss:0.5217\n",
      "-Epoch [114/400], train_Loss: 0.5324,val_Loss:0.5219\n",
      "-Epoch [115/400], train_Loss: 0.5315,val_Loss:0.5265\n",
      "-Epoch [116/400], train_Loss: 0.5365,val_Loss:0.5259\n",
      "-Epoch [117/400], train_Loss: 0.5317,val_Loss:0.5257\n",
      "-Epoch [118/400], train_Loss: 0.5340,val_Loss:0.5185\n",
      "-Epoch [119/400], train_Loss: 0.5311,val_Loss:0.5247\n",
      "-Epoch [120/400], train_Loss: 0.5398,val_Loss:0.5197\n",
      "-Epoch [121/400], train_Loss: 0.5275,val_Loss:0.5067\n",
      "-Epoch [122/400], train_Loss: 0.5248,val_Loss:0.5156\n",
      "-Epoch [123/400], train_Loss: 0.5253,val_Loss:0.5333\n",
      "-Epoch [124/400], train_Loss: 0.5331,val_Loss:0.5220\n",
      "-Epoch [125/400], train_Loss: 0.5211,val_Loss:0.5184\n",
      "-Epoch [126/400], train_Loss: 0.5248,val_Loss:0.5107\n",
      "-Epoch [127/400], train_Loss: 0.5266,val_Loss:0.5130\n",
      "-Epoch [128/400], train_Loss: 0.5261,val_Loss:0.5297\n",
      "-Epoch [129/400], train_Loss: 0.5306,val_Loss:0.5228\n",
      "-Epoch [130/400], train_Loss: 0.5216,val_Loss:0.5116\n",
      "-Epoch [131/400], train_Loss: 0.5279,val_Loss:0.5336\n",
      "-Epoch [132/400], train_Loss: 0.5307,val_Loss:0.5213\n",
      "-Epoch [133/400], train_Loss: 0.5275,val_Loss:0.5270\n",
      "-Epoch [134/400], train_Loss: 0.5251,val_Loss:0.5194\n",
      "-Epoch [135/400], train_Loss: 0.5289,val_Loss:0.5106\n",
      "-Epoch [136/400], train_Loss: 0.5153,val_Loss:0.5292\n",
      "-Epoch [137/400], train_Loss: 0.5228,val_Loss:0.5173\n",
      "-Epoch [138/400], train_Loss: 0.5184,val_Loss:0.5252\n",
      "-Epoch [139/400], train_Loss: 0.5145,val_Loss:0.5233\n",
      "-Epoch [140/400], train_Loss: 0.5206,val_Loss:0.5115\n",
      "-Epoch [141/400], train_Loss: 0.5170,val_Loss:0.5081\n",
      "-Epoch [142/400], train_Loss: 0.5192,val_Loss:0.5258\n",
      "-Epoch [143/400], train_Loss: 0.5112,val_Loss:0.5068\n",
      "-Epoch [144/400], train_Loss: 0.5180,val_Loss:0.5049\n",
      "-Epoch [145/400], train_Loss: 0.5230,val_Loss:0.5175\n",
      "-Epoch [146/400], train_Loss: 0.5160,val_Loss:0.5175\n",
      "-Epoch [147/400], train_Loss: 0.5160,val_Loss:0.5137\n",
      "-Epoch [148/400], train_Loss: 0.5215,val_Loss:0.5214\n",
      "-Epoch [149/400], train_Loss: 0.5204,val_Loss:0.5093\n",
      "-Epoch [150/400], train_Loss: 0.5131,val_Loss:0.5093\n",
      "-Epoch [151/400], train_Loss: 0.5189,val_Loss:0.5248\n",
      "-Epoch [152/400], train_Loss: 0.5177,val_Loss:0.5114\n",
      "-Epoch [153/400], train_Loss: 0.5132,val_Loss:0.5180\n",
      "-Epoch [154/400], train_Loss: 0.5152,val_Loss:0.5081\n",
      "-Epoch [155/400], train_Loss: 0.5095,val_Loss:0.5140\n",
      "-Epoch [156/400], train_Loss: 0.5060,val_Loss:0.5239\n",
      "-Epoch [157/400], train_Loss: 0.5116,val_Loss:0.5108\n",
      "-Epoch [158/400], train_Loss: 0.5123,val_Loss:0.5092\n",
      "-Epoch [159/400], train_Loss: 0.5080,val_Loss:0.5132\n",
      "-Epoch [160/400], train_Loss: 0.5134,val_Loss:0.5098\n",
      "-Epoch [161/400], train_Loss: 0.5065,val_Loss:0.5236\n",
      "-Epoch [162/400], train_Loss: 0.5048,val_Loss:0.5131\n",
      "-Epoch [163/400], train_Loss: 0.5058,val_Loss:0.5140\n",
      "-Epoch [164/400], train_Loss: 0.5135,val_Loss:0.5091\n",
      "-Epoch [165/400], train_Loss: 0.5151,val_Loss:0.5012\n",
      "-Epoch [166/400], train_Loss: 0.5091,val_Loss:0.5152\n",
      "-Epoch [167/400], train_Loss: 0.5050,val_Loss:0.5138\n",
      "-Epoch [168/400], train_Loss: 0.5088,val_Loss:0.5165\n",
      "-Epoch [169/400], train_Loss: 0.5082,val_Loss:0.5104\n",
      "-Epoch [170/400], train_Loss: 0.5055,val_Loss:0.5227\n",
      "-Epoch [171/400], train_Loss: 0.5027,val_Loss:0.5202\n",
      "-Epoch [172/400], train_Loss: 0.5003,val_Loss:0.4998\n",
      "-Epoch [173/400], train_Loss: 0.5061,val_Loss:0.5170\n",
      "-Epoch [174/400], train_Loss: 0.5028,val_Loss:0.5177\n",
      "-Epoch [175/400], train_Loss: 0.5075,val_Loss:0.5130\n",
      "-Epoch [176/400], train_Loss: 0.5041,val_Loss:0.5126\n",
      "-Epoch [177/400], train_Loss: 0.5085,val_Loss:0.5027\n",
      "-Epoch [178/400], train_Loss: 0.5043,val_Loss:0.5017\n",
      "-Epoch [179/400], train_Loss: 0.5061,val_Loss:0.5207\n",
      "-Epoch [180/400], train_Loss: 0.4973,val_Loss:0.5115\n",
      "-Epoch [181/400], train_Loss: 0.5041,val_Loss:0.5054\n",
      "-Epoch [182/400], train_Loss: 0.5012,val_Loss:0.5292\n",
      "-Epoch [183/400], train_Loss: 0.5070,val_Loss:0.5089\n",
      "-Epoch [184/400], train_Loss: 0.5026,val_Loss:0.5118\n",
      "-Epoch [185/400], train_Loss: 0.5044,val_Loss:0.5150\n",
      "-Epoch [186/400], train_Loss: 0.4968,val_Loss:0.4984\n",
      "-Epoch [187/400], train_Loss: 0.5029,val_Loss:0.5012\n",
      "-Epoch [188/400], train_Loss: 0.5034,val_Loss:0.4978\n",
      "-Epoch [189/400], train_Loss: 0.4980,val_Loss:0.5047\n",
      "-Epoch [190/400], train_Loss: 0.4965,val_Loss:0.5013\n",
      "-Epoch [191/400], train_Loss: 0.4955,val_Loss:0.5242\n",
      "-Epoch [192/400], train_Loss: 0.4927,val_Loss:0.5094\n",
      "-Epoch [193/400], train_Loss: 0.4997,val_Loss:0.5130\n",
      "-Epoch [194/400], train_Loss: 0.5004,val_Loss:0.5036\n",
      "-Epoch [195/400], train_Loss: 0.4976,val_Loss:0.5084\n",
      "-Epoch [196/400], train_Loss: 0.4910,val_Loss:0.5117\n",
      "-Epoch [197/400], train_Loss: 0.5006,val_Loss:0.4967\n",
      "-Epoch [198/400], train_Loss: 0.5086,val_Loss:0.5005\n",
      "-Epoch [199/400], train_Loss: 0.5018,val_Loss:0.5077\n",
      "-Epoch [200/400], train_Loss: 0.4982,val_Loss:0.5034\n",
      "-Epoch [201/400], train_Loss: 0.4977,val_Loss:0.4988\n",
      "-Epoch [202/400], train_Loss: 0.4902,val_Loss:0.4946\n",
      "-Epoch [203/400], train_Loss: 0.4942,val_Loss:0.5033\n",
      "-Epoch [204/400], train_Loss: 0.4933,val_Loss:0.5035\n",
      "-Epoch [205/400], train_Loss: 0.4937,val_Loss:0.5166\n",
      "-Epoch [206/400], train_Loss: 0.4923,val_Loss:0.5046\n",
      "-Epoch [207/400], train_Loss: 0.4879,val_Loss:0.5045\n",
      "-Epoch [208/400], train_Loss: 0.4935,val_Loss:0.5114\n",
      "-Epoch [209/400], train_Loss: 0.4947,val_Loss:0.5075\n",
      "-Epoch [210/400], train_Loss: 0.4946,val_Loss:0.5034\n",
      "-Epoch [211/400], train_Loss: 0.4910,val_Loss:0.5066\n",
      "-Epoch [212/400], train_Loss: 0.4866,val_Loss:0.5167\n",
      "-Epoch [213/400], train_Loss: 0.4873,val_Loss:0.5198\n",
      "-Epoch [214/400], train_Loss: 0.4977,val_Loss:0.5163\n",
      "-Epoch [215/400], train_Loss: 0.4957,val_Loss:0.5086\n",
      "-Epoch [216/400], train_Loss: 0.4879,val_Loss:0.5214\n",
      "-Epoch [217/400], train_Loss: 0.4887,val_Loss:0.5092\n",
      "-Epoch [218/400], train_Loss: 0.4898,val_Loss:0.5083\n",
      "-Epoch [219/400], train_Loss: 0.4916,val_Loss:0.5081\n",
      "-Epoch [220/400], train_Loss: 0.4964,val_Loss:0.5148\n",
      "-Epoch [221/400], train_Loss: 0.4899,val_Loss:0.5105\n",
      "-Epoch [222/400], train_Loss: 0.4867,val_Loss:0.5028\n",
      "-Epoch [223/400], train_Loss: 0.4926,val_Loss:0.5068\n",
      "-Epoch [224/400], train_Loss: 0.4930,val_Loss:0.5068\n",
      "-Epoch [225/400], train_Loss: 0.4897,val_Loss:0.5147\n",
      "-Epoch [226/400], train_Loss: 0.4903,val_Loss:0.5155\n",
      "-Epoch [227/400], train_Loss: 0.4847,val_Loss:0.5102\n",
      "-Epoch [228/400], train_Loss: 0.4887,val_Loss:0.5098\n",
      "-Epoch [229/400], train_Loss: 0.4899,val_Loss:0.5046\n",
      "-Epoch [230/400], train_Loss: 0.4844,val_Loss:0.5138\n",
      "-Epoch [231/400], train_Loss: 0.4868,val_Loss:0.4985\n",
      "-Epoch [232/400], train_Loss: 0.4952,val_Loss:0.5150\n",
      "-Epoch [233/400], train_Loss: 0.4913,val_Loss:0.5100\n",
      "-Epoch [234/400], train_Loss: 0.4841,val_Loss:0.5003\n",
      "-Epoch [235/400], train_Loss: 0.4862,val_Loss:0.4953\n",
      "-Epoch [236/400], train_Loss: 0.4890,val_Loss:0.5186\n",
      "-Epoch [237/400], train_Loss: 0.4827,val_Loss:0.5005\n",
      "-Epoch [238/400], train_Loss: 0.4914,val_Loss:0.5056\n",
      "-Epoch [239/400], train_Loss: 0.4914,val_Loss:0.5049\n",
      "-Epoch [240/400], train_Loss: 0.4860,val_Loss:0.5054\n",
      "-Epoch [241/400], train_Loss: 0.4874,val_Loss:0.5142\n",
      "-Epoch [242/400], train_Loss: 0.4852,val_Loss:0.5155\n",
      "-Epoch [243/400], train_Loss: 0.4824,val_Loss:0.5032\n",
      "-Epoch [244/400], train_Loss: 0.4910,val_Loss:0.5117\n",
      "-Epoch [245/400], train_Loss: 0.4830,val_Loss:0.4934\n",
      "-Epoch [246/400], train_Loss: 0.4886,val_Loss:0.5026\n",
      "-Epoch [247/400], train_Loss: 0.4779,val_Loss:0.5151\n",
      "-Epoch [248/400], train_Loss: 0.4854,val_Loss:0.4989\n",
      "-Epoch [249/400], train_Loss: 0.4828,val_Loss:0.4951\n",
      "-Epoch [250/400], train_Loss: 0.4835,val_Loss:0.5166\n",
      "-Epoch [251/400], train_Loss: 0.4822,val_Loss:0.4973\n",
      "-Epoch [252/400], train_Loss: 0.4773,val_Loss:0.5079\n",
      "-Epoch [253/400], train_Loss: 0.4883,val_Loss:0.5062\n",
      "-Epoch [254/400], train_Loss: 0.4808,val_Loss:0.5085\n",
      "-Epoch [255/400], train_Loss: 0.4829,val_Loss:0.5071\n",
      "-Epoch [256/400], train_Loss: 0.4808,val_Loss:0.5041\n",
      "-Epoch [257/400], train_Loss: 0.4856,val_Loss:0.5064\n",
      "-Epoch [258/400], train_Loss: 0.4789,val_Loss:0.5095\n",
      "-Epoch [259/400], train_Loss: 0.4789,val_Loss:0.5167\n",
      "-Epoch [260/400], train_Loss: 0.4848,val_Loss:0.5086\n",
      "-Epoch [261/400], train_Loss: 0.4721,val_Loss:0.5029\n",
      "-Epoch [262/400], train_Loss: 0.4803,val_Loss:0.5057\n",
      "-Epoch [263/400], train_Loss: 0.4700,val_Loss:0.4972\n",
      "-Epoch [264/400], train_Loss: 0.4804,val_Loss:0.5069\n",
      "-Epoch [265/400], train_Loss: 0.4808,val_Loss:0.5068\n",
      "-Epoch [266/400], train_Loss: 0.4821,val_Loss:0.5066\n",
      "-Epoch [267/400], train_Loss: 0.4806,val_Loss:0.4961\n",
      "-Epoch [268/400], train_Loss: 0.4857,val_Loss:0.4953\n",
      "-Epoch [269/400], train_Loss: 0.4759,val_Loss:0.4908\n",
      "-Epoch [270/400], train_Loss: 0.4772,val_Loss:0.5104\n",
      "-Epoch [271/400], train_Loss: 0.4776,val_Loss:0.5102\n",
      "-Epoch [272/400], train_Loss: 0.4813,val_Loss:0.5067\n",
      "-Epoch [273/400], train_Loss: 0.4789,val_Loss:0.4981\n",
      "-Epoch [274/400], train_Loss: 0.4801,val_Loss:0.5014\n",
      "-Epoch [275/400], train_Loss: 0.4740,val_Loss:0.5026\n",
      "-Epoch [276/400], train_Loss: 0.4778,val_Loss:0.5035\n",
      "-Epoch [277/400], train_Loss: 0.4752,val_Loss:0.5072\n",
      "-Epoch [278/400], train_Loss: 0.4804,val_Loss:0.5174\n",
      "-Epoch [279/400], train_Loss: 0.4818,val_Loss:0.5111\n",
      "-Epoch [280/400], train_Loss: 0.4824,val_Loss:0.5087\n",
      "-Epoch [281/400], train_Loss: 0.4802,val_Loss:0.5061\n",
      "-Epoch [282/400], train_Loss: 0.4776,val_Loss:0.4948\n",
      "-Epoch [283/400], train_Loss: 0.4818,val_Loss:0.5104\n",
      "-Epoch [284/400], train_Loss: 0.4829,val_Loss:0.4935\n",
      "-Epoch [285/400], train_Loss: 0.4800,val_Loss:0.5102\n",
      "-Epoch [286/400], train_Loss: 0.4753,val_Loss:0.5169\n",
      "-Epoch [287/400], train_Loss: 0.4818,val_Loss:0.5020\n",
      "-Epoch [288/400], train_Loss: 0.4727,val_Loss:0.5025\n",
      "-Epoch [289/400], train_Loss: 0.4844,val_Loss:0.5036\n",
      "-Epoch [290/400], train_Loss: 0.4789,val_Loss:0.5044\n",
      "-Epoch [291/400], train_Loss: 0.4903,val_Loss:0.5120\n",
      "-Epoch [292/400], train_Loss: 0.4795,val_Loss:0.5142\n",
      "-Epoch [293/400], train_Loss: 0.4700,val_Loss:0.4923\n",
      "-Epoch [294/400], train_Loss: 0.4758,val_Loss:0.5018\n",
      "-Epoch [295/400], train_Loss: 0.4768,val_Loss:0.5117\n",
      "-Epoch [296/400], train_Loss: 0.4799,val_Loss:0.5110\n",
      "-Epoch [297/400], train_Loss: 0.4845,val_Loss:0.5021\n",
      "-Epoch [298/400], train_Loss: 0.4726,val_Loss:0.5090\n",
      "-Epoch [299/400], train_Loss: 0.4720,val_Loss:0.5102\n",
      "-Epoch [300/400], train_Loss: 0.4748,val_Loss:0.5157\n",
      "-Epoch [301/400], train_Loss: 0.4738,val_Loss:0.5078\n",
      "-Epoch [302/400], train_Loss: 0.4750,val_Loss:0.5111\n",
      "-Epoch [303/400], train_Loss: 0.4631,val_Loss:0.5115\n",
      "-Epoch [304/400], train_Loss: 0.4706,val_Loss:0.4997\n",
      "-Epoch [305/400], train_Loss: 0.4750,val_Loss:0.5049\n",
      "-Epoch [306/400], train_Loss: 0.4794,val_Loss:0.5042\n",
      "-Epoch [307/400], train_Loss: 0.4786,val_Loss:0.5187\n",
      "-Epoch [308/400], train_Loss: 0.4674,val_Loss:0.5096\n",
      "-Epoch [309/400], train_Loss: 0.4737,val_Loss:0.5195\n",
      "-Epoch [310/400], train_Loss: 0.4754,val_Loss:0.5082\n",
      "-Epoch [311/400], train_Loss: 0.4729,val_Loss:0.5054\n",
      "-Epoch [312/400], train_Loss: 0.4718,val_Loss:0.5102\n",
      "-Epoch [313/400], train_Loss: 0.4681,val_Loss:0.5156\n",
      "-Epoch [314/400], train_Loss: 0.4717,val_Loss:0.5066\n",
      "-Epoch [315/400], train_Loss: 0.4741,val_Loss:0.5028\n",
      "-Epoch [316/400], train_Loss: 0.4683,val_Loss:0.5077\n",
      "-Epoch [317/400], train_Loss: 0.4720,val_Loss:0.5063\n",
      "-Epoch [318/400], train_Loss: 0.4716,val_Loss:0.5135\n",
      "-Epoch [319/400], train_Loss: 0.4743,val_Loss:0.4915\n",
      "-Epoch [320/400], train_Loss: 0.4723,val_Loss:0.5150\n",
      "-Epoch [321/400], train_Loss: 0.4749,val_Loss:0.5023\n",
      "-Epoch [322/400], train_Loss: 0.4815,val_Loss:0.5238\n",
      "-Epoch [323/400], train_Loss: 0.4762,val_Loss:0.4958\n",
      "-Epoch [324/400], train_Loss: 0.4750,val_Loss:0.5012\n",
      "-Epoch [325/400], train_Loss: 0.4822,val_Loss:0.5030\n",
      "-Epoch [326/400], train_Loss: 0.4756,val_Loss:0.4933\n",
      "-Epoch [327/400], train_Loss: 0.4674,val_Loss:0.4972\n",
      "-Epoch [328/400], train_Loss: 0.4700,val_Loss:0.5018\n",
      "-Epoch [329/400], train_Loss: 0.4736,val_Loss:0.4976\n",
      "-Epoch [330/400], train_Loss: 0.4616,val_Loss:0.4864\n",
      "-Epoch [331/400], train_Loss: 0.4690,val_Loss:0.5011\n",
      "-Epoch [332/400], train_Loss: 0.4686,val_Loss:0.5152\n",
      "-Epoch [333/400], train_Loss: 0.4679,val_Loss:0.5010\n",
      "-Epoch [334/400], train_Loss: 0.4615,val_Loss:0.4913\n",
      "-Epoch [335/400], train_Loss: 0.4716,val_Loss:0.5212\n",
      "-Epoch [336/400], train_Loss: 0.4660,val_Loss:0.4930\n",
      "-Epoch [337/400], train_Loss: 0.4712,val_Loss:0.5055\n",
      "-Epoch [338/400], train_Loss: 0.4685,val_Loss:0.5099\n",
      "-Epoch [339/400], train_Loss: 0.4646,val_Loss:0.5058\n",
      "-Epoch [340/400], train_Loss: 0.4682,val_Loss:0.5019\n",
      "-Epoch [341/400], train_Loss: 0.4641,val_Loss:0.5023\n",
      "-Epoch [342/400], train_Loss: 0.4660,val_Loss:0.5186\n",
      "-Epoch [343/400], train_Loss: 0.4669,val_Loss:0.5067\n",
      "-Epoch [344/400], train_Loss: 0.4553,val_Loss:0.4984\n",
      "-Epoch [345/400], train_Loss: 0.4664,val_Loss:0.5069\n",
      "-Epoch [346/400], train_Loss: 0.4567,val_Loss:0.4932\n",
      "-Epoch [347/400], train_Loss: 0.4649,val_Loss:0.5011\n",
      "-Epoch [348/400], train_Loss: 0.4718,val_Loss:0.5013\n",
      "-Epoch [349/400], train_Loss: 0.4682,val_Loss:0.4983\n",
      "-Epoch [350/400], train_Loss: 0.4671,val_Loss:0.5074\n",
      "-Epoch [351/400], train_Loss: 0.4690,val_Loss:0.5109\n",
      "-Epoch [352/400], train_Loss: 0.4594,val_Loss:0.4938\n",
      "-Epoch [353/400], train_Loss: 0.4592,val_Loss:0.5040\n",
      "-Epoch [354/400], train_Loss: 0.4637,val_Loss:0.5127\n",
      "-Epoch [355/400], train_Loss: 0.4661,val_Loss:0.5046\n",
      "-Epoch [356/400], train_Loss: 0.4740,val_Loss:0.4909\n",
      "-Epoch [357/400], train_Loss: 0.4643,val_Loss:0.4962\n",
      "-Epoch [358/400], train_Loss: 0.4633,val_Loss:0.4822\n",
      "-Epoch [359/400], train_Loss: 0.4677,val_Loss:0.4979\n",
      "-Epoch [360/400], train_Loss: 0.4647,val_Loss:0.5048\n",
      "-Epoch [361/400], train_Loss: 0.4728,val_Loss:0.5014\n",
      "-Epoch [362/400], train_Loss: 0.4639,val_Loss:0.4943\n",
      "-Epoch [363/400], train_Loss: 0.4699,val_Loss:0.5071\n",
      "-Epoch [364/400], train_Loss: 0.4618,val_Loss:0.4946\n",
      "-Epoch [365/400], train_Loss: 0.4661,val_Loss:0.5003\n",
      "-Epoch [366/400], train_Loss: 0.4629,val_Loss:0.4991\n",
      "-Epoch [367/400], train_Loss: 0.4677,val_Loss:0.5012\n",
      "-Epoch [368/400], train_Loss: 0.4589,val_Loss:0.4871\n",
      "-Epoch [369/400], train_Loss: 0.4617,val_Loss:0.4966\n",
      "-Epoch [370/400], train_Loss: 0.4630,val_Loss:0.4983\n",
      "-Epoch [371/400], train_Loss: 0.4638,val_Loss:0.5047\n",
      "-Epoch [372/400], train_Loss: 0.4645,val_Loss:0.4964\n",
      "-Epoch [373/400], train_Loss: 0.4653,val_Loss:0.5013\n",
      "-Epoch [374/400], train_Loss: 0.4673,val_Loss:0.5001\n",
      "-Epoch [375/400], train_Loss: 0.4682,val_Loss:0.5088\n",
      "-Epoch [376/400], train_Loss: 0.4623,val_Loss:0.5024\n",
      "-Epoch [377/400], train_Loss: 0.4629,val_Loss:0.4973\n",
      "-Epoch [378/400], train_Loss: 0.4582,val_Loss:0.5047\n",
      "-Epoch [379/400], train_Loss: 0.4690,val_Loss:0.5170\n",
      "-Epoch [380/400], train_Loss: 0.4571,val_Loss:0.5077\n",
      "-Epoch [381/400], train_Loss: 0.4587,val_Loss:0.5178\n",
      "-Epoch [382/400], train_Loss: 0.4642,val_Loss:0.5002\n",
      "-Epoch [383/400], train_Loss: 0.4633,val_Loss:0.4972\n",
      "-Epoch [384/400], train_Loss: 0.4639,val_Loss:0.4967\n",
      "-Epoch [385/400], train_Loss: 0.4592,val_Loss:0.4993\n",
      "-Epoch [386/400], train_Loss: 0.4624,val_Loss:0.5318\n",
      "-Epoch [387/400], train_Loss: 0.4666,val_Loss:0.4934\n",
      "-Epoch [388/400], train_Loss: 0.4661,val_Loss:0.4997\n",
      "-Epoch [389/400], train_Loss: 0.4588,val_Loss:0.5128\n",
      "-Epoch [390/400], train_Loss: 0.4525,val_Loss:0.4987\n",
      "-Epoch [391/400], train_Loss: 0.4614,val_Loss:0.5029\n",
      "-Epoch [392/400], train_Loss: 0.4705,val_Loss:0.5038\n",
      "-Epoch [393/400], train_Loss: 0.4601,val_Loss:0.5010\n",
      "-Epoch [394/400], train_Loss: 0.4646,val_Loss:0.5059\n",
      "-Epoch [395/400], train_Loss: 0.4582,val_Loss:0.5021\n",
      "-Epoch [396/400], train_Loss: 0.4617,val_Loss:0.5048\n",
      "-Epoch [397/400], train_Loss: 0.4607,val_Loss:0.4960\n",
      "-Epoch [398/400], train_Loss: 0.4655,val_Loss:0.5034\n",
      "-Epoch [399/400], train_Loss: 0.4613,val_Loss:0.5145\n",
      "-Epoch [400/400], train_Loss: 0.4680,val_Loss:0.5090\n"
     ]
    }
   ],
   "source": [
    "#optimizer = optim.SGD(model.parameters(), lr=0.01,momentum = 0.9,weight_decay=0.00005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.9)\n",
    "num_epochs = 400\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(node_features)\n",
    "    optimizer.zero_grad()\n",
    "    # 计算损失\n",
    "    l = criterion(outputs[idx_train], labels[idx_train])\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    #r2_train = r2_fun(outputs, labels[idx_train])\n",
    "    \n",
    "    mse = F.mse_loss(outputs[idx_val], labels[idx_val])\n",
    "    r1 = r2_fun(outputs[idx_val], labels[idx_val])\n",
    "\n",
    "    # 打印训练误差\n",
    "    print(f'-Epoch [{epoch+1}/{num_epochs}], train_Loss: {l:.4f},val_Loss:{mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "850a8006-70ff-4687-be86-3b8c4d328b94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5096277394059817 3.4830086\n"
     ]
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load('./up/MLP_avg_trained.pth'))\n",
    "model.eval()\n",
    "output= model(node_features)\n",
    "loss1 = F.mse_loss(output[idx_test], labels[idx_test])\n",
    "r2_val = r2_fun(output[idx_test], labels[idx_test])\n",
    "s_y = dataset.ss_y\n",
    "y_pre = s_y.inverse_transform(output.detach().numpy())\n",
    "y_ture = s_y.inverse_transform(labels.detach().numpy())\n",
    "\n",
    "r2 = r2_score(y_ture[idx_test], y_pre[idx_test])\n",
    "mae = mean_absolute_error(y_ture[idx_test], y_pre[idx_test])\n",
    "\n",
    "print(\"Mean Squared Error:\", r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a5757ec-f08b-42dd-aa6f-5deb99abfaee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import BatchNorm\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size1,hidden_size2):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_feats, hidden_size1)\n",
    "        self.conv1 = dglnn.GraphConv(hidden_size1, hidden_size2,weight = True)\n",
    "        self.conv2 = dglnn.GraphConv(hidden_size2, hidden_size2, weight = True)\n",
    "        #self.conv3 = dglnn.GraphConv(hidden_size2, hidden_size2, weight = True)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dropout0 = nn.Dropout(0.5)\n",
    "        self.bn1 = BatchNorm(hidden_size1)\n",
    "\n",
    "        #self.embedding_1 = nn.Embedding(10,2)  #9 equal to calsses of land cover\n",
    "        #self.embedding_2 = nn.Embedding(13,2)  #7 equal to calsses of lithology\n",
    "\n",
    "    def reset_param(self):\n",
    "        for layer in [self.conv1, self.conv2]:\n",
    "            nn.itnit.kaiming_uniform_(layer.weight, a=0, mode = 'fan_in',nonlinearity = 'relu')\n",
    "\n",
    "    def forward(self, g, x1):\n",
    "        #embedded_1 = self.embedding_1(x1[:,-2].long())\n",
    "        #embedded_2 = self.embedding_2(x1[:,-1].long())\n",
    "\n",
    "        #combined_fe = torch.cat((x1[:,:-2], embedded_1.view(embedded_1.size(0), -1), embedded_2.view(embedded_2.size(0), -1)), dim=1)\n",
    "\n",
    "        #x = self.dropout0(combined_fe)\n",
    "        x1 =  self.fc1(x1)   #concat combined_fe0 and x2\n",
    "        x1 =  nn.functional.elu(x1)\n",
    "        #combined_fe = self.dropout0(combined_fe)\n",
    "        \n",
    "        \n",
    "        x = self.conv1(g, x1)\n",
    "        #x= self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x= self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(g, x)\n",
    "        x = torch.relu(x)\n",
    "        x= self.dropout2(x)\n",
    "        '''\n",
    "        x = self.conv3(g, x)\n",
    "        x = torch.relu(x)\n",
    "        x= self.dropout3(x)\n",
    "        '''\n",
    "        #x = self.fc1(x)\n",
    "        #x = torch.relu(x)\n",
    "        #x= self.dropout0(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "GNN = GNN(in_feats=node_features.shape[1], hidden_size1=128,hidden_size2=128)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(GNN.parameters(), lr=0.005,weight_decay = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d16e998b-9055-43d3-8cef-0249fe244289",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------epoch: 0\n",
      "0.9762498140335083 -56.56361118604066\n",
      "Mean Squared Error: 0.9468945264816284 -60.159629024113904\n",
      "------------------epoch: 1\n",
      "0.8659457564353943 -7.7453500601544665\n",
      "Mean Squared Error: 0.8305231332778931 -7.42079604369712\n",
      "------------------epoch: 2\n",
      "0.8354129195213318 -2.8647451814332654\n",
      "Mean Squared Error: 0.8006804585456848 -2.8087916608365204\n",
      "------------------epoch: 3\n",
      "0.7974793314933777 -3.0779929225034754\n",
      "Mean Squared Error: 0.7656152844429016 -3.0893659878186615\n",
      "------------------epoch: 4\n",
      "0.7846793532371521 -3.7231436496126573\n",
      "Mean Squared Error: 0.753498911857605 -3.5450203989575035\n",
      "------------------epoch: 5\n",
      "0.7645609378814697 -3.796322054688142\n",
      "Mean Squared Error: 0.7223557829856873 -3.5584229040333613\n",
      "------------------epoch: 6\n",
      "0.7428364753723145 -2.8710158463759554\n",
      "Mean Squared Error: 0.702528715133667 -2.7225775560104273\n",
      "------------------epoch: 7\n",
      "0.7357779741287231 -1.9619801379478017\n",
      "Mean Squared Error: 0.7031760811805725 -1.7745637624263773\n",
      "------------------epoch: 8\n",
      "0.7312649488449097 -1.53456974503912\n",
      "Mean Squared Error: 0.6908571720123291 -1.3914022501501737\n",
      "------------------epoch: 9\n",
      "0.718034565448761 -1.664805912206929\n",
      "Mean Squared Error: 0.6985354423522949 -1.553179796205109\n",
      "------------------epoch: 10\n",
      "0.7146487832069397 -1.8032244202395074\n",
      "Mean Squared Error: 0.6842401027679443 -1.6733641252368145\n",
      "------------------epoch: 11\n",
      "0.7086014151573181 -1.827050672106465\n",
      "Mean Squared Error: 0.6774572134017944 -1.5902415034529462\n",
      "------------------epoch: 12\n",
      "0.7008540034294128 -1.6075504880975302\n",
      "Mean Squared Error: 0.6750672459602356 -1.4406643425145602\n",
      "------------------epoch: 13\n",
      "0.6959143280982971 -1.3470392753961313\n",
      "Mean Squared Error: 0.6683825850486755 -1.2425122467119674\n",
      "------------------epoch: 14\n",
      "0.6913864016532898 -1.279352635867245\n",
      "Mean Squared Error: 0.6587862372398376 -1.19081119116007\n",
      "------------------epoch: 15\n",
      "0.686388373374939 -1.5005509470378082\n",
      "Mean Squared Error: 0.6553163528442383 -1.3912160248388319\n",
      "------------------epoch: 16\n",
      "0.6872400045394897 -1.7449361088287412\n",
      "Mean Squared Error: 0.6556400060653687 -1.664297231550552\n",
      "------------------epoch: 17\n",
      "0.6800724864006042 -1.7415322735443604\n",
      "Mean Squared Error: 0.6552079916000366 -1.6305476706917044\n",
      "------------------epoch: 18\n",
      "0.6827971339225769 -1.520895908597784\n",
      "Mean Squared Error: 0.645831286907196 -1.42678204344777\n",
      "------------------epoch: 19\n",
      "0.6783875823020935 -1.1672019281774464\n",
      "Mean Squared Error: 0.6501702070236206 -1.0492501823844238\n",
      "------------------epoch: 20\n",
      "0.6730794906616211 -1.1674006236070023\n",
      "Mean Squared Error: 0.6431906819343567 -1.05272126102125\n",
      "------------------epoch: 21\n",
      "0.6688956618309021 -1.2337555428687206\n",
      "Mean Squared Error: 0.6263168454170227 -1.1343850843152903\n",
      "------------------epoch: 22\n",
      "0.6647647619247437 -1.348144775863191\n",
      "Mean Squared Error: 0.6265360116958618 -1.2540242242851076\n",
      "------------------epoch: 23\n",
      "0.6551772356033325 -1.291634170989024\n",
      "Mean Squared Error: 0.6216369867324829 -1.193907961313422\n",
      "------------------epoch: 24\n",
      "0.6485345959663391 -1.1170315611791453\n",
      "Mean Squared Error: 0.6264063715934753 -1.009400512194361\n",
      "------------------epoch: 25\n",
      "0.6534192562103271 -1.0223660844141444\n",
      "Mean Squared Error: 0.6061858534812927 -0.8535841437125358\n",
      "------------------epoch: 26\n",
      "0.65098637342453 -1.0403320798817384\n",
      "Mean Squared Error: 0.6126458048820496 -0.8922088726722182\n",
      "------------------epoch: 27\n",
      "0.6455159783363342 -1.0683029572744118\n",
      "Mean Squared Error: 0.6013241410255432 -0.8538507194625033\n",
      "------------------epoch: 28\n",
      "0.6412960290908813 -1.1671944369149072\n",
      "Mean Squared Error: 0.6141704320907593 -1.0044745760031697\n",
      "------------------epoch: 29\n",
      "0.6427476406097412 -1.1012040920563035\n",
      "Mean Squared Error: 0.6176996827125549 -1.0172458606300325\n",
      "------------------epoch: 30\n",
      "0.6385059952735901 -0.8623353772183766\n",
      "Mean Squared Error: 0.6157839894294739 -0.7202489168680613\n",
      "------------------epoch: 31\n",
      "0.6326621770858765 -0.8003204781161779\n",
      "Mean Squared Error: 0.606894850730896 -0.7129537846712917\n",
      "------------------epoch: 32\n",
      "0.6293961405754089 -0.9212008141922474\n",
      "Mean Squared Error: 0.6133202910423279 -0.8542801968797458\n",
      "------------------epoch: 33\n",
      "0.6247367262840271 -1.049317731824007\n",
      "Mean Squared Error: 0.5976332426071167 -0.8965166704557617\n",
      "------------------epoch: 34\n",
      "0.6182172298431396 -0.9466709736268184\n",
      "Mean Squared Error: 0.6008333563804626 -0.910246528565861\n",
      "------------------epoch: 35\n",
      "0.6201741099357605 -0.8229600446219545\n",
      "Mean Squared Error: 0.6101763844490051 -0.7516052348518094\n",
      "------------------epoch: 36\n",
      "0.6207968592643738 -0.6770796149522194\n",
      "Mean Squared Error: 0.5935690402984619 -0.5512747844982266\n",
      "------------------epoch: 37\n",
      "0.6180869936943054 -0.7227450643041771\n",
      "Mean Squared Error: 0.5987107157707214 -0.6336940551964843\n",
      "------------------epoch: 38\n",
      "0.6089097261428833 -0.7927551863300981\n",
      "Mean Squared Error: 0.6012952923774719 -0.7620247749714291\n",
      "------------------epoch: 39\n",
      "0.6154068112373352 -0.8043544809414702\n",
      "Mean Squared Error: 0.6000514626502991 -0.7973635080958699\n",
      "------------------epoch: 40\n",
      "0.6021502614021301 -0.7349484783692\n",
      "Mean Squared Error: 0.5929228663444519 -0.7301808711517981\n",
      "------------------epoch: 41\n",
      "0.6056792140007019 -0.7217685248525016\n",
      "Mean Squared Error: 0.5916560888290405 -0.7338666267291332\n",
      "------------------epoch: 42\n",
      "0.608548641204834 -0.6670612961309452\n",
      "Mean Squared Error: 0.5773962140083313 -0.542095088298044\n",
      "------------------epoch: 43\n",
      "0.6026609539985657 -0.7583606467808621\n",
      "Mean Squared Error: 0.5819505453109741 -0.6617220793523078\n",
      "------------------epoch: 44\n",
      "0.6016913056373596 -0.7303327090907406\n",
      "Mean Squared Error: 0.5955927968025208 -0.6430097374625079\n",
      "------------------epoch: 45\n",
      "0.5963188409805298 -0.6828498449773408\n",
      "Mean Squared Error: 0.5945966839790344 -0.6653510742555799\n",
      "------------------epoch: 46\n",
      "0.6023759841918945 -0.632372378193458\n",
      "Mean Squared Error: 0.5930912494659424 -0.5974777255526833\n",
      "------------------epoch: 47\n",
      "0.5998062491416931 -0.5440591615672281\n",
      "Mean Squared Error: 0.5905286073684692 -0.46147422959274387\n",
      "------------------epoch: 48\n",
      "0.59366774559021 -0.5759617679173354\n",
      "Mean Squared Error: 0.5928254127502441 -0.5158027268888106\n",
      "------------------epoch: 49\n",
      "0.585248589515686 -0.5897633765781038\n",
      "Mean Squared Error: 0.5772168636322021 -0.5750274900052117\n",
      "------------------epoch: 50\n",
      "0.5889979004859924 -0.6909494329859609\n",
      "Mean Squared Error: 0.5697416663169861 -0.5798185690022191\n",
      "------------------epoch: 51\n",
      "0.5890786051750183 -0.6052560409409611\n",
      "Mean Squared Error: 0.5921034216880798 -0.5861654375683565\n",
      "------------------epoch: 52\n",
      "0.5854834318161011 -0.5288303860936383\n",
      "Mean Squared Error: 0.5768662691116333 -0.49945425989201575\n",
      "------------------epoch: 53\n",
      "0.58064866065979 -0.5431802159678616\n",
      "Mean Squared Error: 0.5790968537330627 -0.5122197075386659\n",
      "------------------epoch: 54\n",
      "0.5835575461387634 -0.5953803162963831\n",
      "Mean Squared Error: 0.5722701549530029 -0.5005877066529489\n",
      "------------------epoch: 55\n",
      "0.5756748914718628 -0.599517878380678\n",
      "Mean Squared Error: 0.5769262909889221 -0.5318144400705846\n",
      "------------------epoch: 56\n",
      "0.5806873440742493 -0.5509834795213715\n",
      "Mean Squared Error: 0.572201669216156 -0.5195216957021613\n",
      "------------------epoch: 57\n",
      "0.5782608389854431 -0.45850424022509784\n",
      "Mean Squared Error: 0.5740643739700317 -0.4173698677872333\n",
      "------------------epoch: 58\n",
      "0.5740302801132202 -0.4123609390996015\n",
      "Mean Squared Error: 0.5654524564743042 -0.3693729681668323\n",
      "------------------epoch: 59\n",
      "0.5725669860839844 -0.4453920958408697\n",
      "Mean Squared Error: 0.5758731961250305 -0.48813425670244626\n",
      "------------------epoch: 60\n",
      "0.5756655931472778 -0.5351180042780848\n",
      "Mean Squared Error: 0.565512478351593 -0.5153412344934385\n",
      "------------------epoch: 61\n",
      "0.5633063912391663 -0.5186621908080848\n",
      "Mean Squared Error: 0.5682099461555481 -0.5608072553584487\n",
      "------------------epoch: 62\n",
      "0.5709672570228577 -0.4367712247066333\n",
      "Mean Squared Error: 0.569723904132843 -0.43685456957019553\n",
      "------------------epoch: 63\n",
      "0.5728273391723633 -0.43831782930118046\n",
      "Mean Squared Error: 0.5686157941818237 -0.4179327601215992\n",
      "------------------epoch: 64\n",
      "0.5639350414276123 -0.48556061280728624\n",
      "Mean Squared Error: 0.564808189868927 -0.4629990805792126\n",
      "------------------epoch: 65\n",
      "0.56577068567276 -0.5032028255711494\n",
      "Mean Squared Error: 0.5687688589096069 -0.5303509370054345\n",
      "------------------epoch: 66\n",
      "0.5615904331207275 -0.3930067033561697\n",
      "Mean Squared Error: 0.5554792881011963 -0.3544147433388749\n",
      "------------------epoch: 67\n",
      "0.558858335018158 -0.36473408691634046\n",
      "Mean Squared Error: 0.5654612183570862 -0.3307841107494991\n",
      "------------------epoch: 68\n",
      "0.564670205116272 -0.33751353368418524\n",
      "Mean Squared Error: 0.5725358724594116 -0.36020019055794417\n",
      "------------------epoch: 69\n",
      "0.5590417981147766 -0.3995371629224045\n",
      "Mean Squared Error: 0.5645171403884888 -0.3889489740574401\n",
      "------------------epoch: 70\n",
      "0.5530496835708618 -0.4333773703998365\n",
      "Mean Squared Error: 0.5598751306533813 -0.4519794643141388\n",
      "------------------epoch: 71\n",
      "0.5571253895759583 -0.4158586018442665\n",
      "Mean Squared Error: 0.555705726146698 -0.40528565210802703\n",
      "------------------epoch: 72\n",
      "0.548242449760437 -0.4341492030384535\n",
      "Mean Squared Error: 0.5601220726966858 -0.44611428715159906\n",
      "------------------epoch: 73\n",
      "0.5554494261741638 -0.36054817035567077\n",
      "Mean Squared Error: 0.5615073442459106 -0.3513745214583406\n",
      "------------------epoch: 74\n",
      "0.5412478446960449 -0.23053461400297892\n",
      "Mean Squared Error: 0.5614532828330994 -0.3024961725896296\n",
      "------------------epoch: 75\n",
      "0.5483959913253784 -0.2817823507950423\n",
      "Mean Squared Error: 0.558912456035614 -0.3121047940683903\n",
      "------------------epoch: 76\n",
      "0.5519130229949951 -0.31873171184873916\n",
      "Mean Squared Error: 0.5541815161705017 -0.32574227092147745\n",
      "------------------epoch: 77\n",
      "0.5461045503616333 -0.31830610701255035\n",
      "Mean Squared Error: 0.5643887519836426 -0.32712146722982904\n",
      "------------------epoch: 78\n",
      "0.5439051389694214 -0.36750215388332785\n",
      "Mean Squared Error: 0.5629258751869202 -0.3597715211490671\n",
      "------------------epoch: 79\n",
      "0.5458643436431885 -0.4035848501417343\n",
      "Mean Squared Error: 0.5666718482971191 -0.4702135614089211\n",
      "------------------epoch: 80\n",
      "0.5404837727546692 -0.30576169317592594\n",
      "Mean Squared Error: 0.5700005888938904 -0.3621188431900546\n",
      "------------------epoch: 81\n",
      "0.5440177321434021 -0.23362756675252694\n",
      "Mean Squared Error: 0.5705904364585876 -0.27053480071104685\n",
      "------------------epoch: 82\n",
      "0.548225462436676 -0.26206875133575336\n",
      "Mean Squared Error: 0.5712523460388184 -0.279114781841324\n",
      "------------------epoch: 83\n",
      "0.5347055196762085 -0.32596345725094333\n",
      "Mean Squared Error: 0.5530826449394226 -0.32205514799648616\n",
      "------------------epoch: 84\n",
      "0.5397732853889465 -0.3596653104694423\n",
      "Mean Squared Error: 0.5494227409362793 -0.4072929247805879\n",
      "------------------epoch: 85\n",
      "0.5396015048027039 -0.3368486013323826\n",
      "Mean Squared Error: 0.5588610768318176 -0.3859443632940027\n",
      "------------------epoch: 86\n",
      "0.5439682602882385 -0.1753458396566676\n",
      "Mean Squared Error: 0.5650970339775085 -0.20378277270240863\n",
      "------------------epoch: 87\n",
      "0.5297943949699402 -0.19534975364547313\n",
      "Mean Squared Error: 0.5548213124275208 -0.27652129372649004\n",
      "------------------epoch: 88\n",
      "0.539489209651947 -0.3919131762772545\n",
      "Mean Squared Error: 0.561956524848938 -0.44870890547441067\n",
      "------------------epoch: 89\n",
      "0.5368390083312988 -0.34869938795469824\n",
      "Mean Squared Error: 0.5552927255630493 -0.3945254203733779\n",
      "------------------epoch: 90\n",
      "0.5316506624221802 -0.2398450071970355\n",
      "Mean Squared Error: 0.548482358455658 -0.27909652027648213\n",
      "------------------epoch: 91\n",
      "0.5332492589950562 -0.16906910497151584\n",
      "Mean Squared Error: 0.5498773455619812 -0.16755220512506752\n",
      "------------------epoch: 92\n",
      "0.5328212380409241 -0.23751378726757744\n",
      "Mean Squared Error: 0.5580265522003174 -0.2681706414001024\n",
      "------------------epoch: 93\n",
      "0.5268007516860962 -0.26314409070935785\n",
      "Mean Squared Error: 0.5492215752601624 -0.285860884666868\n",
      "------------------epoch: 94\n",
      "0.5302883982658386 -0.2080892104903156\n",
      "Mean Squared Error: 0.5490236878395081 -0.27581839174750145\n",
      "------------------epoch: 95\n",
      "0.5256993770599365 -0.1844162013029944\n",
      "Mean Squared Error: 0.5477244257926941 -0.24622281114477107\n",
      "------------------epoch: 96\n",
      "0.5223443508148193 -0.20244484366811677\n",
      "Mean Squared Error: 0.5494974255561829 -0.2860970058744212\n",
      "------------------epoch: 97\n",
      "0.5317525267601013 -0.2542620598876173\n",
      "Mean Squared Error: 0.5574220418930054 -0.31023985594979253\n",
      "------------------epoch: 98\n",
      "0.525560736656189 -0.20282278251503594\n",
      "Mean Squared Error: 0.5535950064659119 -0.2631686206765562\n",
      "------------------epoch: 99\n",
      "0.5234693884849548 -0.17191357930687334\n",
      "Mean Squared Error: 0.5390225648880005 -0.22805060695997126\n",
      "------------------epoch: 100\n",
      "0.5226430892944336 -0.16725236760277973\n",
      "Mean Squared Error: 0.5695109367370605 -0.28272397405283867\n",
      "------------------epoch: 101\n",
      "0.522851288318634 -0.20834272504049456\n",
      "Mean Squared Error: 0.5394874215126038 -0.2683347714615332\n",
      "------------------epoch: 102\n",
      "0.5221214294433594 -0.18883776129044372\n",
      "Mean Squared Error: 0.5466881394386292 -0.2519625170467992\n",
      "------------------epoch: 103\n",
      "0.5212581157684326 -0.20901232098925981\n",
      "Mean Squared Error: 0.5496494174003601 -0.32138625810201615\n",
      "------------------epoch: 104\n",
      "0.5173236727714539 -0.14539363089570756\n",
      "Mean Squared Error: 0.5393809676170349 -0.21992124489434373\n",
      "------------------epoch: 105\n",
      "0.5262758135795593 -0.23355765297980224\n",
      "Mean Squared Error: 0.5513817071914673 -0.28574675482031564\n",
      "------------------epoch: 106\n",
      "0.5165623426437378 -0.19492938450268782\n",
      "Mean Squared Error: 0.5318374037742615 -0.23156791494894113\n",
      "------------------epoch: 107\n",
      "0.516274094581604 -0.11759139671789343\n",
      "Mean Squared Error: 0.5435850620269775 -0.1812425529700623\n",
      "------------------epoch: 108\n",
      "0.5216019749641418 -0.21765388208620284\n",
      "Mean Squared Error: 0.5470848083496094 -0.27017500542045525\n",
      "------------------epoch: 109\n",
      "0.5213426947593689 -0.2157070188713428\n",
      "Mean Squared Error: 0.553007185459137 -0.2469645047340021\n",
      "------------------epoch: 110\n",
      "0.5139433741569519 -0.10806353244310563\n",
      "Mean Squared Error: 0.5527309775352478 -0.1878120420672691\n",
      "------------------epoch: 111\n",
      "0.5148171782493591 -0.1694353752702611\n",
      "Mean Squared Error: 0.5498844981193542 -0.2670589607454339\n",
      "------------------epoch: 112\n",
      "0.5096049308776855 -0.13285206176549336\n",
      "Mean Squared Error: 0.549376368522644 -0.21832897163222698\n",
      "------------------epoch: 113\n",
      "0.5104633569717407 -0.15497577819361075\n",
      "Mean Squared Error: 0.5478370785713196 -0.19179472695978195\n",
      "------------------epoch: 114\n",
      "0.5146898627281189 -0.2302998053898806\n",
      "Mean Squared Error: 0.5469108819961548 -0.29727849593683997\n",
      "------------------epoch: 115\n",
      "0.5153868198394775 -0.14384560617108977\n",
      "Mean Squared Error: 0.544166624546051 -0.18368263549903707\n",
      "------------------epoch: 116\n",
      "0.5144724249839783 -0.11556363928945101\n",
      "Mean Squared Error: 0.5514494776725769 -0.20876357175740146\n",
      "------------------epoch: 117\n",
      "0.5118812322616577 -0.18084346966211573\n",
      "Mean Squared Error: 0.5375707149505615 -0.27059740197104554\n",
      "------------------epoch: 118\n",
      "0.5031512379646301 -0.13871406689392995\n",
      "Mean Squared Error: 0.5342495441436768 -0.16949832905172357\n",
      "------------------epoch: 119\n",
      "0.5100566744804382 -0.08579099476114616\n",
      "Mean Squared Error: 0.5507355332374573 -0.1396852313575656\n",
      "------------------epoch: 120\n",
      "0.5170145630836487 -0.17085346905209642\n",
      "Mean Squared Error: 0.5565971732139587 -0.26461777432586553\n",
      "------------------epoch: 121\n",
      "0.5143860578536987 -0.09820776086910499\n",
      "Mean Squared Error: 0.5484635233879089 -0.175971027712988\n",
      "------------------epoch: 122\n",
      "0.5124067068099976 -0.13754624391897563\n",
      "Mean Squared Error: 0.5490120053291321 -0.2132039863405446\n",
      "------------------epoch: 123\n",
      "0.5085869431495667 -0.2519150217428081\n",
      "Mean Squared Error: 0.5499226450920105 -0.3399550631336048\n",
      "------------------epoch: 124\n",
      "0.5053383708000183 -0.1422170247672061\n",
      "Mean Squared Error: 0.550356924533844 -0.24352106694500764\n",
      "------------------epoch: 125\n",
      "0.5057060122489929 -0.03159835239574016\n",
      "Mean Squared Error: 0.5624457001686096 -0.11751077244588082\n",
      "------------------epoch: 126\n",
      "0.5042111873626709 -0.0913310648801231\n",
      "Mean Squared Error: 0.539674699306488 -0.17553551825857983\n",
      "------------------epoch: 127\n",
      "0.5052942037582397 -0.14494644040330562\n",
      "Mean Squared Error: 0.5433743596076965 -0.3018632080353336\n",
      "------------------epoch: 128\n",
      "0.5035244226455688 -0.09206495805577641\n",
      "Mean Squared Error: 0.5402793884277344 -0.19515992331178422\n",
      "------------------epoch: 129\n",
      "0.504568338394165 -0.07106693775063055\n",
      "Mean Squared Error: 0.5420065522193909 -0.15229910445877892\n",
      "------------------epoch: 130\n",
      "0.4988594353199005 -0.11741384803538613\n",
      "Mean Squared Error: 0.5477083325386047 -0.20599826511195052\n",
      "------------------epoch: 131\n",
      "0.5044375658035278 -0.12033774162311972\n",
      "Mean Squared Error: 0.5505874156951904 -0.2299853128608229\n",
      "------------------epoch: 132\n",
      "0.4960298538208008 -0.09975016540664705\n",
      "Mean Squared Error: 0.5491331219673157 -0.1949086322553908\n",
      "------------------epoch: 133\n",
      "0.5017899870872498 -0.11065598704800195\n",
      "Mean Squared Error: 0.5326876044273376 -0.18626980953713645\n",
      "------------------epoch: 134\n",
      "0.5034773945808411 -0.11318360523204385\n",
      "Mean Squared Error: 0.5380694270133972 -0.1727939324953971\n",
      "------------------epoch: 135\n",
      "0.4985244572162628 -0.05875264575982819\n",
      "Mean Squared Error: 0.5470655560493469 -0.17852041666407592\n",
      "------------------epoch: 136\n",
      "0.49740609526634216 -0.06874575968439411\n",
      "Mean Squared Error: 0.5304712653160095 -0.16383744921453536\n",
      "------------------epoch: 137\n",
      "0.5018475651741028 -0.10461634835795786\n",
      "Mean Squared Error: 0.5442805290222168 -0.1993917266810139\n",
      "------------------epoch: 138\n",
      "0.4970479905605316 -0.13449906623671648\n",
      "Mean Squared Error: 0.5325292944908142 -0.2152081291370358\n",
      "------------------epoch: 139\n",
      "0.4987229108810425 -0.0680598515569848\n",
      "Mean Squared Error: 0.5420026183128357 -0.15139200582579515\n",
      "------------------epoch: 140\n",
      "0.49939078092575073 -0.09660811396817848\n",
      "Mean Squared Error: 0.5456830859184265 -0.23905426462033996\n",
      "------------------epoch: 141\n",
      "0.4986021816730499 -0.050936102212179035\n",
      "Mean Squared Error: 0.537339985370636 -0.11935242878731\n",
      "------------------epoch: 142\n",
      "0.4973337948322296 -0.07509200420191187\n",
      "Mean Squared Error: 0.5449541211128235 -0.17528385901952204\n",
      "------------------epoch: 143\n",
      "0.4973054528236389 -0.08818965829972325\n",
      "Mean Squared Error: 0.5223034620285034 -0.1260370966367388\n",
      "------------------epoch: 144\n",
      "0.4938729405403137 -0.04013377109408234\n",
      "Mean Squared Error: 0.5326810479164124 -0.10948690478082534\n",
      "------------------epoch: 145\n",
      "0.5011281371116638 -0.09725104969208265\n",
      "Mean Squared Error: 0.5377023816108704 -0.18752810335238612\n",
      "------------------epoch: 146\n",
      "0.48633521795272827 -0.0813517714498917\n",
      "Mean Squared Error: 0.5376584529876709 -0.1681151998571495\n",
      "------------------epoch: 147\n",
      "0.4911341667175293 -0.05837295133421194\n",
      "Mean Squared Error: 0.5411604642868042 -0.17290400807061124\n",
      "------------------epoch: 148\n",
      "0.49341896176338196 -0.04484570061379611\n",
      "Mean Squared Error: 0.5370665788650513 -0.14580688834717082\n",
      "------------------epoch: 149\n",
      "0.4954029619693756 -0.003795549278171162\n",
      "Mean Squared Error: 0.5457375645637512 -0.1140127169486791\n",
      "------------------epoch: 150\n",
      "0.49486619234085083 -0.04795437726045426\n",
      "Mean Squared Error: 0.5457120537757874 -0.17057135508164056\n",
      "------------------epoch: 151\n",
      "0.48699504137039185 -0.05663221533705043\n",
      "Mean Squared Error: 0.534527599811554 -0.16057165363338366\n",
      "------------------epoch: 152\n",
      "0.49180614948272705 -0.08358985672977748\n",
      "Mean Squared Error: 0.5316997170448303 -0.14002818337493528\n",
      "------------------epoch: 153\n",
      "0.4908057749271393 -0.04708252195239693\n",
      "Mean Squared Error: 0.5336626768112183 -0.1380574830761765\n",
      "------------------epoch: 154\n",
      "0.4870831370353699 -0.03900994486995457\n",
      "Mean Squared Error: 0.5395945310592651 -0.15198830914633144\n",
      "------------------epoch: 155\n",
      "0.4801218807697296 -0.04411438728394179\n",
      "Mean Squared Error: 0.5393774509429932 -0.19034610866391422\n",
      "------------------epoch: 156\n",
      "0.4818827509880066 -0.038726136743628015\n",
      "Mean Squared Error: 0.5490319132804871 -0.17939387861898037\n",
      "------------------epoch: 157\n",
      "0.4898615777492523 -0.026010141414805732\n",
      "Mean Squared Error: 0.5328371524810791 -0.12186538775783795\n",
      "------------------epoch: 158\n",
      "0.485387921333313 0.017496279314748286\n",
      "Mean Squared Error: 0.5242577791213989 -0.09972717870180858\n",
      "------------------epoch: 159\n",
      "0.4842424690723419 -0.024356474625592872\n",
      "Mean Squared Error: 0.5292680263519287 -0.10673925918141447\n",
      "------------------epoch: 160\n",
      "0.48090660572052 -0.013250591399575073\n",
      "Mean Squared Error: 0.5253596305847168 -0.13482603825613548\n",
      "------------------epoch: 161\n",
      "0.4823910892009735 0.005981732678929763\n",
      "Mean Squared Error: 0.5502728223800659 -0.11763615366629421\n",
      "------------------epoch: 162\n",
      "0.4832836985588074 -0.008235023058320134\n",
      "Mean Squared Error: 0.5217533111572266 -0.10516752854467049\n",
      "------------------epoch: 163\n",
      "0.47861912846565247 -0.020659578348753538\n",
      "Mean Squared Error: 0.5424540638923645 -0.1395538073493492\n",
      "------------------epoch: 164\n",
      "0.4840187728404999 -0.05284055641237484\n",
      "Mean Squared Error: 0.5352180600166321 -0.17896522722517827\n",
      "------------------epoch: 165\n",
      "0.4850362241268158 -0.04899798126174448\n",
      "Mean Squared Error: 0.5301572680473328 -0.1620082704680601\n",
      "------------------epoch: 166\n",
      "0.4800826907157898 -0.023324845330859212\n",
      "Mean Squared Error: 0.534949541091919 -0.13223787697836054\n",
      "------------------epoch: 167\n",
      "0.4803335964679718 0.03226440350997084\n",
      "Mean Squared Error: 0.5315353274345398 -0.08359152466431263\n",
      "------------------epoch: 168\n",
      "0.48468920588493347 -0.01769840099128639\n",
      "Mean Squared Error: 0.5358276963233948 -0.15591048761357773\n",
      "------------------epoch: 169\n",
      "0.4780663847923279 -0.038259658318790635\n",
      "Mean Squared Error: 0.5383378267288208 -0.1703030010174762\n",
      "------------------epoch: 170\n",
      "0.48182156682014465 0.027171992711118698\n",
      "Mean Squared Error: 0.5412795543670654 -0.1055358488256386\n",
      "------------------epoch: 171\n",
      "0.47418659925460815 0.006276768447737502\n",
      "Mean Squared Error: 0.5351589322090149 -0.15184270337996586\n",
      "------------------epoch: 172\n",
      "0.4833872616291046 -0.03094034934936385\n",
      "Mean Squared Error: 0.5402588844299316 -0.1452908665755046\n",
      "------------------epoch: 173\n",
      "0.4810335338115692 0.05776021652183383\n",
      "Mean Squared Error: 0.5382782220840454 -0.08123250449287855\n",
      "------------------epoch: 174\n",
      "0.4795570969581604 -0.04342861772148798\n",
      "Mean Squared Error: 0.5286913514137268 -0.16613608972318605\n",
      "------------------epoch: 175\n",
      "0.475198358297348 -0.004782310734213091\n",
      "Mean Squared Error: 0.5319499373435974 -0.09928602714728041\n",
      "------------------epoch: 176\n",
      "0.4813253879547119 -0.015257518485845445\n",
      "Mean Squared Error: 0.5381402373313904 -0.14740490861022648\n",
      "------------------epoch: 177\n",
      "0.47804075479507446 -0.012874913973345947\n",
      "Mean Squared Error: 0.5252261757850647 -0.1757420553856044\n",
      "------------------epoch: 178\n",
      "0.47821226716041565 -0.022777054720110712\n",
      "Mean Squared Error: 0.533333420753479 -0.13036405748668778\n",
      "------------------epoch: 179\n",
      "0.4729768931865692 0.041257511686599524\n",
      "Mean Squared Error: 0.5351680517196655 -0.08900752171814896\n",
      "------------------epoch: 180\n",
      "0.4832303822040558 0.05120189610398185\n",
      "Mean Squared Error: 0.5361848473548889 -0.055637774572961485\n",
      "------------------epoch: 181\n",
      "0.4867417514324188 -0.005532903482510454\n",
      "Mean Squared Error: 0.5194401144981384 -0.12403475686596943\n",
      "------------------epoch: 182\n",
      "0.4792477786540985 -0.0507966387185097\n",
      "Mean Squared Error: 0.5299400091171265 -0.18476037669896317\n",
      "------------------epoch: 183\n",
      "0.48195788264274597 -0.03420090132500597\n",
      "Mean Squared Error: 0.5442655682563782 -0.18086262078823379\n",
      "------------------epoch: 184\n",
      "0.474007248878479 -0.03526284597695262\n",
      "Mean Squared Error: 0.5310183763504028 -0.19521933665708313\n",
      "------------------epoch: 185\n",
      "0.47437891364097595 0.0025192666255333673\n",
      "Mean Squared Error: 0.5381125211715698 -0.16073775084112585\n",
      "------------------epoch: 186\n",
      "0.4793001711368561 0.03908861912631467\n",
      "Mean Squared Error: 0.5155432224273682 -0.0526451622393691\n",
      "------------------epoch: 187\n",
      "0.4740987718105316 0.061962595830500344\n",
      "Mean Squared Error: 0.5246690511703491 -0.08289683553244709\n",
      "------------------epoch: 188\n",
      "0.4718886911869049 0.026743546848726374\n",
      "Mean Squared Error: 0.5403574705123901 -0.12062398178564937\n",
      "------------------epoch: 189\n",
      "0.479790061712265 -0.0075999164754674275\n",
      "Mean Squared Error: 0.5222743153572083 -0.15529947149730217\n",
      "------------------epoch: 190\n",
      "0.47240352630615234 0.019714119409720232\n",
      "Mean Squared Error: 0.5318817496299744 -0.10117264585964003\n",
      "------------------epoch: 191\n",
      "0.4685111343860626 0.030398323433946106\n",
      "Mean Squared Error: 0.524732768535614 -0.1114469248539709\n",
      "------------------epoch: 192\n",
      "0.4763249158859253 -0.03392647425400486\n",
      "Mean Squared Error: 0.5229606032371521 -0.14444892387719288\n",
      "------------------epoch: 193\n",
      "0.4720842242240906 0.0030109356603947868\n",
      "Mean Squared Error: 0.5259271860122681 -0.09042266460439041\n",
      "------------------epoch: 194\n",
      "0.47426602244377136 0.07814590620959283\n",
      "Mean Squared Error: 0.5374197363853455 -0.0639053733411925\n",
      "------------------epoch: 195\n",
      "0.47252845764160156 0.021004307333945538\n",
      "Mean Squared Error: 0.5284866094589233 -0.0836225380299973\n",
      "------------------epoch: 196\n",
      "0.4748258888721466 0.0058111029655640856\n",
      "Mean Squared Error: 0.5337794423103333 -0.13081048340900625\n",
      "------------------epoch: 197\n",
      "0.4751701354980469 0.03153475706694053\n",
      "Mean Squared Error: 0.546291172504425 -0.14271612716907178\n",
      "------------------epoch: 198\n",
      "0.46760550141334534 0.0473642974363776\n",
      "Mean Squared Error: 0.5413815379142761 -0.11730309978364528\n",
      "------------------epoch: 199\n",
      "0.4654753804206848 0.024605140245384627\n",
      "Mean Squared Error: 0.5230865478515625 -0.12866964709288875\n",
      "------------------epoch: 200\n",
      "0.46990966796875 -0.023690761828430107\n",
      "Mean Squared Error: 0.5279889106750488 -0.14689241918192342\n",
      "------------------epoch: 201\n",
      "0.4756249189376831 0.03930654158976443\n",
      "Mean Squared Error: 0.5402237176895142 -0.12016954255094592\n",
      "------------------epoch: 202\n",
      "0.46198567748069763 0.05654222838995471\n",
      "Mean Squared Error: 0.5425269603729248 -0.08829370031486361\n",
      "------------------epoch: 203\n",
      "0.47749900817871094 0.015763428058348072\n",
      "Mean Squared Error: 0.5297346711158752 -0.08982471358161925\n",
      "------------------epoch: 204\n",
      "0.4701336920261383 0.028438497511207972\n",
      "Mean Squared Error: 0.5425593852996826 -0.12275198816348287\n",
      "------------------epoch: 205\n",
      "0.47426459193229675 0.05045524849346539\n",
      "Mean Squared Error: 0.5296762585639954 -0.0795481249165495\n",
      "------------------epoch: 206\n",
      "0.47114720940589905 0.016714804875637146\n",
      "Mean Squared Error: 0.5264224410057068 -0.11732356219455053\n",
      "------------------epoch: 207\n",
      "0.47295746207237244 0.010754904454625236\n",
      "Mean Squared Error: 0.5355668663978577 -0.15682631573614203\n",
      "------------------epoch: 208\n",
      "0.4704039692878723 0.041781707743901\n",
      "Mean Squared Error: 0.543133020401001 -0.09843746242905049\n",
      "------------------epoch: 209\n",
      "0.47387707233428955 0.048061401500304024\n",
      "Mean Squared Error: 0.5338427424430847 -0.09943848868965532\n",
      "------------------epoch: 210\n",
      "0.46522489190101624 -0.015507315229523533\n",
      "Mean Squared Error: 0.5268609523773193 -0.16751893908663096\n",
      "------------------epoch: 211\n",
      "0.4640629291534424 0.023641274988160155\n",
      "Mean Squared Error: 0.5288525223731995 -0.12646198561814792\n",
      "------------------epoch: 212\n",
      "0.4702706038951874 0.08301216216607588\n",
      "Mean Squared Error: 0.541493833065033 -0.034024585104308835\n",
      "------------------epoch: 213\n",
      "0.4631291627883911 0.10309695190625723\n",
      "Mean Squared Error: 0.5268490314483643 -0.026351131579502196\n",
      "------------------epoch: 214\n",
      "0.46759435534477234 0.025805951484923373\n",
      "Mean Squared Error: 0.5194213390350342 -0.08458491550742608\n",
      "------------------epoch: 215\n",
      "0.4576750099658966 0.051680338735414\n",
      "Mean Squared Error: 0.5235728025436401 -0.09636316935224265\n",
      "------------------epoch: 216\n",
      "0.45850664377212524 0.10872415429512461\n",
      "Mean Squared Error: 0.5398597121238708 -0.05671255030891409\n",
      "------------------epoch: 217\n",
      "0.4716728627681732 0.06351036223259521\n",
      "Mean Squared Error: 0.5327179431915283 -0.06741332796534238\n",
      "------------------epoch: 218\n",
      "0.4676196575164795 -0.004830165195457425\n",
      "Mean Squared Error: 0.5341338515281677 -0.17252085281967888\n",
      "------------------epoch: 219\n",
      "0.4627090394496918 0.011570907293802501\n",
      "Mean Squared Error: 0.5228129029273987 -0.1449832403723823\n",
      "------------------epoch: 220\n",
      "0.46089768409729004 0.07792900299456806\n",
      "Mean Squared Error: 0.533420741558075 -0.09988062339324921\n",
      "------------------epoch: 221\n",
      "0.46116459369659424 0.10931764564593616\n",
      "Mean Squared Error: 0.5324862599372864 -0.08327722902862056\n",
      "------------------epoch: 222\n",
      "0.46117252111434937 0.022659042353832426\n",
      "Mean Squared Error: 0.5237991213798523 -0.1567366881731611\n",
      "------------------epoch: 223\n",
      "0.46743664145469666 -0.015812520470148028\n",
      "Mean Squared Error: 0.50681471824646 -0.09423905966164292\n",
      "------------------epoch: 224\n",
      "0.4592002332210541 0.10553750532377348\n",
      "Mean Squared Error: 0.5277145504951477 -0.0750608358365541\n",
      "------------------epoch: 225\n",
      "0.4646216928958893 0.12932087786208102\n",
      "Mean Squared Error: 0.5345109105110168 -0.028439453223680466\n",
      "------------------epoch: 226\n",
      "0.45885971188545227 0.04058560179820592\n",
      "Mean Squared Error: 0.5300939679145813 -0.12948983442257211\n",
      "------------------epoch: 227\n",
      "0.464589387178421 0.05690918697851188\n",
      "Mean Squared Error: 0.5132656097412109 -0.04875084304689192\n",
      "------------------epoch: 228\n",
      "0.4651722311973572 0.11548816396821415\n",
      "Mean Squared Error: 0.5141449570655823 -0.006914955343200191\n",
      "------------------epoch: 229\n",
      "0.45616263151168823 0.10869516255322265\n",
      "Mean Squared Error: 0.5336701273918152 -0.07933885664893836\n",
      "------------------epoch: 230\n",
      "0.4543595016002655 0.05422378908750336\n",
      "Mean Squared Error: 0.5231482982635498 -0.11355200617715111\n",
      "------------------epoch: 231\n",
      "0.4570086598396301 0.04017998078999552\n",
      "Mean Squared Error: 0.5316005349159241 -0.17138802602726888\n",
      "------------------epoch: 232\n",
      "0.45825520157814026 0.043807670591178294\n",
      "Mean Squared Error: 0.5225486159324646 -0.1272327654896419\n",
      "------------------epoch: 233\n",
      "0.45834434032440186 0.08393369077627033\n",
      "Mean Squared Error: 0.5275920033454895 -0.049514559679965764\n",
      "------------------epoch: 234\n",
      "0.4510636329650879 0.11540378489157432\n",
      "Mean Squared Error: 0.5253515243530273 -0.03617086163135341\n",
      "------------------epoch: 235\n",
      "0.45603978633880615 0.13000929023106833\n",
      "Mean Squared Error: 0.5212154984474182 0.004908900660467563\n",
      "------------------epoch: 236\n",
      "0.4595678150653839 0.08828550664734636\n",
      "Mean Squared Error: 0.5257863402366638 -0.055657939091089625\n",
      "------------------epoch: 237\n",
      "0.45415160059928894 0.07974998242072628\n",
      "Mean Squared Error: 0.5306631922721863 -0.09085131094395882\n",
      "------------------epoch: 238\n",
      "0.457963764667511 0.0589363084157869\n",
      "Mean Squared Error: 0.5179151296615601 -0.07366714748293113\n",
      "------------------epoch: 239\n",
      "0.4557686448097229 0.056540509327485\n",
      "Mean Squared Error: 0.5256390571594238 -0.09315521222180556\n",
      "------------------epoch: 240\n",
      "0.451984703540802 0.10855841844957126\n",
      "Mean Squared Error: 0.5252089500427246 -0.04313721577559049\n",
      "------------------epoch: 241\n",
      "0.4550539553165436 0.1232571500068621\n",
      "Mean Squared Error: 0.5276353359222412 -0.05545048013995557\n",
      "------------------epoch: 242\n",
      "0.4569101631641388 0.11559428474034505\n",
      "Mean Squared Error: 0.521541953086853 -0.034992677284639395\n",
      "------------------epoch: 243\n",
      "0.4553641676902771 0.06773290388994102\n",
      "Mean Squared Error: 0.5239492654800415 -0.08113870548336455\n",
      "------------------epoch: 244\n",
      "0.45905768871307373 0.07852603135293801\n",
      "Mean Squared Error: 0.5214303135871887 -0.04068046205621756\n",
      "------------------epoch: 245\n",
      "0.45548301935195923 0.0942674070694487\n",
      "Mean Squared Error: 0.5240886807441711 -0.03670009149549536\n",
      "------------------epoch: 246\n",
      "0.4540960192680359 0.09779079518263079\n",
      "Mean Squared Error: 0.5214354991912842 -0.03964807221690858\n",
      "------------------epoch: 247\n",
      "0.45582646131515503 0.0849672325462889\n",
      "Mean Squared Error: 0.5376564264297485 -0.082339960170148\n",
      "------------------epoch: 248\n",
      "0.4593769609928131 0.05346959750076685\n",
      "Mean Squared Error: 0.5191442966461182 -0.08028229044506152\n",
      "------------------epoch: 249\n",
      "0.4502396285533905 0.10338407660196025\n",
      "Mean Squared Error: 0.5311862230300903 -0.031130370068300106\n",
      "------------------epoch: 250\n",
      "0.4578177034854889 0.1254535745528622\n",
      "Mean Squared Error: 0.5325340628623962 -0.012948221901792012\n",
      "------------------epoch: 251\n",
      "0.4466439187526703 0.10978186284164781\n",
      "Mean Squared Error: 0.5260975360870361 -0.10876107503659571\n",
      "------------------epoch: 252\n",
      "0.4510190486907959 0.09473487687086724\n",
      "Mean Squared Error: 0.5189621448516846 -0.08037735693807546\n",
      "------------------epoch: 253\n",
      "0.4505857229232788 0.08640449906016145\n",
      "Mean Squared Error: 0.5200619697570801 -0.05548562904963905\n",
      "------------------epoch: 254\n",
      "0.45556411147117615 0.08005200097293796\n",
      "Mean Squared Error: 0.5330567955970764 -0.08783269778454139\n",
      "------------------epoch: 255\n",
      "0.4523119628429413 0.09042972491224444\n",
      "Mean Squared Error: 0.5094684362411499 -0.03650960954612126\n",
      "------------------epoch: 256\n",
      "0.45342159271240234 0.10929677772341462\n",
      "Mean Squared Error: 0.5316498279571533 -0.031878457587489084\n",
      "------------------epoch: 257\n",
      "0.45568764209747314 0.1235676929643651\n",
      "Mean Squared Error: 0.5276045203208923 -0.044033209080167834\n",
      "------------------epoch: 258\n",
      "0.4560735821723938 0.11973832745057855\n",
      "Mean Squared Error: 0.5193954110145569 -0.0018012701787775143\n",
      "------------------epoch: 259\n",
      "0.45468083024024963 0.060516728286134414\n",
      "Mean Squared Error: 0.5150225162506104 -0.06741083933525438\n",
      "------------------epoch: 260\n",
      "0.4525260031223297 0.07829478743574292\n",
      "Mean Squared Error: 0.526630163192749 -0.08808653054392623\n",
      "------------------epoch: 261\n",
      "0.45294198393821716 0.07630334748828549\n",
      "Mean Squared Error: 0.5223348736763 -0.07561540425029456\n",
      "------------------epoch: 262\n",
      "0.4511628746986389 0.0855524701123398\n",
      "Mean Squared Error: 0.522453248500824 -0.07634030702715378\n",
      "------------------epoch: 263\n",
      "0.4439699351787567 0.1424374926154659\n",
      "Mean Squared Error: 0.5285394191741943 -0.054687117468276814\n",
      "------------------epoch: 264\n",
      "0.4442861080169678 0.1472689802899526\n",
      "Mean Squared Error: 0.5247435569763184 -0.03717316907526347\n",
      "------------------epoch: 265\n",
      "0.4457450807094574 0.1591363541235814\n",
      "Mean Squared Error: 0.5379379987716675 -0.004298100443131947\n",
      "------------------epoch: 266\n",
      "0.44658127427101135 0.14127310424238781\n",
      "Mean Squared Error: 0.5135955810546875 -0.012111935621317516\n",
      "------------------epoch: 267\n",
      "0.45350581407546997 0.09007197534781974\n",
      "Mean Squared Error: 0.528715968132019 -0.05591873429196692\n",
      "------------------epoch: 268\n",
      "0.44151926040649414 0.10431020862152274\n",
      "Mean Squared Error: 0.5225783586502075 -0.10461777742347911\n",
      "------------------epoch: 269\n",
      "0.4424346089363098 0.1423187979633881\n",
      "Mean Squared Error: 0.5351002216339111 -0.04817048508462918\n",
      "------------------epoch: 270\n",
      "0.4502089023590088 0.12542904187566795\n",
      "Mean Squared Error: 0.49517422914505005 0.03610713659115539\n",
      "------------------epoch: 271\n",
      "0.44374844431877136 0.12299684724472704\n",
      "Mean Squared Error: 0.5290383696556091 -0.03078056844736632\n",
      "------------------epoch: 272\n",
      "0.4501299262046814 0.07492903563454578\n",
      "Mean Squared Error: 0.5088971257209778 -0.05830413063434614\n",
      "------------------epoch: 273\n",
      "0.4438956677913666 0.11117040322639837\n",
      "Mean Squared Error: 0.521938145160675 -0.04908746921681928\n",
      "------------------epoch: 274\n",
      "0.44655466079711914 0.12403548339477688\n",
      "Mean Squared Error: 0.519902229309082 -0.0207065634471022\n",
      "------------------epoch: 275\n",
      "0.44362956285476685 0.14676380098203623\n",
      "Mean Squared Error: 0.5284743309020996 0.011824251916277229\n",
      "------------------epoch: 276\n",
      "0.44889935851097107 0.12877154981933192\n",
      "Mean Squared Error: 0.5192136764526367 -0.030130546159750526\n",
      "------------------epoch: 277\n",
      "0.4458058774471283 0.1314663103540693\n",
      "Mean Squared Error: 0.5238904356956482 -0.06657777051047753\n",
      "------------------epoch: 278\n",
      "0.4412638247013092 0.12798145656139603\n",
      "Mean Squared Error: 0.541790783405304 -0.08604162751911293\n",
      "------------------epoch: 279\n",
      "0.44401466846466064 0.11114121623791773\n",
      "Mean Squared Error: 0.5267549753189087 -0.04701100929363\n",
      "------------------epoch: 280\n",
      "0.4482337236404419 0.13394037859540997\n",
      "Mean Squared Error: 0.5326530337333679 -0.04803028455853453\n",
      "------------------epoch: 281\n",
      "0.446711003780365 0.14205034693629992\n",
      "Mean Squared Error: 0.5233761668205261 -0.030670565968548003\n",
      "------------------epoch: 282\n",
      "0.44461867213249207 0.10262799998632988\n",
      "Mean Squared Error: 0.5190962553024292 -0.0548829007567011\n",
      "------------------epoch: 283\n",
      "0.4442058801651001 0.12868867504298276\n",
      "Mean Squared Error: 0.5100644826889038 -0.01887743372044315\n",
      "------------------epoch: 284\n",
      "0.44311556220054626 0.1391214889443223\n",
      "Mean Squared Error: 0.5169014930725098 -0.059547566713205935\n",
      "------------------epoch: 285\n",
      "0.4458772838115692 0.12079894747327258\n",
      "Mean Squared Error: 0.5356130003929138 -0.07579098947248708\n",
      "------------------epoch: 286\n",
      "0.44482627511024475 0.14708296018517397\n",
      "Mean Squared Error: 0.5377001166343689 -0.051564990022075596\n",
      "------------------epoch: 287\n",
      "0.4453396797180176 0.13637068273645636\n",
      "Mean Squared Error: 0.5249680876731873 -0.02643488186320586\n",
      "------------------epoch: 288\n",
      "0.44962459802627563 0.13708348312340235\n",
      "Mean Squared Error: 0.5365189909934998 -0.03072655593946738\n",
      "------------------epoch: 289\n",
      "0.44361263513565063 0.0918682400394788\n",
      "Mean Squared Error: 0.5157514810562134 -0.07466661007705966\n",
      "------------------epoch: 290\n",
      "0.4348585903644562 0.12835048214402267\n",
      "Mean Squared Error: 0.5341323018074036 -0.056938651791836214\n",
      "------------------epoch: 291\n",
      "0.43750113248825073 0.15067925093693946\n",
      "Mean Squared Error: 0.5186395049095154 -0.02862310758154285\n",
      "------------------epoch: 292\n",
      "0.43526601791381836 0.17958840484390537\n",
      "Mean Squared Error: 0.5217335224151611 0.014545352759836594\n",
      "------------------epoch: 293\n",
      "0.4462738037109375 0.15053240534478662\n",
      "Mean Squared Error: 0.5311856865882874 -0.040134348823385846\n",
      "------------------epoch: 294\n",
      "0.44455474615097046 0.14959461965903165\n",
      "Mean Squared Error: 0.5159439444541931 -0.063734127506061\n",
      "------------------epoch: 295\n",
      "0.4421914219856262 0.11940966448205759\n",
      "Mean Squared Error: 0.5041539072990417 -0.03271728805862906\n",
      "------------------epoch: 296\n",
      "0.4439539909362793 0.12004267862998108\n",
      "Mean Squared Error: 0.5073789954185486 -0.03958382003882277\n",
      "------------------epoch: 297\n",
      "0.44415631890296936 0.13285546476883836\n",
      "Mean Squared Error: 0.5191860795021057 -0.050501099092052026\n",
      "------------------epoch: 298\n",
      "0.443398654460907 0.10820898877092622\n",
      "Mean Squared Error: 0.5220411419868469 -0.0742018033879086\n",
      "------------------epoch: 299\n",
      "0.44053906202316284 0.11607637883486988\n",
      "Mean Squared Error: 0.5187949538230896 -0.03971664779740358\n"
     ]
    }
   ],
   "source": [
    "#optimizer = optim.SGD(GNN.parameters(), lr=0.01,momentum = 0.9,weight_decay=0.00005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.9)\n",
    "for epoch in range(300):\n",
    "    GNN.train()\n",
    "    predictions = GNN(graph, node_features)\n",
    "    loss = loss_fn(predictions[idx_train], labels[idx_train])\n",
    "    r2_train = r2_fun(predictions[idx_train], labels[idx_train])\n",
    "    print('------------------epoch:', epoch)\n",
    "    print(loss.item(),r2_train.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    mse = F.mse_loss(predictions[idx_val], labels[idx_val])\n",
    "    r1 = r2_fun(predictions[idx_val], labels[idx_val])\n",
    "    print('Mean Squared Error:', mse.item(), r1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6229f5-d115-448c-9f68-01857c96a813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23140, 1)\n",
      "Mean Squared Error: 0.5084453670515263 3.4681451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "GNN.eval()\n",
    "output= GNN(graph,node_features)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "s_y = dataset.ss_y\n",
    "y_pre = s_y.inverse_transform(output.detach().numpy())\n",
    "y_ture = s_y.inverse_transform(labels.detach().numpy())\n",
    "print(y_pre.shape)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_ture[idx_test], y_pre[idx_test])\n",
    "mse = mean_squared_error(y_ture[idx_test], y_pre[idx_test])\n",
    "mae = mean_absolute_error(y_ture[idx_test], y_pre[idx_test])\n",
    "\n",
    "print(\"Mean Squared Error:\", r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198b60ae-4b7b-42eb-bd50-8c7baccaa894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--fastmode', action='store_true', default=False,\n",
    "                    help='Validate during training pass.')\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=200,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.008,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-5,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--num_heads', type=int, default=8,\n",
    "                    help='Attention heads.')\n",
    "parser.add_argument('--l_nums', type=int, default=3,\n",
    "                    help='Number of EGATLayer.')\n",
    "parser.add_argument('--lamda', type=float, default=0.85,\n",
    "                    help='The node feature ratio.')\n",
    "args =parser.parse_known_args()[0]\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "# Load data\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    device = torch.device('cuda:0')\n",
    "# Model and optimizer\n",
    "model = EGAT(node_feats=node_features.shape[1],\n",
    "            edge_feats=edge_features.shape[1],\n",
    "            f_h = 128,\n",
    "            f_e = 128,\n",
    "            lamda = args.lamda,\n",
    "            num_heads = args.num_heads,\n",
    "            dropout=args.dropout,\n",
    "            pred_hid = 128, \n",
    "            l_num = args.l_nums, \n",
    "             )\n",
    "optimizer = optim.Adam(model.parameters(),lr=args.lr, weight_decay=args.weight_decay)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01,momentum = 0.9,weight_decay=args.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.9)\n",
    "if args.cuda:\n",
    "    #print(\"pppppppppppppppppppppppppppp\")\n",
    "    graph = graph.to(device)\n",
    "    model = model.to(device)\n",
    "    node_features = node_features.to(device)\n",
    "    edge_features = edge_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "    idx_train = idx_train.to(device)\n",
    "    idx_val = idx_val.to(device)\n",
    "    idx_test = idx_test.to(device)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(graph, node_features, edge_features)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    loss_train = loss_func(output[idx_train], labels[idx_train])\n",
    "    print(\"loss------------------------------------------------------111\")\n",
    "    r2_train = r2_fun(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if not args.fastmode:\n",
    "        model.eval()\n",
    "        output = model(graph, node_features, edge_features)\n",
    "\n",
    "    #loss_val = F.cross_entropy(output[idx_val], labels[idx_val]).to(device)\n",
    "    loss_val = loss_func(output[idx_val],labels[idx_val])\n",
    "    r2_val = r2_fun(output[idx_val], labels[idx_val])\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'r2_train: {:.4f}'.format(r2_train.item()),\n",
    "         'r2_val: {:.4f}'.format(r2_val.item()))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(graph, node_features, edge_features)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    loss_test = loss_func(output[idx_test], labels[idx_test])\n",
    "    r2_test = r2_fun(output[idx_test], labels[idx_test])\n",
    "    \n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "         \"r2_loss= {:.4f}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e07b1d-a4a9-4999-bcaa-797f501f0435",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0001 loss_train: 0.9490 loss_val: 0.8696 r2_train: -409.1757 r2_val: -0.7606\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0002 loss_train: 0.9147 loss_val: 1.5039 r2_train: -0.8058 r2_val: -2.6583\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0003 loss_train: 1.5906 loss_val: 0.7314 r2_train: -2.7244 r2_val: -3.6507\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0004 loss_train: 0.7736 loss_val: 0.7015 r2_train: -3.8817 r2_val: -0.9483\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0005 loss_train: 0.7542 loss_val: 0.6775 r2_train: -1.1235 r2_val: -2.3396\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0006 loss_train: 0.7349 loss_val: 0.6972 r2_train: -2.5789 r2_val: -3.7883\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0007 loss_train: 0.7498 loss_val: 0.6643 r2_train: -4.1988 r2_val: -2.3476\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0008 loss_train: 0.7163 loss_val: 0.6492 r2_train: -2.6685 r2_val: -0.9907\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0009 loss_train: 0.6991 loss_val: 0.6535 r2_train: -1.1556 r2_val: -0.6590\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0010 loss_train: 0.7021 loss_val: 0.6506 r2_train: -0.7975 r2_val: -1.2758\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0011 loss_train: 0.6952 loss_val: 0.6581 r2_train: -1.4495 r2_val: -1.9982\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0012 loss_train: 0.6964 loss_val: 0.6435 r2_train: -2.2582 r2_val: -2.1449\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0013 loss_train: 0.6800 loss_val: 0.6497 r2_train: -2.3158 r2_val: -1.1472\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0014 loss_train: 0.6875 loss_val: 0.6723 r2_train: -1.3525 r2_val: -0.4545\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0015 loss_train: 0.7180 loss_val: 0.6190 r2_train: -0.6255 r2_val: -0.6872\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0016 loss_train: 0.6668 loss_val: 0.6146 r2_train: -0.7548 r2_val: -1.1855\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0017 loss_train: 0.6561 loss_val: 0.6163 r2_train: -1.2782 r2_val: -1.5163\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0018 loss_train: 0.6610 loss_val: 0.6177 r2_train: -1.8075 r2_val: -1.3190\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0019 loss_train: 0.6570 loss_val: 0.5991 r2_train: -1.5734 r2_val: -0.8772\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0020 loss_train: 0.6459 loss_val: 0.6080 r2_train: -0.9876 r2_val: -0.6661\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0021 loss_train: 0.6513 loss_val: 0.5942 r2_train: -0.7944 r2_val: -0.6923\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0022 loss_train: 0.6417 loss_val: 0.5994 r2_train: -0.8490 r2_val: -0.7243\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0023 loss_train: 0.6442 loss_val: 0.5888 r2_train: -0.8166 r2_val: -0.9329\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0024 loss_train: 0.6324 loss_val: 0.5928 r2_train: -1.2056 r2_val: -0.8433\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0025 loss_train: 0.6264 loss_val: 0.5843 r2_train: -0.8742 r2_val: -0.6004\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0026 loss_train: 0.6259 loss_val: 0.5796 r2_train: -0.6736 r2_val: -0.4254\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0027 loss_train: 0.6194 loss_val: 0.5753 r2_train: -0.5516 r2_val: -0.7653\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0028 loss_train: 0.6212 loss_val: 0.5947 r2_train: -0.8145 r2_val: -1.2194\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0029 loss_train: 0.6329 loss_val: 0.5638 r2_train: -1.3804 r2_val: -0.6917\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0030 loss_train: 0.6067 loss_val: 0.5827 r2_train: -0.8671 r2_val: -0.2573\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0031 loss_train: 0.6310 loss_val: 0.5587 r2_train: -0.3118 r2_val: -0.7058\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0032 loss_train: 0.6016 loss_val: 0.5776 r2_train: -0.8354 r2_val: -1.0534\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0033 loss_train: 0.6100 loss_val: 0.5535 r2_train: -1.2043 r2_val: -0.4985\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0034 loss_train: 0.5935 loss_val: 0.5480 r2_train: -0.5915 r2_val: -0.2129\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0035 loss_train: 0.6080 loss_val: 0.5980 r2_train: -0.3490 r2_val: -0.8310\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0036 loss_train: 0.6019 loss_val: 0.5896 r2_train: -0.7760 r2_val: -1.0498\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0037 loss_train: 0.6191 loss_val: 0.5408 r2_train: -1.0248 r2_val: -0.6024\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0038 loss_train: 0.5769 loss_val: 0.5549 r2_train: -0.7248 r2_val: -0.2294\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0039 loss_train: 0.6085 loss_val: 0.5578 r2_train: -0.2764 r2_val: -0.3576\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0040 loss_train: 0.6010 loss_val: 0.5486 r2_train: -0.5031 r2_val: -0.8659\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0041 loss_train: 0.5848 loss_val: 0.5666 r2_train: -0.9089 r2_val: -1.0900\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0042 loss_train: 0.5929 loss_val: 0.5425 r2_train: -1.0836 r2_val: -0.6784\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0043 loss_train: 0.5769 loss_val: 0.5284 r2_train: -0.7506 r2_val: -0.5445\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0044 loss_train: 0.5641 loss_val: 0.5231 r2_train: -0.6390 r2_val: -0.2264\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0045 loss_train: 0.5612 loss_val: 0.5192 r2_train: -0.2688 r2_val: 0.0650\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0046 loss_train: 0.5766 loss_val: 0.5282 r2_train: -0.0538 r2_val: 0.0092\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0047 loss_train: 0.5769 loss_val: 0.5440 r2_train: -0.1181 r2_val: -0.4911\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0048 loss_train: 0.5730 loss_val: 0.5540 r2_train: -0.5344 r2_val: -0.4570\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0049 loss_train: 0.5770 loss_val: 0.5646 r2_train: -0.7120 r2_val: -0.5706\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0050 loss_train: 0.5774 loss_val: 0.5165 r2_train: -0.5685 r2_val: -0.6615\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0051 loss_train: 0.5500 loss_val: 0.5511 r2_train: -0.7294 r2_val: -0.5527\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0052 loss_train: 0.5705 loss_val: 0.5220 r2_train: -0.6759 r2_val: -0.2116\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0053 loss_train: 0.6277 loss_val: 0.5648 r2_train: -0.3752 r2_val: -0.2781\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0054 loss_train: 0.5437 loss_val: 0.5952 r2_train: -0.2532 r2_val: 0.0171\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0055 loss_train: 0.5955 loss_val: 0.5710 r2_train: 0.0132 r2_val: -0.8301\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0056 loss_train: 0.6078 loss_val: 0.5336 r2_train: -1.2215 r2_val: -1.5050\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0057 loss_train: 0.5901 loss_val: 0.5376 r2_train: -2.1073 r2_val: -0.7267\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0058 loss_train: 0.5910 loss_val: 0.5154 r2_train: -0.6354 r2_val: -0.4445\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0059 loss_train: 0.5556 loss_val: 0.4853 r2_train: -0.4556 r2_val: -0.2041\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0060 loss_train: 0.5781 loss_val: 0.5292 r2_train: -0.5516 r2_val: -0.1661\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0061 loss_train: 0.5684 loss_val: 0.5147 r2_train: -0.3535 r2_val: 0.0743\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0062 loss_train: 0.5653 loss_val: 0.5052 r2_train: 0.0059 r2_val: 0.1140\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0063 loss_train: 0.5515 loss_val: 0.5093 r2_train: 0.0119 r2_val: -0.2199\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0064 loss_train: 0.5625 loss_val: 0.4943 r2_train: -0.5294 r2_val: -0.3723\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0065 loss_train: 0.5461 loss_val: 0.4890 r2_train: -0.6242 r2_val: -0.3782\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0066 loss_train: 0.5248 loss_val: 0.5062 r2_train: -0.4144 r2_val: -0.1388\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0067 loss_train: 0.5467 loss_val: 0.4851 r2_train: -0.3351 r2_val: -0.0977\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0068 loss_train: 0.5242 loss_val: 0.5160 r2_train: -0.1768 r2_val: -0.0379\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0069 loss_train: 0.5345 loss_val: 0.5064 r2_train: -0.1662 r2_val: -0.0083\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0070 loss_train: 0.5347 loss_val: 0.4880 r2_train: -0.0736 r2_val: -0.0777\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0071 loss_train: 0.5211 loss_val: 0.4873 r2_train: -0.0819 r2_val: -0.3425\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0072 loss_train: 0.5113 loss_val: 0.5117 r2_train: -0.3649 r2_val: -0.3664\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0073 loss_train: 0.5701 loss_val: 0.4987 r2_train: -0.5562 r2_val: -0.5156\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0074 loss_train: 0.5486 loss_val: 0.5000 r2_train: -0.7747 r2_val: -0.1627\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0075 loss_train: 0.5389 loss_val: 0.4828 r2_train: -0.2661 r2_val: 0.0931\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0076 loss_train: 0.5103 loss_val: 0.5211 r2_train: -0.0084 r2_val: 0.1965\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0077 loss_train: 0.5347 loss_val: 0.4871 r2_train: 0.1390 r2_val: -0.0064\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0078 loss_train: 0.5165 loss_val: 0.4915 r2_train: -0.1227 r2_val: -0.1082\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0079 loss_train: 0.5162 loss_val: 0.5078 r2_train: -0.2679 r2_val: -0.2602\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0080 loss_train: 0.5067 loss_val: 0.4787 r2_train: -0.1808 r2_val: 0.0736\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0081 loss_train: 0.5187 loss_val: 0.4815 r2_train: -0.1351 r2_val: -0.0604\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0082 loss_train: 0.5319 loss_val: 0.4807 r2_train: -0.1583 r2_val: -0.3461\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0083 loss_train: 0.5028 loss_val: 0.4748 r2_train: -0.4590 r2_val: -0.3519\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0084 loss_train: 0.5015 loss_val: 0.4661 r2_train: -0.3946 r2_val: -0.0469\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0085 loss_train: 0.4924 loss_val: 0.4686 r2_train: -0.0970 r2_val: 0.2014\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0086 loss_train: 0.4910 loss_val: 0.4744 r2_train: 0.1500 r2_val: 0.2055\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0087 loss_train: 0.4953 loss_val: 0.4603 r2_train: 0.2295 r2_val: 0.0656\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0088 loss_train: 0.4812 loss_val: 0.4564 r2_train: 0.0526 r2_val: 0.0123\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0089 loss_train: 0.4853 loss_val: 0.4576 r2_train: -0.1333 r2_val: -0.0829\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0090 loss_train: 0.4983 loss_val: 0.4689 r2_train: -0.2057 r2_val: -0.0264\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0091 loss_train: 0.4835 loss_val: 0.4718 r2_train: -0.1572 r2_val: -0.0115\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0092 loss_train: 0.5095 loss_val: 0.4570 r2_train: -0.0314 r2_val: 0.0112\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0093 loss_train: 0.4767 loss_val: 0.4642 r2_train: -0.0155 r2_val: -0.0075\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0094 loss_train: 0.4853 loss_val: 0.4722 r2_train: -0.0466 r2_val: -0.0890\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0095 loss_train: 0.5044 loss_val: 0.4536 r2_train: -0.1946 r2_val: 0.0278\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0096 loss_train: 0.4817 loss_val: 0.4763 r2_train: -0.0611 r2_val: 0.1573\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0097 loss_train: 0.4844 loss_val: 0.4927 r2_train: 0.0698 r2_val: 0.2640\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0098 loss_train: 0.4830 loss_val: 0.4578 r2_train: 0.2085 r2_val: 0.2100\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0099 loss_train: 0.4775 loss_val: 0.4517 r2_train: 0.1587 r2_val: -0.0367\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0100 loss_train: 0.4669 loss_val: 0.4752 r2_train: -0.0108 r2_val: -0.3577\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0101 loss_train: 0.4936 loss_val: 0.4573 r2_train: -0.3986 r2_val: -0.1991\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0102 loss_train: 0.4771 loss_val: 0.4513 r2_train: -0.2768 r2_val: 0.0180\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0103 loss_train: 0.4619 loss_val: 0.4701 r2_train: 0.0945 r2_val: 0.2757\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0104 loss_train: 0.4730 loss_val: 0.4705 r2_train: 0.2005 r2_val: 0.2054\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0105 loss_train: 0.4955 loss_val: 0.4442 r2_train: 0.1700 r2_val: 0.0821\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0106 loss_train: 0.4658 loss_val: 0.4643 r2_train: 0.0351 r2_val: -0.1778\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0107 loss_train: 0.4638 loss_val: 0.4607 r2_train: -0.1257 r2_val: -0.1517\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0108 loss_train: 0.4713 loss_val: 0.4539 r2_train: -0.1867 r2_val: 0.0326\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0109 loss_train: 0.4631 loss_val: 0.4428 r2_train: -0.0480 r2_val: 0.1498\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0110 loss_train: 0.4651 loss_val: 0.4555 r2_train: 0.1677 r2_val: 0.2962\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0111 loss_train: 0.4559 loss_val: 0.4497 r2_train: 0.2553 r2_val: 0.2257\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0112 loss_train: 0.4533 loss_val: 0.4434 r2_train: 0.2243 r2_val: 0.0241\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0113 loss_train: 0.4494 loss_val: 0.4433 r2_train: 0.0174 r2_val: -0.0926\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0114 loss_train: 0.4477 loss_val: 0.4504 r2_train: -0.0518 r2_val: -0.0080\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0115 loss_train: 0.4596 loss_val: 0.4574 r2_train: -0.0740 r2_val: 0.1953\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0116 loss_train: 0.4504 loss_val: 0.4402 r2_train: 0.2068 r2_val: 0.2416\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0117 loss_train: 0.4482 loss_val: 0.4426 r2_train: 0.2873 r2_val: 0.1564\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0118 loss_train: 0.4414 loss_val: 0.4404 r2_train: 0.2248 r2_val: 0.0673\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0119 loss_train: 0.4531 loss_val: 0.4527 r2_train: -0.0337 r2_val: -0.0347\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0120 loss_train: 0.4503 loss_val: 0.4469 r2_train: -0.0872 r2_val: 0.1378\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0121 loss_train: 0.4491 loss_val: 0.4369 r2_train: 0.1385 r2_val: 0.2589\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0122 loss_train: 0.4351 loss_val: 0.4459 r2_train: 0.2829 r2_val: 0.2847\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0123 loss_train: 0.4489 loss_val: 0.4359 r2_train: 0.2228 r2_val: 0.1743\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0124 loss_train: 0.4365 loss_val: 0.4313 r2_train: 0.1652 r2_val: 0.0335\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0125 loss_train: 0.4314 loss_val: 0.4387 r2_train: 0.1042 r2_val: 0.0868\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0126 loss_train: 0.4402 loss_val: 0.4301 r2_train: 0.0607 r2_val: 0.1184\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0127 loss_train: 0.4267 loss_val: 0.4303 r2_train: 0.1523 r2_val: 0.2426\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0128 loss_train: 0.4266 loss_val: 0.4402 r2_train: 0.2604 r2_val: 0.2904\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0129 loss_train: 0.4281 loss_val: 0.4287 r2_train: 0.3271 r2_val: 0.2442\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0130 loss_train: 0.4172 loss_val: 0.4253 r2_train: 0.2688 r2_val: 0.1312\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0131 loss_train: 0.4207 loss_val: 0.4299 r2_train: 0.0951 r2_val: -0.0040\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0132 loss_train: 0.4193 loss_val: 0.4396 r2_train: 0.1049 r2_val: 0.0896\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0133 loss_train: 0.4203 loss_val: 0.4246 r2_train: 0.1647 r2_val: 0.2685\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0134 loss_train: 0.4164 loss_val: 0.4221 r2_train: 0.3250 r2_val: 0.3000\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0135 loss_train: 0.4134 loss_val: 0.4198 r2_train: 0.3476 r2_val: 0.2536\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0136 loss_train: 0.4055 loss_val: 0.4209 r2_train: 0.2793 r2_val: 0.1151\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0137 loss_train: 0.4077 loss_val: 0.4231 r2_train: 0.1550 r2_val: 0.1385\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0138 loss_train: 0.4058 loss_val: 0.4142 r2_train: 0.2202 r2_val: 0.2092\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0139 loss_train: 0.4074 loss_val: 0.4391 r2_train: 0.2518 r2_val: 0.2545\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0140 loss_train: 0.4153 loss_val: 0.4192 r2_train: 0.2822 r2_val: 0.3262\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0141 loss_train: 0.4024 loss_val: 0.4255 r2_train: 0.3511 r2_val: 0.2351\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0142 loss_train: 0.4058 loss_val: 0.4186 r2_train: 0.2802 r2_val: 0.1135\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0143 loss_train: 0.4006 loss_val: 0.4141 r2_train: 0.1956 r2_val: 0.1928\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0144 loss_train: 0.3952 loss_val: 0.4121 r2_train: 0.2491 r2_val: 0.2936\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0145 loss_train: 0.3966 loss_val: 0.4178 r2_train: 0.3085 r2_val: 0.2926\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0146 loss_train: 0.3961 loss_val: 0.4088 r2_train: 0.3592 r2_val: 0.2626\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0147 loss_train: 0.3879 loss_val: 0.4097 r2_train: 0.3272 r2_val: 0.2181\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0148 loss_train: 0.3874 loss_val: 0.4221 r2_train: 0.3059 r2_val: 0.2457\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0149 loss_train: 0.4048 loss_val: 0.4416 r2_train: 0.2357 r2_val: 0.2316\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0150 loss_train: 0.4185 loss_val: 0.4312 r2_train: 0.2862 r2_val: 0.2874\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0151 loss_train: 0.4065 loss_val: 0.4270 r2_train: 0.3247 r2_val: 0.1919\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0152 loss_train: 0.4003 loss_val: 0.4140 r2_train: 0.2202 r2_val: 0.1262\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0153 loss_train: 0.3912 loss_val: 0.4192 r2_train: 0.2095 r2_val: 0.1824\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0154 loss_train: 0.3912 loss_val: 0.4097 r2_train: 0.3061 r2_val: 0.3291\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0155 loss_train: 0.3869 loss_val: 0.4086 r2_train: 0.3953 r2_val: 0.3207\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0156 loss_train: 0.3870 loss_val: 0.4380 r2_train: 0.3505 r2_val: 0.2565\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0157 loss_train: 0.4001 loss_val: 0.4281 r2_train: 0.3378 r2_val: 0.2578\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0158 loss_train: 0.4031 loss_val: 0.4084 r2_train: 0.2754 r2_val: 0.2127\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0159 loss_train: 0.3947 loss_val: 0.4199 r2_train: 0.2255 r2_val: 0.2066\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0160 loss_train: 0.3856 loss_val: 0.4219 r2_train: 0.2838 r2_val: 0.3006\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0161 loss_train: 0.3825 loss_val: 0.4184 r2_train: 0.3734 r2_val: 0.3262\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0162 loss_train: 0.3874 loss_val: 0.4129 r2_train: 0.3731 r2_val: 0.2639\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0163 loss_train: 0.3758 loss_val: 0.4064 r2_train: 0.3597 r2_val: 0.2189\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0164 loss_train: 0.3952 loss_val: 0.4365 r2_train: 0.2691 r2_val: 0.2243\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0165 loss_train: 0.4173 loss_val: 0.4101 r2_train: 0.2928 r2_val: 0.1925\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0166 loss_train: 0.3913 loss_val: 0.4525 r2_train: 0.2591 r2_val: 0.0285\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0167 loss_train: 0.4299 loss_val: 0.4189 r2_train: 0.1035 r2_val: 0.1672\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0168 loss_train: 0.3838 loss_val: 0.4272 r2_train: 0.2696 r2_val: 0.2730\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0169 loss_train: 0.3916 loss_val: 0.4543 r2_train: 0.3405 r2_val: 0.3002\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0170 loss_train: 0.4052 loss_val: 0.4141 r2_train: 0.3817 r2_val: 0.2529\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0171 loss_train: 0.3716 loss_val: 0.4312 r2_train: 0.3342 r2_val: 0.1771\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0172 loss_train: 0.4088 loss_val: 0.4170 r2_train: 0.2331 r2_val: 0.2237\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0173 loss_train: 0.3825 loss_val: 0.4068 r2_train: 0.2992 r2_val: 0.3190\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0174 loss_train: 0.3720 loss_val: 0.4287 r2_train: 0.3947 r2_val: 0.2836\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0175 loss_train: 0.3932 loss_val: 0.4124 r2_train: 0.3390 r2_val: 0.1677\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0176 loss_train: 0.3746 loss_val: 0.4112 r2_train: 0.2799 r2_val: 0.1559\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0177 loss_train: 0.3757 loss_val: 0.4167 r2_train: 0.2659 r2_val: 0.2675\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0178 loss_train: 0.3714 loss_val: 0.4150 r2_train: 0.3820 r2_val: 0.3624\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0179 loss_train: 0.3688 loss_val: 0.4121 r2_train: 0.4673 r2_val: 0.3309\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0180 loss_train: 0.3653 loss_val: 0.4051 r2_train: 0.4415 r2_val: 0.2524\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0181 loss_train: 0.3606 loss_val: 0.4079 r2_train: 0.3246 r2_val: 0.2333\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0182 loss_train: 0.3680 loss_val: 0.4084 r2_train: 0.3019 r2_val: 0.3377\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0183 loss_train: 0.3560 loss_val: 0.4097 r2_train: 0.4440 r2_val: 0.3731\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0184 loss_train: 0.3560 loss_val: 0.4110 r2_train: 0.4539 r2_val: 0.2852\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0185 loss_train: 0.3589 loss_val: 0.4010 r2_train: 0.4046 r2_val: 0.2890\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0186 loss_train: 0.3487 loss_val: 0.4053 r2_train: 0.3895 r2_val: 0.2977\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0187 loss_train: 0.3549 loss_val: 0.4163 r2_train: 0.3863 r2_val: 0.3917\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0188 loss_train: 0.3546 loss_val: 0.4010 r2_train: 0.4731 r2_val: 0.3657\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0189 loss_train: 0.3437 loss_val: 0.4052 r2_train: 0.4514 r2_val: 0.2797\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0190 loss_train: 0.3554 loss_val: 0.3948 r2_train: 0.4005 r2_val: 0.2606\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0191 loss_train: 0.3402 loss_val: 0.4218 r2_train: 0.3824 r2_val: 0.3416\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0192 loss_train: 0.3540 loss_val: 0.4214 r2_train: 0.4540 r2_val: 0.3633\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0193 loss_train: 0.3388 loss_val: 0.4067 r2_train: 0.4742 r2_val: 0.3458\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0194 loss_train: 0.3505 loss_val: 0.4124 r2_train: 0.4568 r2_val: 0.2845\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0195 loss_train: 0.3584 loss_val: 0.3989 r2_train: 0.4065 r2_val: 0.2825\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0196 loss_train: 0.3347 loss_val: 0.4004 r2_train: 0.4134 r2_val: 0.2586\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0197 loss_train: 0.3444 loss_val: 0.3949 r2_train: 0.3938 r2_val: 0.3573\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0198 loss_train: 0.3307 loss_val: 0.4092 r2_train: 0.4644 r2_val: 0.3585\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0199 loss_train: 0.3439 loss_val: 0.4065 r2_train: 0.4912 r2_val: 0.3241\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0200 loss_train: 0.3332 loss_val: 0.3985 r2_train: 0.4802 r2_val: 0.3368\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0201 loss_train: 0.3311 loss_val: 0.3987 r2_train: 0.4807 r2_val: 0.3428\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0202 loss_train: 0.3359 loss_val: 0.4005 r2_train: 0.4081 r2_val: 0.3241\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0203 loss_train: 0.3256 loss_val: 0.3984 r2_train: 0.4760 r2_val: 0.3508\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0204 loss_train: 0.3298 loss_val: 0.3971 r2_train: 0.5066 r2_val: 0.3153\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0205 loss_train: 0.3215 loss_val: 0.4034 r2_train: 0.4670 r2_val: 0.3561\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0206 loss_train: 0.3239 loss_val: 0.4162 r2_train: 0.5103 r2_val: 0.2477\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0207 loss_train: 0.3245 loss_val: 0.3983 r2_train: 0.4883 r2_val: 0.3127\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0208 loss_train: 0.3206 loss_val: 0.4501 r2_train: 0.4628 r2_val: 0.3818\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0209 loss_train: 0.3617 loss_val: 0.4120 r2_train: 0.4783 r2_val: 0.3358\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0210 loss_train: 0.3304 loss_val: 0.4211 r2_train: 0.4676 r2_val: 0.1701\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0211 loss_train: 0.3469 loss_val: 0.4000 r2_train: 0.3742 r2_val: 0.2291\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0212 loss_train: 0.3296 loss_val: 0.4146 r2_train: 0.4191 r2_val: 0.3344\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0213 loss_train: 0.3226 loss_val: 0.4189 r2_train: 0.4742 r2_val: 0.3888\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0214 loss_train: 0.3297 loss_val: 0.4057 r2_train: 0.5507 r2_val: 0.3340\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0215 loss_train: 0.3175 loss_val: 0.4074 r2_train: 0.5436 r2_val: 0.2405\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0216 loss_train: 0.3371 loss_val: 0.4014 r2_train: 0.3694 r2_val: 0.3161\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0217 loss_train: 0.3211 loss_val: 0.4357 r2_train: 0.4390 r2_val: 0.4309\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0218 loss_train: 0.3541 loss_val: 0.4018 r2_train: 0.5554 r2_val: 0.3410\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0219 loss_train: 0.3229 loss_val: 0.4168 r2_train: 0.4433 r2_val: 0.2783\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0220 loss_train: 0.3282 loss_val: 0.4181 r2_train: 0.4046 r2_val: 0.3527\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0221 loss_train: 0.3414 loss_val: 0.4369 r2_train: 0.5281 r2_val: 0.2282\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0222 loss_train: 0.3392 loss_val: 0.4218 r2_train: 0.4257 r2_val: 0.2176\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0223 loss_train: 0.3440 loss_val: 0.3988 r2_train: 0.3890 r2_val: 0.3139\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0224 loss_train: 0.3076 loss_val: 0.4564 r2_train: 0.4813 r2_val: 0.2532\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0225 loss_train: 0.4160 loss_val: 0.4184 r2_train: 0.4038 r2_val: 0.2587\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0226 loss_train: 0.3279 loss_val: 0.4593 r2_train: 0.4420 r2_val: 0.1272\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0227 loss_train: 0.4045 loss_val: 0.4220 r2_train: 0.2439 r2_val: 0.2501\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0228 loss_train: 0.3350 loss_val: 0.4286 r2_train: 0.3977 r2_val: 0.2813\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0229 loss_train: 0.3253 loss_val: 0.5040 r2_train: 0.4210 r2_val: 0.2296\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0230 loss_train: 0.4532 loss_val: 0.3927 r2_train: 0.3646 r2_val: 0.2383\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0231 loss_train: 0.3235 loss_val: 0.4699 r2_train: 0.3964 r2_val: 0.1119\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0232 loss_train: 0.3877 loss_val: 0.4620 r2_train: 0.2952 r2_val: 0.1786\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0233 loss_train: 0.3683 loss_val: 0.4096 r2_train: 0.3960 r2_val: 0.2628\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0234 loss_train: 0.3267 loss_val: 0.4068 r2_train: 0.4441 r2_val: 0.2549\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0235 loss_train: 0.3407 loss_val: 0.4608 r2_train: 0.3939 r2_val: 0.2474\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0236 loss_train: 0.3605 loss_val: 0.4077 r2_train: 0.3846 r2_val: 0.3486\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0237 loss_train: 0.3307 loss_val: 0.4063 r2_train: 0.4806 r2_val: 0.3922\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0238 loss_train: 0.3305 loss_val: 0.4258 r2_train: 0.5190 r2_val: 0.3668\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0239 loss_train: 0.3363 loss_val: 0.4664 r2_train: 0.4875 r2_val: 0.2941\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0240 loss_train: 0.3201 loss_val: 0.4116 r2_train: 0.4991 r2_val: 0.2504\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0241 loss_train: 0.3194 loss_val: 0.4191 r2_train: 0.4301 r2_val: 0.2988\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0242 loss_train: 0.3302 loss_val: 0.4592 r2_train: 0.4537 r2_val: 0.3786\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0243 loss_train: 0.3111 loss_val: 0.4409 r2_train: 0.5054 r2_val: 0.4321\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0244 loss_train: 0.3320 loss_val: 0.4439 r2_train: 0.5954 r2_val: 0.3690\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0245 loss_train: 0.3565 loss_val: 0.5440 r2_train: 0.5043 r2_val: -0.3618\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0246 loss_train: 0.4513 loss_val: 0.4462 r2_train: -0.0759 r2_val: -0.0771\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0247 loss_train: 0.4078 loss_val: 0.4049 r2_train: -0.0021 r2_val: 0.2549\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0248 loss_train: 0.3293 loss_val: 0.4869 r2_train: 0.4087 r2_val: 0.2734\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0249 loss_train: 0.3907 loss_val: 0.4516 r2_train: 0.4322 r2_val: 0.3352\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0250 loss_train: 0.3884 loss_val: 0.4019 r2_train: 0.4656 r2_val: 0.3034\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0251 loss_train: 0.3236 loss_val: 0.4177 r2_train: 0.4940 r2_val: 0.1700\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0252 loss_train: 0.3308 loss_val: 0.4890 r2_train: 0.3915 r2_val: -0.0459\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0253 loss_train: 0.3531 loss_val: 0.4286 r2_train: 0.3483 r2_val: 0.2552\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0254 loss_train: 0.3453 loss_val: 0.4138 r2_train: 0.3799 r2_val: 0.4085\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0255 loss_train: 0.3226 loss_val: 0.4106 r2_train: 0.5524 r2_val: 0.3795\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0256 loss_train: 0.3378 loss_val: 0.4081 r2_train: 0.5358 r2_val: 0.3155\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0257 loss_train: 0.3262 loss_val: 0.4221 r2_train: 0.4954 r2_val: 0.2856\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0258 loss_train: 0.3129 loss_val: 0.4151 r2_train: 0.4342 r2_val: 0.1937\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0259 loss_train: 0.3462 loss_val: 0.4152 r2_train: 0.4160 r2_val: 0.1858\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0260 loss_train: 0.3118 loss_val: 0.4369 r2_train: 0.4400 r2_val: 0.1949\n",
      "Optimization Finished!\n",
      "Total time elapsed: 1841.3475s\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01,momentum = 0.9,weight_decay=0.00005)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.005,weight_decay=0.0005)\n",
    "#print(\"oooooooooooooooooooo\")\n",
    "print(graph.device)\n",
    "#print(graph.is_cuda)\n",
    "t_total = time.time()\n",
    "for epoch in range(260):\n",
    "    train(epoch)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "print('----------')\n",
    "#Testing\n",
    "#test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb7b552-0d9c-483c-aa90-c7913a96c514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "(23140, 1)\n",
      "Mean Squared Error: 0.5634200743379739 3.2398155\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(graph, node_features, edge_features)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "s_y = dataset.ss_y\n",
    "y_pre = s_y.inverse_transform(output.detach().numpy())\n",
    "y_ture = s_y.inverse_transform(labels.detach().numpy())\n",
    "print(y_pre.shape)\n",
    "\n",
    "r2 = r2_score(y_ture[idx_test], y_pre[idx_test])\n",
    "mse = mean_squared_error(y_ture[idx_test], y_pre[idx_test])\n",
    "mae = mean_absolute_error(y_ture[idx_test], y_pre[idx_test])\n",
    "print(\"Mean Squared Error:\", r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fa465-0c54-41f0-9396-80e20957396d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "909e2bc4-8515-469b-9218-4a8a59bdfefc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([23140, 17])\n"
     ]
    }
   ],
   "source": [
    "#IG explanation\n",
    "baseline = torch.zeros_like(node_features)\n",
    "baseline[:,-1] = 0\n",
    "baseline[:,-2] = 0\n",
    "print(baseline[:5])\n",
    "print(baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efc29f0c-562e-4ab8-9342-cdebe7c49528",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from functools import partial\n",
    "ig = IntegratedGradients(partial(model, graph, e_in = edge_features))\n",
    "mask = ig.attribute(node_features.float(),baselines = baseline,internal_batch_size=128, n_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d47392-0802-43ef-8e96-80ed029e7d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
