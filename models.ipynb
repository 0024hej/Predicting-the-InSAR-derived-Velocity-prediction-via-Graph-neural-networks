{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893753fe-9a77-499a-b39d-e15831fe0bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dgl.data import DGLDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "\n",
    "\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "from utils import load_data, r2_fun\n",
    "from models import EGAT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020f7202-9a69-45dd-87d5-10771ee76375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([23140, 15])\n",
      "torch.Size([23140, 17])\n",
      "Graph(num_nodes=23140, num_edges=139802,\n",
      "      ndata_schemes={'feat': Scheme(shape=(17,), dtype=torch.float32), 'label': Scheme(shape=(1,), dtype=torch.float32)}\n",
      "      edata_schemes={'weight': Scheme(shape=(4,), dtype=torch.float32)})\n"
     ]
    }
   ],
   "source": [
    "class load_data(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='karate_clube')\n",
    "\n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv('./data/node_data.csv')\n",
    "        edges_data = pd.read_csv('./data/edge_features2.csv')\n",
    "        node_fe_contin = ['std_dem','avg_slope', 'std_slope', 'medi_aspec', 'avg_plan_c', \n",
    "                        'std_plan_c', 'avg_prof_c','std_prof_c', 'avg_maxpre', 'avg_mean a', 'dis2river', \n",
    "                        'max GWS','min GWS', 'differ GWS',  'dis2faults']            #18 ndvi\n",
    "        node_fe_categ = ['land cover','lithology']   #2\n",
    "        edge_fe_name = ['area_ratio','centre distance', 'aspect angle differ', 'elevation differ']\n",
    "        \n",
    "        node_features_contin = nodes_data[node_fe_contin].to_numpy()\n",
    "        node_features_categ = torch.from_numpy(nodes_data[node_fe_categ].astype('category').to_numpy())\n",
    "        \n",
    "        node_labels = nodes_data['max_vel1'].to_numpy()\n",
    "        edge_features = edges_data[edge_fe_name].to_numpy()\n",
    "        edges_src = torch.from_numpy(edges_data['src'].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data['des'].to_numpy()) \n",
    "        \n",
    "        node_labels = np.reshape(node_labels,(-1,1))\n",
    "        ss_node = StandardScaler()\n",
    "        ss_edge = StandardScaler()\n",
    "        ss_y = StandardScaler()\n",
    "\n",
    "        node_features_nor = ss_node.fit_transform(node_features_contin)\n",
    "        edge_features_nor = ss_edge.fit_transform(edge_features)\n",
    "        node_labels_nor = ss_y.fit_transform(node_labels)\n",
    "        print(type(node_features_nor))\n",
    "        self.ss_y = ss_y\n",
    "        self.y_ture = node_labels\n",
    "\n",
    "        \n",
    "        node_features_nor  = torch.from_numpy(node_features_nor.astype('float32'))\n",
    "        node_labels_nor  = torch.from_numpy(node_labels_nor.astype('float32'))\n",
    "        edge_features_nor  = torch.from_numpy(edge_features_nor.astype('float32'))\n",
    "\n",
    "        #cat continues and category features\n",
    "        print(node_features_nor.shape)\n",
    "        cont_cat_fe = torch.cat((node_features_nor,node_features_categ/10),dim = 1)\n",
    "        print(cont_cat_fe.shape)\n",
    "        \n",
    "\n",
    "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])\n",
    "        self.graph.ndata['feat'] = cont_cat_fe\n",
    "        #self.graph.ndata['feat2'] = node_features_categ\n",
    "        self.graph.ndata['label'] = node_labels_nor\n",
    "        self.graph.edata['weight'] = edge_features_nor\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "dataset = load_data()\n",
    "graph = dataset[0]\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fd1c29-ab60-4781-a39b-7038db2b782a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23140, 17])\n",
      "torch.Size([139802, 4])\n",
      "torch.Size([23140, 1])\n",
      "22926\n",
      "[15190 19205 19790 14477  1196   117   913 14799 16235 14408]\n"
     ]
    }
   ],
   "source": [
    "node_features = torch.FloatTensor(np.array(graph.ndata['feat'].detach()))\n",
    "edge_features = torch.FloatTensor(np.array(graph.edata['weight']))\n",
    "labels = torch.FloatTensor(np.array(graph.ndata['label']))\n",
    "\n",
    "print(node_features.shape)\n",
    "print(edge_features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "#import random\n",
    "np.random.seed(113)\n",
    "idx = np.arange(len(labels))   #which is equal to su_id\n",
    "no_points_su_id = pd.read_csv('./data/no_label_id_ERA5.csv')\n",
    "no_points_su_id = list(no_points_su_id['su_id'])\n",
    "idx = np.delete(idx, np.where(np.isin(idx, no_points_su_id)))\n",
    "print(len(idx))\n",
    "\n",
    "\n",
    "part1_size = int(0.3 * len(idx))\n",
    "part2_size = int(0.2 * len(idx))\n",
    "part3_size = int(0.5 * len(idx))\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "idx_train = idx[:part1_size]\n",
    "idx_val = idx[part1_size:part1_size+part2_size]\n",
    "idx_test = idx[part1_size+part2_size:part1_size+part2_size+part3_size]\n",
    "\n",
    "print(idx_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54e5047f-c95f-4899-87a3-5b5d6f744503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressionNN(\n",
      "  (fc1): Linear(in_features=17, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc0): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义神经网络模型\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(RegressionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)  # 输入层到第一个隐藏层\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)  # 第一个隐藏层到第二个隐藏层\n",
    "        self.fc0 = nn.Linear(hidden_dim2, output_dim)  # 第二个隐藏层到输出层\n",
    "        self.relu = nn.ReLU()  # 激活函数\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        #self.embedding_1 = nn.Embedding(10,2)  #9 equal to calsses of land cover\n",
    "        #self.embedding_2 = nn.Embedding(13,2)  #7 equal to calsses of lithology\n",
    "        \n",
    "    def forward(self, x1):\n",
    "        #embedded_1 = self.embedding_1(x1[:,-2].long())\n",
    "        #embedded_2 = self.embedding_2(x1[:,-1].long())\n",
    "\n",
    "        #combined = torch.cat((x1[:,:-2], embedded_1.view(embedded_1.size(0), -1), embedded_2.view(embedded_2.size(0), -1)), dim=1)\n",
    "        \n",
    "        x = self.relu(self.fc1(x1))  # first layer\n",
    "        x= self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))  # second layer\n",
    "        x= self.dropout2(x)\n",
    "\n",
    "        x = self.fc0(x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "input_dim = 17  \n",
    "hidden_dim1 = 128  \n",
    "hidden_dim2 = 128 \n",
    "output_dim = 1  \n",
    "model = RegressionNN(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005,weight_decay = 5e-5)  # Adam\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e085c36-e36a-4caf-a641-dc412fe5bfb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 0.9766, r2:-37.852\n",
      "MSELoss: 0.8719, r2:-15.035\n",
      "Epoch [2/300], Loss: 0.8641, r2:-14.769\n",
      "MSELoss: 0.8023, r2:-5.326\n",
      "Epoch [3/300], Loss: 0.7922, r2:-5.096\n",
      "MSELoss: 0.7901, r2:-2.360\n",
      "Epoch [4/300], Loss: 0.7653, r2:-2.194\n",
      "MSELoss: 0.7709, r2:-1.275\n",
      "Epoch [5/300], Loss: 0.7568, r2:-1.204\n",
      "MSELoss: 0.7660, r2:-1.114\n",
      "Epoch [6/300], Loss: 0.7425, r2:-1.067\n",
      "MSELoss: 0.7534, r2:-1.284\n",
      "Epoch [7/300], Loss: 0.7230, r2:-1.222\n",
      "MSELoss: 0.7346, r2:-1.675\n",
      "Epoch [8/300], Loss: 0.7203, r2:-1.648\n",
      "MSELoss: 0.7272, r2:-2.131\n",
      "Epoch [9/300], Loss: 0.7039, r2:-2.083\n",
      "MSELoss: 0.7220, r2:-2.454\n",
      "Epoch [10/300], Loss: 0.7037, r2:-2.364\n",
      "MSELoss: 0.7194, r2:-2.477\n",
      "Epoch [11/300], Loss: 0.7034, r2:-2.400\n",
      "MSELoss: 0.7075, r2:-2.099\n",
      "Epoch [12/300], Loss: 0.6939, r2:-2.154\n",
      "MSELoss: 0.6979, r2:-1.675\n",
      "Epoch [13/300], Loss: 0.6812, r2:-1.681\n",
      "MSELoss: 0.6981, r2:-1.344\n",
      "Epoch [14/300], Loss: 0.6713, r2:-1.259\n",
      "MSELoss: 0.6938, r2:-1.087\n",
      "Epoch [15/300], Loss: 0.6721, r2:-1.049\n",
      "MSELoss: 0.6965, r2:-0.992\n",
      "Epoch [16/300], Loss: 0.6681, r2:-0.985\n",
      "MSELoss: 0.6899, r2:-1.002\n",
      "Epoch [17/300], Loss: 0.6776, r2:-1.023\n",
      "MSELoss: 0.6860, r2:-1.119\n",
      "Epoch [18/300], Loss: 0.6652, r2:-1.058\n",
      "MSELoss: 0.6812, r2:-1.258\n",
      "Epoch [19/300], Loss: 0.6609, r2:-1.312\n",
      "MSELoss: 0.6723, r2:-1.440\n",
      "Epoch [20/300], Loss: 0.6597, r2:-1.398\n",
      "MSELoss: 0.6721, r2:-1.480\n",
      "Epoch [21/300], Loss: 0.6551, r2:-1.439\n",
      "MSELoss: 0.6726, r2:-1.448\n",
      "Epoch [22/300], Loss: 0.6512, r2:-1.411\n",
      "MSELoss: 0.6678, r2:-1.224\n",
      "Epoch [23/300], Loss: 0.6496, r2:-1.215\n",
      "MSELoss: 0.6668, r2:-1.044\n",
      "Epoch [24/300], Loss: 0.6507, r2:-1.001\n",
      "MSELoss: 0.6663, r2:-0.921\n",
      "Epoch [25/300], Loss: 0.6491, r2:-0.871\n",
      "MSELoss: 0.6588, r2:-0.949\n",
      "Epoch [26/300], Loss: 0.6437, r2:-0.942\n",
      "MSELoss: 0.6561, r2:-1.003\n",
      "Epoch [27/300], Loss: 0.6366, r2:-0.969\n",
      "MSELoss: 0.6602, r2:-1.062\n",
      "Epoch [28/300], Loss: 0.6341, r2:-1.073\n",
      "MSELoss: 0.6561, r2:-1.119\n",
      "Epoch [29/300], Loss: 0.6360, r2:-1.095\n",
      "MSELoss: 0.6498, r2:-1.067\n",
      "Epoch [30/300], Loss: 0.6265, r2:-1.084\n",
      "MSELoss: 0.6472, r2:-0.978\n",
      "Epoch [31/300], Loss: 0.6304, r2:-0.960\n",
      "MSELoss: 0.6488, r2:-0.891\n",
      "Epoch [32/300], Loss: 0.6302, r2:-0.864\n",
      "MSELoss: 0.6456, r2:-0.820\n",
      "Epoch [33/300], Loss: 0.6288, r2:-0.798\n",
      "MSELoss: 0.6463, r2:-0.826\n",
      "Epoch [34/300], Loss: 0.6270, r2:-0.790\n",
      "MSELoss: 0.6431, r2:-0.884\n",
      "Epoch [35/300], Loss: 0.6127, r2:-0.847\n",
      "MSELoss: 0.6359, r2:-0.898\n",
      "Epoch [36/300], Loss: 0.6187, r2:-0.894\n",
      "MSELoss: 0.6383, r2:-0.917\n",
      "Epoch [37/300], Loss: 0.6172, r2:-0.872\n",
      "MSELoss: 0.6305, r2:-0.900\n",
      "Epoch [38/300], Loss: 0.6102, r2:-0.880\n",
      "MSELoss: 0.6354, r2:-0.865\n",
      "Epoch [39/300], Loss: 0.6135, r2:-0.829\n",
      "MSELoss: 0.6351, r2:-0.834\n",
      "Epoch [40/300], Loss: 0.6101, r2:-0.779\n",
      "MSELoss: 0.6303, r2:-0.797\n",
      "Epoch [41/300], Loss: 0.6084, r2:-0.729\n",
      "MSELoss: 0.6324, r2:-0.779\n",
      "Epoch [42/300], Loss: 0.6036, r2:-0.736\n",
      "MSELoss: 0.6312, r2:-0.750\n",
      "Epoch [43/300], Loss: 0.6119, r2:-0.751\n",
      "MSELoss: 0.6282, r2:-0.776\n",
      "Epoch [44/300], Loss: 0.5986, r2:-0.734\n",
      "MSELoss: 0.6259, r2:-0.729\n",
      "Epoch [45/300], Loss: 0.6094, r2:-0.751\n",
      "MSELoss: 0.6256, r2:-0.751\n",
      "Epoch [46/300], Loss: 0.5985, r2:-0.677\n",
      "MSELoss: 0.6299, r2:-0.779\n",
      "Epoch [47/300], Loss: 0.6046, r2:-0.746\n",
      "MSELoss: 0.6226, r2:-0.739\n",
      "Epoch [48/300], Loss: 0.6031, r2:-0.713\n",
      "MSELoss: 0.6257, r2:-0.732\n",
      "Epoch [49/300], Loss: 0.5878, r2:-0.669\n",
      "MSELoss: 0.6155, r2:-0.698\n",
      "Epoch [50/300], Loss: 0.5932, r2:-0.640\n",
      "MSELoss: 0.6193, r2:-0.682\n",
      "Epoch [51/300], Loss: 0.5924, r2:-0.633\n",
      "MSELoss: 0.6198, r2:-0.670\n",
      "Epoch [52/300], Loss: 0.5930, r2:-0.630\n",
      "MSELoss: 0.6174, r2:-0.680\n",
      "Epoch [53/300], Loss: 0.5917, r2:-0.592\n",
      "MSELoss: 0.6183, r2:-0.689\n",
      "Epoch [54/300], Loss: 0.5799, r2:-0.619\n",
      "MSELoss: 0.6125, r2:-0.730\n",
      "Epoch [55/300], Loss: 0.5834, r2:-0.629\n",
      "MSELoss: 0.6135, r2:-0.674\n",
      "Epoch [56/300], Loss: 0.5876, r2:-0.649\n",
      "MSELoss: 0.6096, r2:-0.674\n",
      "Epoch [57/300], Loss: 0.5820, r2:-0.624\n",
      "MSELoss: 0.6030, r2:-0.607\n",
      "Epoch [58/300], Loss: 0.5843, r2:-0.576\n",
      "MSELoss: 0.6053, r2:-0.568\n",
      "Epoch [59/300], Loss: 0.5854, r2:-0.569\n",
      "MSELoss: 0.6106, r2:-0.587\n",
      "Epoch [60/300], Loss: 0.5885, r2:-0.571\n",
      "MSELoss: 0.5976, r2:-0.597\n",
      "Epoch [61/300], Loss: 0.5802, r2:-0.565\n",
      "MSELoss: 0.6003, r2:-0.633\n",
      "Epoch [62/300], Loss: 0.5750, r2:-0.595\n",
      "MSELoss: 0.6058, r2:-0.649\n",
      "Epoch [63/300], Loss: 0.5802, r2:-0.586\n",
      "MSELoss: 0.6091, r2:-0.608\n",
      "Epoch [64/300], Loss: 0.5791, r2:-0.579\n",
      "MSELoss: 0.6077, r2:-0.567\n",
      "Epoch [65/300], Loss: 0.5707, r2:-0.469\n",
      "MSELoss: 0.5999, r2:-0.567\n",
      "Epoch [66/300], Loss: 0.5707, r2:-0.492\n",
      "MSELoss: 0.5978, r2:-0.542\n",
      "Epoch [67/300], Loss: 0.5764, r2:-0.536\n",
      "MSELoss: 0.6046, r2:-0.567\n",
      "Epoch [68/300], Loss: 0.5782, r2:-0.529\n",
      "MSELoss: 0.6051, r2:-0.596\n",
      "Epoch [69/300], Loss: 0.5649, r2:-0.497\n",
      "MSELoss: 0.5917, r2:-0.558\n",
      "Epoch [70/300], Loss: 0.5655, r2:-0.515\n",
      "MSELoss: 0.5969, r2:-0.588\n",
      "Epoch [71/300], Loss: 0.5684, r2:-0.502\n",
      "MSELoss: 0.5980, r2:-0.557\n",
      "Epoch [72/300], Loss: 0.5722, r2:-0.497\n",
      "MSELoss: 0.5943, r2:-0.510\n",
      "Epoch [73/300], Loss: 0.5640, r2:-0.455\n",
      "MSELoss: 0.5971, r2:-0.544\n",
      "Epoch [74/300], Loss: 0.5648, r2:-0.481\n",
      "MSELoss: 0.5943, r2:-0.543\n",
      "Epoch [75/300], Loss: 0.5632, r2:-0.471\n",
      "MSELoss: 0.5930, r2:-0.506\n",
      "Epoch [76/300], Loss: 0.5647, r2:-0.452\n",
      "MSELoss: 0.5961, r2:-0.506\n",
      "Epoch [77/300], Loss: 0.5477, r2:-0.420\n",
      "MSELoss: 0.5920, r2:-0.446\n",
      "Epoch [78/300], Loss: 0.5544, r2:-0.381\n",
      "MSELoss: 0.5895, r2:-0.436\n",
      "Epoch [79/300], Loss: 0.5607, r2:-0.367\n",
      "MSELoss: 0.5906, r2:-0.459\n",
      "Epoch [80/300], Loss: 0.5515, r2:-0.391\n",
      "MSELoss: 0.5864, r2:-0.488\n",
      "Epoch [81/300], Loss: 0.5518, r2:-0.437\n",
      "MSELoss: 0.5894, r2:-0.506\n",
      "Epoch [82/300], Loss: 0.5560, r2:-0.425\n",
      "MSELoss: 0.5883, r2:-0.453\n",
      "Epoch [83/300], Loss: 0.5554, r2:-0.401\n",
      "MSELoss: 0.5823, r2:-0.449\n",
      "Epoch [84/300], Loss: 0.5466, r2:-0.386\n",
      "MSELoss: 0.5917, r2:-0.437\n",
      "Epoch [85/300], Loss: 0.5525, r2:-0.384\n",
      "MSELoss: 0.5853, r2:-0.428\n",
      "Epoch [86/300], Loss: 0.5510, r2:-0.346\n",
      "MSELoss: 0.5911, r2:-0.435\n",
      "Epoch [87/300], Loss: 0.5515, r2:-0.364\n",
      "MSELoss: 0.5826, r2:-0.474\n",
      "Epoch [88/300], Loss: 0.5523, r2:-0.390\n",
      "MSELoss: 0.5829, r2:-0.481\n",
      "Epoch [89/300], Loss: 0.5438, r2:-0.394\n",
      "MSELoss: 0.5802, r2:-0.451\n",
      "Epoch [90/300], Loss: 0.5499, r2:-0.363\n",
      "MSELoss: 0.5809, r2:-0.418\n",
      "Epoch [91/300], Loss: 0.5510, r2:-0.365\n",
      "MSELoss: 0.5819, r2:-0.416\n",
      "Epoch [92/300], Loss: 0.5416, r2:-0.328\n",
      "MSELoss: 0.5771, r2:-0.389\n",
      "Epoch [93/300], Loss: 0.5429, r2:-0.336\n",
      "MSELoss: 0.5816, r2:-0.411\n",
      "Epoch [94/300], Loss: 0.5288, r2:-0.296\n",
      "MSELoss: 0.5859, r2:-0.436\n",
      "Epoch [95/300], Loss: 0.5354, r2:-0.305\n",
      "MSELoss: 0.5771, r2:-0.425\n",
      "Epoch [96/300], Loss: 0.5335, r2:-0.321\n",
      "MSELoss: 0.5788, r2:-0.394\n",
      "Epoch [97/300], Loss: 0.5413, r2:-0.328\n",
      "MSELoss: 0.5745, r2:-0.377\n",
      "Epoch [98/300], Loss: 0.5393, r2:-0.294\n",
      "MSELoss: 0.5724, r2:-0.345\n",
      "Epoch [99/300], Loss: 0.5379, r2:-0.308\n",
      "MSELoss: 0.5810, r2:-0.350\n",
      "Epoch [100/300], Loss: 0.5300, r2:-0.252\n",
      "MSELoss: 0.5775, r2:-0.323\n",
      "Epoch [101/300], Loss: 0.5419, r2:-0.248\n",
      "MSELoss: 0.5856, r2:-0.361\n",
      "Epoch [102/300], Loss: 0.5234, r2:-0.236\n",
      "MSELoss: 0.5790, r2:-0.359\n",
      "Epoch [103/300], Loss: 0.5382, r2:-0.265\n",
      "MSELoss: 0.5725, r2:-0.355\n",
      "Epoch [104/300], Loss: 0.5377, r2:-0.282\n",
      "MSELoss: 0.5732, r2:-0.399\n",
      "Epoch [105/300], Loss: 0.5257, r2:-0.316\n",
      "MSELoss: 0.5774, r2:-0.427\n",
      "Epoch [106/300], Loss: 0.5318, r2:-0.327\n",
      "MSELoss: 0.5774, r2:-0.387\n",
      "Epoch [107/300], Loss: 0.5258, r2:-0.299\n",
      "MSELoss: 0.5766, r2:-0.314\n",
      "Epoch [108/300], Loss: 0.5306, r2:-0.224\n",
      "MSELoss: 0.5733, r2:-0.259\n",
      "Epoch [109/300], Loss: 0.5294, r2:-0.189\n",
      "MSELoss: 0.5713, r2:-0.263\n",
      "Epoch [110/300], Loss: 0.5261, r2:-0.184\n",
      "MSELoss: 0.5718, r2:-0.308\n",
      "Epoch [111/300], Loss: 0.5269, r2:-0.209\n",
      "MSELoss: 0.5706, r2:-0.368\n",
      "Epoch [112/300], Loss: 0.5299, r2:-0.307\n",
      "MSELoss: 0.5777, r2:-0.440\n",
      "Epoch [113/300], Loss: 0.5253, r2:-0.303\n",
      "MSELoss: 0.5690, r2:-0.382\n",
      "Epoch [114/300], Loss: 0.5260, r2:-0.293\n",
      "MSELoss: 0.5746, r2:-0.331\n",
      "Epoch [115/300], Loss: 0.5220, r2:-0.222\n",
      "MSELoss: 0.5777, r2:-0.298\n",
      "Epoch [116/300], Loss: 0.5220, r2:-0.187\n",
      "MSELoss: 0.5708, r2:-0.244\n",
      "Epoch [117/300], Loss: 0.5314, r2:-0.193\n",
      "MSELoss: 0.5684, r2:-0.279\n",
      "Epoch [118/300], Loss: 0.5197, r2:-0.199\n",
      "MSELoss: 0.5745, r2:-0.350\n",
      "Epoch [119/300], Loss: 0.5214, r2:-0.230\n",
      "MSELoss: 0.5682, r2:-0.372\n",
      "Epoch [120/300], Loss: 0.5192, r2:-0.268\n",
      "MSELoss: 0.5676, r2:-0.350\n",
      "Epoch [121/300], Loss: 0.5260, r2:-0.254\n",
      "MSELoss: 0.5710, r2:-0.326\n",
      "Epoch [122/300], Loss: 0.5294, r2:-0.261\n",
      "MSELoss: 0.5666, r2:-0.292\n",
      "Epoch [123/300], Loss: 0.5200, r2:-0.223\n",
      "MSELoss: 0.5640, r2:-0.276\n",
      "Epoch [124/300], Loss: 0.5099, r2:-0.168\n",
      "MSELoss: 0.5677, r2:-0.242\n",
      "Epoch [125/300], Loss: 0.5215, r2:-0.177\n",
      "MSELoss: 0.5639, r2:-0.270\n",
      "Epoch [126/300], Loss: 0.5188, r2:-0.183\n",
      "MSELoss: 0.5677, r2:-0.291\n",
      "Epoch [127/300], Loss: 0.5121, r2:-0.181\n",
      "MSELoss: 0.5716, r2:-0.292\n",
      "Epoch [128/300], Loss: 0.5190, r2:-0.183\n",
      "MSELoss: 0.5652, r2:-0.294\n",
      "Epoch [129/300], Loss: 0.5170, r2:-0.205\n",
      "MSELoss: 0.5669, r2:-0.279\n",
      "Epoch [130/300], Loss: 0.5080, r2:-0.162\n",
      "MSELoss: 0.5635, r2:-0.262\n",
      "Epoch [131/300], Loss: 0.5140, r2:-0.157\n",
      "MSELoss: 0.5674, r2:-0.262\n",
      "Epoch [132/300], Loss: 0.5139, r2:-0.160\n",
      "MSELoss: 0.5668, r2:-0.280\n",
      "Epoch [133/300], Loss: 0.5145, r2:-0.197\n",
      "MSELoss: 0.5682, r2:-0.297\n",
      "Epoch [134/300], Loss: 0.5167, r2:-0.228\n",
      "MSELoss: 0.5666, r2:-0.280\n",
      "Epoch [135/300], Loss: 0.5079, r2:-0.163\n",
      "MSELoss: 0.5653, r2:-0.240\n",
      "Epoch [136/300], Loss: 0.5115, r2:-0.158\n",
      "MSELoss: 0.5665, r2:-0.222\n",
      "Epoch [137/300], Loss: 0.5055, r2:-0.130\n",
      "MSELoss: 0.5713, r2:-0.248\n",
      "Epoch [138/300], Loss: 0.5121, r2:-0.126\n",
      "MSELoss: 0.5611, r2:-0.237\n",
      "Epoch [139/300], Loss: 0.5084, r2:-0.158\n",
      "MSELoss: 0.5618, r2:-0.257\n",
      "Epoch [140/300], Loss: 0.5033, r2:-0.147\n",
      "MSELoss: 0.5629, r2:-0.283\n",
      "Epoch [141/300], Loss: 0.5120, r2:-0.188\n",
      "MSELoss: 0.5639, r2:-0.273\n",
      "Epoch [142/300], Loss: 0.5067, r2:-0.179\n",
      "MSELoss: 0.5633, r2:-0.235\n",
      "Epoch [143/300], Loss: 0.5065, r2:-0.123\n",
      "MSELoss: 0.5671, r2:-0.218\n",
      "Epoch [144/300], Loss: 0.5045, r2:-0.099\n",
      "MSELoss: 0.5663, r2:-0.228\n",
      "Epoch [145/300], Loss: 0.4996, r2:-0.123\n",
      "MSELoss: 0.5633, r2:-0.234\n",
      "Epoch [146/300], Loss: 0.5016, r2:-0.118\n",
      "MSELoss: 0.5617, r2:-0.247\n",
      "Epoch [147/300], Loss: 0.5051, r2:-0.124\n",
      "MSELoss: 0.5648, r2:-0.257\n",
      "Epoch [148/300], Loss: 0.5031, r2:-0.153\n",
      "MSELoss: 0.5656, r2:-0.223\n",
      "Epoch [149/300], Loss: 0.5053, r2:-0.084\n",
      "MSELoss: 0.5636, r2:-0.212\n",
      "Epoch [150/300], Loss: 0.5041, r2:-0.111\n",
      "MSELoss: 0.5659, r2:-0.235\n",
      "Epoch [151/300], Loss: 0.5073, r2:-0.135\n",
      "MSELoss: 0.5597, r2:-0.248\n",
      "Epoch [152/300], Loss: 0.5000, r2:-0.131\n",
      "MSELoss: 0.5673, r2:-0.262\n",
      "Epoch [153/300], Loss: 0.5039, r2:-0.146\n",
      "MSELoss: 0.5588, r2:-0.223\n",
      "Epoch [154/300], Loss: 0.5017, r2:-0.137\n",
      "MSELoss: 0.5667, r2:-0.230\n",
      "Epoch [155/300], Loss: 0.5024, r2:-0.093\n",
      "MSELoss: 0.5631, r2:-0.249\n",
      "Epoch [156/300], Loss: 0.4983, r2:-0.115\n",
      "MSELoss: 0.5600, r2:-0.249\n",
      "Epoch [157/300], Loss: 0.5013, r2:-0.131\n",
      "MSELoss: 0.5572, r2:-0.227\n",
      "Epoch [158/300], Loss: 0.5043, r2:-0.107\n",
      "MSELoss: 0.5559, r2:-0.221\n",
      "Epoch [159/300], Loss: 0.5014, r2:-0.107\n",
      "MSELoss: 0.5653, r2:-0.250\n",
      "Epoch [160/300], Loss: 0.5030, r2:-0.102\n",
      "MSELoss: 0.5528, r2:-0.223\n",
      "Epoch [161/300], Loss: 0.4976, r2:-0.114\n",
      "MSELoss: 0.5618, r2:-0.239\n",
      "Epoch [162/300], Loss: 0.5026, r2:-0.147\n",
      "MSELoss: 0.5630, r2:-0.264\n",
      "Epoch [163/300], Loss: 0.4955, r2:-0.122\n",
      "MSELoss: 0.5603, r2:-0.219\n",
      "Epoch [164/300], Loss: 0.4940, r2:-0.090\n",
      "MSELoss: 0.5637, r2:-0.203\n",
      "Epoch [165/300], Loss: 0.4856, r2:-0.050\n",
      "MSELoss: 0.5577, r2:-0.178\n",
      "Epoch [166/300], Loss: 0.4957, r2:-0.045\n",
      "MSELoss: 0.5656, r2:-0.206\n",
      "Epoch [167/300], Loss: 0.5010, r2:-0.088\n",
      "MSELoss: 0.5588, r2:-0.217\n",
      "Epoch [168/300], Loss: 0.4889, r2:-0.067\n",
      "MSELoss: 0.5642, r2:-0.253\n",
      "Epoch [169/300], Loss: 0.5003, r2:-0.119\n",
      "MSELoss: 0.5506, r2:-0.229\n",
      "Epoch [170/300], Loss: 0.4978, r2:-0.115\n",
      "MSELoss: 0.5607, r2:-0.246\n",
      "Epoch [171/300], Loss: 0.4932, r2:-0.099\n",
      "MSELoss: 0.5522, r2:-0.215\n",
      "Epoch [172/300], Loss: 0.4929, r2:-0.104\n",
      "MSELoss: 0.5626, r2:-0.236\n",
      "Epoch [173/300], Loss: 0.4854, r2:-0.056\n",
      "MSELoss: 0.5592, r2:-0.210\n",
      "Epoch [174/300], Loss: 0.5003, r2:-0.075\n",
      "MSELoss: 0.5640, r2:-0.221\n",
      "Epoch [175/300], Loss: 0.4902, r2:-0.084\n",
      "MSELoss: 0.5568, r2:-0.220\n",
      "Epoch [176/300], Loss: 0.4890, r2:-0.079\n",
      "MSELoss: 0.5590, r2:-0.210\n",
      "Epoch [177/300], Loss: 0.4902, r2:-0.046\n",
      "MSELoss: 0.5574, r2:-0.181\n",
      "Epoch [178/300], Loss: 0.4951, r2:-0.065\n",
      "MSELoss: 0.5533, r2:-0.209\n",
      "Epoch [179/300], Loss: 0.5019, r2:-0.106\n",
      "MSELoss: 0.5589, r2:-0.253\n",
      "Epoch [180/300], Loss: 0.4886, r2:-0.108\n",
      "MSELoss: 0.5579, r2:-0.248\n",
      "Epoch [181/300], Loss: 0.4861, r2:-0.105\n",
      "MSELoss: 0.5556, r2:-0.190\n",
      "Epoch [182/300], Loss: 0.4902, r2:-0.066\n",
      "MSELoss: 0.5576, r2:-0.144\n",
      "Epoch [183/300], Loss: 0.4885, r2:-0.022\n",
      "MSELoss: 0.5586, r2:-0.162\n",
      "Epoch [184/300], Loss: 0.4894, r2:-0.010\n",
      "MSELoss: 0.5618, r2:-0.197\n",
      "Epoch [185/300], Loss: 0.4963, r2:-0.068\n",
      "MSELoss: 0.5583, r2:-0.216\n",
      "Epoch [186/300], Loss: 0.4871, r2:-0.063\n",
      "MSELoss: 0.5519, r2:-0.228\n",
      "Epoch [187/300], Loss: 0.4881, r2:-0.091\n",
      "MSELoss: 0.5556, r2:-0.213\n",
      "Epoch [188/300], Loss: 0.4869, r2:-0.074\n",
      "MSELoss: 0.5639, r2:-0.205\n",
      "Epoch [189/300], Loss: 0.4900, r2:-0.052\n",
      "MSELoss: 0.5592, r2:-0.211\n",
      "Epoch [190/300], Loss: 0.4824, r2:-0.037\n",
      "MSELoss: 0.5577, r2:-0.176\n",
      "Epoch [191/300], Loss: 0.4899, r2:-0.050\n",
      "MSELoss: 0.5626, r2:-0.193\n",
      "Epoch [192/300], Loss: 0.4904, r2:-0.026\n",
      "MSELoss: 0.5651, r2:-0.204\n",
      "Epoch [193/300], Loss: 0.4890, r2:-0.047\n",
      "MSELoss: 0.5607, r2:-0.239\n",
      "Epoch [194/300], Loss: 0.4858, r2:-0.069\n",
      "MSELoss: 0.5512, r2:-0.236\n",
      "Epoch [195/300], Loss: 0.4869, r2:-0.088\n",
      "MSELoss: 0.5579, r2:-0.232\n",
      "Epoch [196/300], Loss: 0.4875, r2:-0.070\n",
      "MSELoss: 0.5654, r2:-0.189\n",
      "Epoch [197/300], Loss: 0.4796, r2:0.013\n",
      "MSELoss: 0.5547, r2:-0.128\n",
      "Epoch [198/300], Loss: 0.4839, r2:0.005\n",
      "MSELoss: 0.5624, r2:-0.185\n",
      "Epoch [199/300], Loss: 0.4882, r2:-0.022\n",
      "MSELoss: 0.5566, r2:-0.194\n",
      "Epoch [200/300], Loss: 0.4832, r2:-0.058\n",
      "MSELoss: 0.5543, r2:-0.202\n",
      "Epoch [201/300], Loss: 0.4898, r2:-0.067\n",
      "MSELoss: 0.5533, r2:-0.193\n",
      "Epoch [202/300], Loss: 0.4901, r2:-0.050\n",
      "MSELoss: 0.5547, r2:-0.214\n",
      "Epoch [203/300], Loss: 0.4849, r2:-0.072\n",
      "MSELoss: 0.5540, r2:-0.177\n",
      "Epoch [204/300], Loss: 0.4756, r2:-0.018\n",
      "MSELoss: 0.5520, r2:-0.150\n",
      "Epoch [205/300], Loss: 0.4853, r2:-0.020\n",
      "MSELoss: 0.5532, r2:-0.161\n",
      "Epoch [206/300], Loss: 0.4805, r2:0.013\n",
      "MSELoss: 0.5552, r2:-0.172\n",
      "Epoch [207/300], Loss: 0.4800, r2:-0.018\n",
      "MSELoss: 0.5585, r2:-0.205\n",
      "Epoch [208/300], Loss: 0.4768, r2:-0.045\n",
      "MSELoss: 0.5557, r2:-0.234\n",
      "Epoch [209/300], Loss: 0.4803, r2:-0.070\n",
      "MSELoss: 0.5506, r2:-0.201\n",
      "Epoch [210/300], Loss: 0.4805, r2:-0.028\n",
      "MSELoss: 0.5632, r2:-0.190\n",
      "Epoch [211/300], Loss: 0.4724, r2:-0.031\n",
      "MSELoss: 0.5493, r2:-0.132\n",
      "Epoch [212/300], Loss: 0.4795, r2:0.039\n",
      "MSELoss: 0.5578, r2:-0.161\n",
      "Epoch [213/300], Loss: 0.4779, r2:0.022\n",
      "MSELoss: 0.5562, r2:-0.166\n",
      "Epoch [214/300], Loss: 0.4802, r2:-0.015\n",
      "MSELoss: 0.5560, r2:-0.193\n",
      "Epoch [215/300], Loss: 0.4746, r2:-0.016\n",
      "MSELoss: 0.5548, r2:-0.203\n",
      "Epoch [216/300], Loss: 0.4803, r2:-0.057\n",
      "MSELoss: 0.5576, r2:-0.211\n",
      "Epoch [217/300], Loss: 0.4796, r2:-0.028\n",
      "MSELoss: 0.5582, r2:-0.200\n",
      "Epoch [218/300], Loss: 0.4855, r2:-0.032\n",
      "MSELoss: 0.5517, r2:-0.154\n",
      "Epoch [219/300], Loss: 0.4742, r2:0.015\n",
      "MSELoss: 0.5600, r2:-0.145\n",
      "Epoch [220/300], Loss: 0.4779, r2:0.024\n",
      "MSELoss: 0.5588, r2:-0.137\n",
      "Epoch [221/300], Loss: 0.4706, r2:0.045\n",
      "MSELoss: 0.5543, r2:-0.176\n",
      "Epoch [222/300], Loss: 0.4741, r2:-0.004\n",
      "MSELoss: 0.5577, r2:-0.200\n",
      "Epoch [223/300], Loss: 0.4680, r2:-0.016\n",
      "MSELoss: 0.5559, r2:-0.200\n",
      "Epoch [224/300], Loss: 0.4734, r2:-0.024\n",
      "MSELoss: 0.5596, r2:-0.193\n",
      "Epoch [225/300], Loss: 0.4740, r2:-0.004\n",
      "MSELoss: 0.5515, r2:-0.146\n",
      "Epoch [226/300], Loss: 0.4733, r2:0.022\n",
      "MSELoss: 0.5597, r2:-0.198\n",
      "Epoch [227/300], Loss: 0.4785, r2:0.005\n",
      "MSELoss: 0.5626, r2:-0.191\n",
      "Epoch [228/300], Loss: 0.4785, r2:-0.002\n",
      "MSELoss: 0.5593, r2:-0.205\n",
      "Epoch [229/300], Loss: 0.4719, r2:-0.012\n",
      "MSELoss: 0.5547, r2:-0.188\n",
      "Epoch [230/300], Loss: 0.4689, r2:-0.013\n",
      "MSELoss: 0.5606, r2:-0.190\n",
      "Epoch [231/300], Loss: 0.4756, r2:-0.009\n",
      "MSELoss: 0.5564, r2:-0.126\n",
      "Epoch [232/300], Loss: 0.4688, r2:0.047\n",
      "MSELoss: 0.5595, r2:-0.137\n",
      "Epoch [233/300], Loss: 0.4708, r2:0.051\n",
      "MSELoss: 0.5632, r2:-0.156\n",
      "Epoch [234/300], Loss: 0.4721, r2:0.024\n",
      "MSELoss: 0.5540, r2:-0.150\n",
      "Epoch [235/300], Loss: 0.4751, r2:-0.001\n",
      "MSELoss: 0.5520, r2:-0.187\n",
      "Epoch [236/300], Loss: 0.4725, r2:0.003\n",
      "MSELoss: 0.5563, r2:-0.190\n",
      "Epoch [237/300], Loss: 0.4734, r2:-0.001\n",
      "MSELoss: 0.5598, r2:-0.176\n",
      "Epoch [238/300], Loss: 0.4697, r2:0.015\n",
      "MSELoss: 0.5593, r2:-0.147\n",
      "Epoch [239/300], Loss: 0.4718, r2:0.027\n",
      "MSELoss: 0.5618, r2:-0.156\n",
      "Epoch [240/300], Loss: 0.4755, r2:0.043\n",
      "MSELoss: 0.5592, r2:-0.175\n",
      "Epoch [241/300], Loss: 0.4761, r2:-0.007\n",
      "MSELoss: 0.5598, r2:-0.224\n",
      "Epoch [242/300], Loss: 0.4715, r2:-0.031\n",
      "MSELoss: 0.5560, r2:-0.199\n",
      "Epoch [243/300], Loss: 0.4722, r2:-0.042\n",
      "MSELoss: 0.5577, r2:-0.169\n",
      "Epoch [244/300], Loss: 0.4709, r2:0.006\n",
      "MSELoss: 0.5641, r2:-0.144\n",
      "Epoch [245/300], Loss: 0.4753, r2:0.038\n",
      "MSELoss: 0.5583, r2:-0.108\n",
      "Epoch [246/300], Loss: 0.4722, r2:0.061\n",
      "MSELoss: 0.5536, r2:-0.145\n",
      "Epoch [247/300], Loss: 0.4731, r2:0.051\n",
      "MSELoss: 0.5616, r2:-0.158\n",
      "Epoch [248/300], Loss: 0.4665, r2:0.021\n",
      "MSELoss: 0.5538, r2:-0.183\n",
      "Epoch [249/300], Loss: 0.4636, r2:0.016\n",
      "MSELoss: 0.5513, r2:-0.184\n",
      "Epoch [250/300], Loss: 0.4773, r2:-0.025\n",
      "MSELoss: 0.5515, r2:-0.188\n",
      "Epoch [251/300], Loss: 0.4766, r2:-0.023\n",
      "MSELoss: 0.5572, r2:-0.188\n",
      "Epoch [252/300], Loss: 0.4735, r2:-0.008\n",
      "MSELoss: 0.5564, r2:-0.142\n",
      "Epoch [253/300], Loss: 0.4738, r2:0.045\n",
      "MSELoss: 0.5567, r2:-0.135\n",
      "Epoch [254/300], Loss: 0.4716, r2:0.025\n",
      "MSELoss: 0.5576, r2:-0.146\n",
      "Epoch [255/300], Loss: 0.4726, r2:0.019\n",
      "MSELoss: 0.5560, r2:-0.170\n",
      "Epoch [256/300], Loss: 0.4731, r2:-0.009\n",
      "MSELoss: 0.5577, r2:-0.175\n",
      "Epoch [257/300], Loss: 0.4733, r2:-0.005\n",
      "MSELoss: 0.5599, r2:-0.164\n",
      "Epoch [258/300], Loss: 0.4681, r2:0.025\n",
      "MSELoss: 0.5576, r2:-0.123\n",
      "Epoch [259/300], Loss: 0.4731, r2:0.039\n",
      "MSELoss: 0.5632, r2:-0.139\n",
      "Epoch [260/300], Loss: 0.4697, r2:0.031\n",
      "MSELoss: 0.5557, r2:-0.177\n",
      "Epoch [261/300], Loss: 0.4717, r2:0.004\n",
      "MSELoss: 0.5534, r2:-0.165\n",
      "Epoch [262/300], Loss: 0.4630, r2:0.024\n",
      "MSELoss: 0.5575, r2:-0.167\n",
      "Epoch [263/300], Loss: 0.4687, r2:0.012\n",
      "MSELoss: 0.5511, r2:-0.167\n",
      "Epoch [264/300], Loss: 0.4719, r2:-0.012\n",
      "MSELoss: 0.5566, r2:-0.131\n",
      "Epoch [265/300], Loss: 0.4692, r2:0.049\n",
      "MSELoss: 0.5522, r2:-0.132\n",
      "Epoch [266/300], Loss: 0.4712, r2:0.040\n",
      "MSELoss: 0.5527, r2:-0.166\n",
      "Epoch [267/300], Loss: 0.4686, r2:0.015\n",
      "MSELoss: 0.5525, r2:-0.189\n",
      "Epoch [268/300], Loss: 0.4640, r2:-0.014\n",
      "MSELoss: 0.5510, r2:-0.137\n",
      "Epoch [269/300], Loss: 0.4694, r2:0.002\n",
      "MSELoss: 0.5546, r2:-0.120\n",
      "Epoch [270/300], Loss: 0.4734, r2:0.066\n",
      "MSELoss: 0.5562, r2:-0.117\n",
      "Epoch [271/300], Loss: 0.4716, r2:0.056\n",
      "MSELoss: 0.5606, r2:-0.171\n",
      "Epoch [272/300], Loss: 0.4610, r2:0.075\n",
      "MSELoss: 0.5563, r2:-0.201\n",
      "Epoch [273/300], Loss: 0.4604, r2:0.010\n",
      "MSELoss: 0.5569, r2:-0.190\n",
      "Epoch [274/300], Loss: 0.4578, r2:0.031\n",
      "MSELoss: 0.5567, r2:-0.152\n",
      "Epoch [275/300], Loss: 0.4620, r2:0.061\n",
      "MSELoss: 0.5628, r2:-0.133\n",
      "Epoch [276/300], Loss: 0.4622, r2:0.063\n",
      "MSELoss: 0.5581, r2:-0.131\n",
      "Epoch [277/300], Loss: 0.4595, r2:0.076\n",
      "MSELoss: 0.5595, r2:-0.150\n",
      "Epoch [278/300], Loss: 0.4589, r2:0.068\n",
      "MSELoss: 0.5560, r2:-0.150\n",
      "Epoch [279/300], Loss: 0.4679, r2:0.068\n",
      "MSELoss: 0.5543, r2:-0.148\n",
      "Epoch [280/300], Loss: 0.4646, r2:0.043\n",
      "MSELoss: 0.5568, r2:-0.165\n",
      "Epoch [281/300], Loss: 0.4674, r2:0.022\n",
      "MSELoss: 0.5637, r2:-0.189\n",
      "Epoch [282/300], Loss: 0.4644, r2:0.031\n",
      "MSELoss: 0.5552, r2:-0.172\n",
      "Epoch [283/300], Loss: 0.4578, r2:0.040\n",
      "MSELoss: 0.5580, r2:-0.139\n",
      "Epoch [284/300], Loss: 0.4628, r2:0.072\n",
      "MSELoss: 0.5559, r2:-0.154\n",
      "Epoch [285/300], Loss: 0.4679, r2:0.043\n",
      "MSELoss: 0.5577, r2:-0.141\n",
      "Epoch [286/300], Loss: 0.4640, r2:0.032\n",
      "MSELoss: 0.5486, r2:-0.138\n",
      "Epoch [287/300], Loss: 0.4660, r2:0.045\n",
      "MSELoss: 0.5518, r2:-0.147\n",
      "Epoch [288/300], Loss: 0.4630, r2:0.033\n",
      "MSELoss: 0.5537, r2:-0.134\n",
      "Epoch [289/300], Loss: 0.4718, r2:0.036\n",
      "MSELoss: 0.5607, r2:-0.131\n",
      "Epoch [290/300], Loss: 0.4660, r2:0.068\n",
      "MSELoss: 0.5452, r2:-0.134\n",
      "Epoch [291/300], Loss: 0.4651, r2:0.063\n",
      "MSELoss: 0.5535, r2:-0.178\n",
      "Epoch [292/300], Loss: 0.4603, r2:0.033\n",
      "MSELoss: 0.5507, r2:-0.169\n",
      "Epoch [293/300], Loss: 0.4541, r2:0.037\n",
      "MSELoss: 0.5553, r2:-0.176\n",
      "Epoch [294/300], Loss: 0.4677, r2:0.040\n",
      "MSELoss: 0.5585, r2:-0.151\n",
      "Epoch [295/300], Loss: 0.4617, r2:0.074\n",
      "MSELoss: 0.5533, r2:-0.131\n",
      "Epoch [296/300], Loss: 0.4539, r2:0.077\n",
      "MSELoss: 0.5558, r2:-0.140\n",
      "Epoch [297/300], Loss: 0.4617, r2:0.049\n",
      "MSELoss: 0.5473, r2:-0.106\n",
      "Epoch [298/300], Loss: 0.4556, r2:0.076\n",
      "MSELoss: 0.5580, r2:-0.153\n",
      "Epoch [299/300], Loss: 0.4561, r2:0.081\n",
      "MSELoss: 0.5563, r2:-0.153\n",
      "Epoch [300/300], Loss: 0.4631, r2:0.038\n",
      "MSELoss: 0.5462, r2:-0.139\n",
      "------------ test\n",
      "MSELoss: 0.5533, r2:-0.155\n"
     ]
    }
   ],
   "source": [
    "#optimizer = optim.SGD(model.parameters(), lr=0.01,momentum = 0.9,weight_decay=0.00005)\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(node_features[idx_train])\n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, labels[idx_train])\n",
    "    r2_train = r2_fun(outputs, labels[idx_train])\n",
    "    \n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    y_pre1 = model(node_features[idx_test])\n",
    "    loss1 = F.mse_loss(y_pre1, labels[idx_test])\n",
    "    r2_val = r2_fun(y_pre1, labels[idx_test])\n",
    "    # 打印训练误差\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, r2:{r2_train.item():.3f}')\n",
    "    print(f'MSELoss: {loss1.item():.4f}, r2:{r2_val.item():.3f}')\n",
    "    \n",
    "print('------------ test')\n",
    "y_pre1 = model(node_features[idx_test])\n",
    "loss1 = F.mse_loss(y_pre1, labels[idx_test])\n",
    "r2_val = r2_fun(y_pre1, labels[idx_test])\n",
    "print(f'MSELoss: {loss1.item():.4f}, r2:{r2_val.item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "850a8006-70ff-4687-be86-3b8c4d328b94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.4871772087648466 3.5844667\n"
     ]
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load('./up/MLP_avg_trained.pth'))\n",
    "model.eval()\n",
    "output= model(node_features)\n",
    "loss1 = F.mse_loss(output[idx_test], labels[idx_test])\n",
    "r2_val = r2_fun(output[idx_test], labels[idx_test])\n",
    "s_y = dataset.ss_y\n",
    "y_pre = s_y.inverse_transform(output.detach().numpy())\n",
    "y_ture = s_y.inverse_transform(labels.detach().numpy())\n",
    "\n",
    "r2 = r2_score(y_ture[idx_test], y_pre[idx_test])\n",
    "mae = mean_absolute_error(y_ture[idx_test], y_pre[idx_test])\n",
    "\n",
    "print(\"Mean Squared Error:\", r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a5757ec-f08b-42dd-aa6f-5deb99abfaee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import BatchNorm\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size1,hidden_size2):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_feats, hidden_size1)\n",
    "        self.conv1 = dglnn.GraphConv(hidden_size1, hidden_size2,weight = True)\n",
    "        self.conv2 = dglnn.GraphConv(hidden_size2, hidden_size2, weight = True)\n",
    "        #self.conv3 = dglnn.GraphConv(hidden_size2, hidden_size2, weight = True)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dropout0 = nn.Dropout(0.5)\n",
    "        self.bn1 = BatchNorm(hidden_size1)\n",
    "\n",
    "        #self.embedding_1 = nn.Embedding(10,2)  #9 equal to calsses of land cover\n",
    "        #self.embedding_2 = nn.Embedding(13,2)  #7 equal to calsses of lithology\n",
    "\n",
    "    def reset_param(self):\n",
    "        for layer in [self.conv1, self.conv2]:\n",
    "            nn.itnit.kaiming_uniform_(layer.weight, a=0, mode = 'fan_in',nonlinearity = 'relu')\n",
    "\n",
    "    def forward(self, g, x1):\n",
    "        #embedded_1 = self.embedding_1(x1[:,-2].long())\n",
    "        #embedded_2 = self.embedding_2(x1[:,-1].long())\n",
    "\n",
    "        #combined_fe = torch.cat((x1[:,:-2], embedded_1.view(embedded_1.size(0), -1), embedded_2.view(embedded_2.size(0), -1)), dim=1)\n",
    "\n",
    "        #x = self.dropout0(combined_fe)\n",
    "        x1 =  self.fc1(x1)   #concat combined_fe0 and x2\n",
    "        x1 =  nn.functional.elu(x1)\n",
    "        #combined_fe = self.dropout0(combined_fe)\n",
    "        \n",
    "        \n",
    "        x = self.conv1(g, x1)\n",
    "        #x= self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x= self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(g, x)\n",
    "        x = torch.relu(x)\n",
    "        x= self.dropout2(x)\n",
    "        '''\n",
    "        x = self.conv3(g, x)\n",
    "        x = torch.relu(x)\n",
    "        x= self.dropout3(x)\n",
    "        '''\n",
    "        #x = self.fc1(x)\n",
    "        #x = torch.relu(x)\n",
    "        #x= self.dropout0(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "GNN = GNN(in_feats=node_features.shape[1], hidden_size1=128,hidden_size2=128)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(GNN.parameters(), lr=0.004,weight_decay = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d16e998b-9055-43d3-8cef-0249fe244289",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------epoch: 0\n",
      "0.9625081419944763 -43.18264795588727\n",
      "Mean Squared Error: 0.9775046706199646 -43.94946338438297\n",
      "------------------epoch: 1\n",
      "0.8658705949783325 -10.574558487109162\n",
      "Mean Squared Error: 0.8659515976905823 -10.444876437445256\n",
      "------------------epoch: 2\n",
      "0.8447470664978027 -3.717551591833778\n",
      "Mean Squared Error: 0.8494231700897217 -3.8646217633752835\n",
      "------------------epoch: 3\n",
      "0.8076081275939941 -3.267836670273577\n",
      "Mean Squared Error: 0.8245954513549805 -3.366029441755371\n",
      "------------------epoch: 4\n",
      "0.791424572467804 -4.0796178149232984\n",
      "Mean Squared Error: 0.8023555874824524 -3.985573376332268\n",
      "------------------epoch: 5\n",
      "0.7749747037887573 -4.420779691377251\n",
      "Mean Squared Error: 0.7904466390609741 -4.455565245410107\n",
      "------------------epoch: 6\n",
      "0.7520983815193176 -3.7832499586289474\n",
      "Mean Squared Error: 0.7674378752708435 -3.7239672947808895\n",
      "------------------epoch: 7\n",
      "0.7378938794136047 -2.5491239458906954\n",
      "Mean Squared Error: 0.7485668659210205 -2.542220680346561\n",
      "------------------epoch: 8\n",
      "0.7303922176361084 -1.6862074013492974\n",
      "Mean Squared Error: 0.7421404719352722 -1.6321398922993682\n",
      "------------------epoch: 9\n",
      "0.7148882150650024 -1.492614272199594\n",
      "Mean Squared Error: 0.7351644039154053 -1.517720214644418\n",
      "------------------epoch: 10\n",
      "0.7142339944839478 -1.8434075940650123\n",
      "Mean Squared Error: 0.720685601234436 -1.802484110469441\n",
      "------------------epoch: 11\n",
      "0.7158455848693848 -2.007556700808101\n",
      "Mean Squared Error: 0.7263339161872864 -1.8745502801162757\n",
      "------------------epoch: 12\n",
      "0.7098410725593567 -1.6771271473672438\n",
      "Mean Squared Error: 0.7138826251029968 -1.6689220546025463\n",
      "------------------epoch: 13\n",
      "0.7039666771888733 -1.4368520798552407\n",
      "Mean Squared Error: 0.7112327218055725 -1.399794305829773\n",
      "------------------epoch: 14\n",
      "0.701542854309082 -1.2594061333433695\n",
      "Mean Squared Error: 0.710965633392334 -1.234658873348145\n",
      "------------------epoch: 15\n",
      "0.6971015334129333 -1.4297879223369034\n",
      "Mean Squared Error: 0.704138457775116 -1.3770848698881664\n",
      "------------------epoch: 16\n",
      "0.6880432367324829 -1.7189812244797507\n",
      "Mean Squared Error: 0.7035095691680908 -1.7071315203974184\n",
      "------------------epoch: 17\n",
      "0.6847689747810364 -1.9263657425957028\n",
      "Mean Squared Error: 0.6971492767333984 -1.871078366491162\n",
      "------------------epoch: 18\n",
      "0.6817753911018372 -1.8729306534614665\n",
      "Mean Squared Error: 0.6929433941841125 -1.745348351615736\n",
      "------------------epoch: 19\n",
      "0.6806564927101135 -1.6922131387450796\n",
      "Mean Squared Error: 0.6872172355651855 -1.6054149515026195\n",
      "------------------epoch: 20\n",
      "0.6775468587875366 -1.4176128470569997\n",
      "Mean Squared Error: 0.6849815249443054 -1.3661626071491133\n",
      "------------------epoch: 21\n",
      "0.6730290651321411 -1.2444574232580607\n",
      "Mean Squared Error: 0.6817223429679871 -1.2309491614410022\n",
      "------------------epoch: 22\n",
      "0.6680995225906372 -1.320698292475463\n",
      "Mean Squared Error: 0.68327796459198 -1.3022321853160794\n",
      "------------------epoch: 23\n",
      "0.6661969423294067 -1.4818710101041694\n",
      "Mean Squared Error: 0.6737062335014343 -1.3930474689016878\n",
      "------------------epoch: 24\n",
      "0.6638109683990479 -1.4645356265917302\n",
      "Mean Squared Error: 0.674784243106842 -1.4472222148630731\n",
      "------------------epoch: 25\n",
      "0.6598884463310242 -1.3457028197138436\n",
      "Mean Squared Error: 0.6760556697845459 -1.3045159256809558\n",
      "------------------epoch: 26\n",
      "0.6509086489677429 -1.1382010032193683\n",
      "Mean Squared Error: 0.6670740246772766 -1.0836715992270638\n",
      "------------------epoch: 27\n",
      "0.6496496200561523 -1.062959359538774\n",
      "Mean Squared Error: 0.6715753674507141 -1.0624819936016885\n",
      "------------------epoch: 28\n",
      "0.6459667682647705 -1.0758960534444015\n",
      "Mean Squared Error: 0.6600475311279297 -1.0227977580791459\n",
      "------------------epoch: 29\n",
      "0.6450105309486389 -1.144344836918707\n",
      "Mean Squared Error: 0.6540018320083618 -1.094397347576967\n",
      "------------------epoch: 30\n",
      "0.6350433230400085 -1.1212068136949358\n",
      "Mean Squared Error: 0.6551409959793091 -1.1137525818235474\n",
      "------------------epoch: 31\n",
      "0.6318570375442505 -1.0454528313623763\n",
      "Mean Squared Error: 0.6512125134468079 -1.038980343701399\n",
      "------------------epoch: 32\n",
      "0.6422045826911926 -0.9920450350114922\n",
      "Mean Squared Error: 0.6553186178207397 -0.9778896889451081\n",
      "------------------epoch: 33\n",
      "0.6309077739715576 -0.9712083362849178\n",
      "Mean Squared Error: 0.6517012119293213 -0.9920552912239053\n",
      "------------------epoch: 34\n",
      "0.6308788061141968 -1.0338091954732196\n",
      "Mean Squared Error: 0.6443800330162048 -0.9974299682711876\n",
      "------------------epoch: 35\n",
      "0.6257901191711426 -1.0608626848777436\n",
      "Mean Squared Error: 0.6448001861572266 -1.0451581248310604\n",
      "------------------epoch: 36\n",
      "0.61863112449646 -1.016609685410288\n",
      "Mean Squared Error: 0.6378075480461121 -1.0059525255594033\n",
      "------------------epoch: 37\n",
      "0.6266438961029053 -0.9121874214500072\n",
      "Mean Squared Error: 0.6465374231338501 -0.9256020692885529\n",
      "------------------epoch: 38\n",
      "0.6211950182914734 -0.8853523984138791\n",
      "Mean Squared Error: 0.6294457912445068 -0.8421716257627059\n",
      "------------------epoch: 39\n",
      "0.6177526116371155 -0.894444958822219\n",
      "Mean Squared Error: 0.6380400657653809 -0.9127202544387898\n",
      "------------------epoch: 40\n",
      "0.61207115650177 -0.8994174828981198\n",
      "Mean Squared Error: 0.6369193196296692 -0.8876803838435212\n",
      "------------------epoch: 41\n",
      "0.6141161918640137 -0.7970576936658593\n",
      "Mean Squared Error: 0.6311048865318298 -0.8128492923837669\n",
      "------------------epoch: 42\n",
      "0.6090543270111084 -0.750496935937526\n",
      "Mean Squared Error: 0.6325962543487549 -0.7926814742222306\n",
      "------------------epoch: 43\n",
      "0.6110279560089111 -0.8260136803127873\n",
      "Mean Squared Error: 0.6253595352172852 -0.8122076376705061\n",
      "------------------epoch: 44\n",
      "0.6122260689735413 -0.8425341310778609\n",
      "Mean Squared Error: 0.6265628933906555 -0.8470411883489226\n",
      "------------------epoch: 45\n",
      "0.6042422652244568 -0.8747835510661337\n",
      "Mean Squared Error: 0.6208953261375427 -0.8736749206592878\n",
      "------------------epoch: 46\n",
      "0.6009663939476013 -0.7805897743516643\n",
      "Mean Squared Error: 0.6238663196563721 -0.8577561939747531\n",
      "------------------epoch: 47\n",
      "0.5936915874481201 -0.7181396751859468\n",
      "Mean Squared Error: 0.618529200553894 -0.7712747879116515\n",
      "------------------epoch: 48\n",
      "0.6050034165382385 -0.7457162624690812\n",
      "Mean Squared Error: 0.6168904900550842 -0.7172904045790562\n",
      "------------------epoch: 49\n",
      "0.5932532548904419 -0.637829046441827\n",
      "Mean Squared Error: 0.6222540736198425 -0.661411882772404\n",
      "------------------epoch: 50\n",
      "0.5963242650032043 -0.6963256444747317\n",
      "Mean Squared Error: 0.6145293712615967 -0.6851879487490296\n",
      "------------------epoch: 51\n",
      "0.591659426689148 -0.6867631443403843\n",
      "Mean Squared Error: 0.6152266263961792 -0.707095439825977\n",
      "------------------epoch: 52\n",
      "0.5887424945831299 -0.6678625117408128\n",
      "Mean Squared Error: 0.6056015491485596 -0.6953109188502267\n",
      "------------------epoch: 53\n",
      "0.5911630392074585 -0.6750503457619028\n",
      "Mean Squared Error: 0.6060797572135925 -0.6563292073895939\n",
      "------------------epoch: 54\n",
      "0.5867988467216492 -0.6035171376941468\n",
      "Mean Squared Error: 0.6058971881866455 -0.6453182178589127\n",
      "------------------epoch: 55\n",
      "0.5817081332206726 -0.6426637280601728\n",
      "Mean Squared Error: 0.6040588021278381 -0.6400112170048107\n",
      "------------------epoch: 56\n",
      "0.5802222490310669 -0.5301350778288301\n",
      "Mean Squared Error: 0.6124758720397949 -0.5954688311921312\n",
      "------------------epoch: 57\n",
      "0.5744215250015259 -0.5405030660943289\n",
      "Mean Squared Error: 0.6090283393859863 -0.5966808123656713\n",
      "------------------epoch: 58\n",
      "0.57713383436203 -0.6422766480042139\n",
      "Mean Squared Error: 0.607278048992157 -0.6383904396290565\n",
      "------------------epoch: 59\n",
      "0.5712279081344604 -0.5192910358162972\n",
      "Mean Squared Error: 0.5989221930503845 -0.533379196449209\n",
      "------------------epoch: 60\n",
      "0.5664529204368591 -0.5052597504489358\n",
      "Mean Squared Error: 0.6000538468360901 -0.5194508974487217\n",
      "------------------epoch: 61\n",
      "0.5711625218391418 -0.5313478610844589\n",
      "Mean Squared Error: 0.6038678288459778 -0.5707104690048328\n",
      "------------------epoch: 62\n",
      "0.5746282339096069 -0.500837436426365\n",
      "Mean Squared Error: 0.5983031392097473 -0.5260471488334018\n",
      "------------------epoch: 63\n",
      "0.5726492404937744 -0.455831207393085\n",
      "Mean Squared Error: 0.6024491786956787 -0.46990639152523195\n",
      "------------------epoch: 64\n",
      "0.5610406398773193 -0.5190312444836052\n",
      "Mean Squared Error: 0.599479079246521 -0.5751308559101451\n",
      "------------------epoch: 65\n",
      "0.5673421621322632 -0.5484537299521115\n",
      "Mean Squared Error: 0.605201244354248 -0.612369959214496\n",
      "------------------epoch: 66\n",
      "0.5687798857688904 -0.5453326397139879\n",
      "Mean Squared Error: 0.5984688997268677 -0.5348875986588775\n",
      "------------------epoch: 67\n",
      "0.5678155422210693 -0.46961081998610066\n",
      "Mean Squared Error: 0.6037055253982544 -0.4909007623267694\n",
      "------------------epoch: 68\n",
      "0.5630385279655457 -0.3569583588255465\n",
      "Mean Squared Error: 0.59646075963974 -0.40683592652677336\n",
      "------------------epoch: 69\n",
      "0.5554404854774475 -0.4546969316097087\n",
      "Mean Squared Error: 0.5974410772323608 -0.5184348205902938\n",
      "------------------epoch: 70\n",
      "0.5624210238456726 -0.5472974741618915\n",
      "Mean Squared Error: 0.5929505228996277 -0.5767728286585863\n",
      "------------------epoch: 71\n",
      "0.554317831993103 -0.4201503222487093\n",
      "Mean Squared Error: 0.5906034708023071 -0.5049259363498817\n",
      "------------------epoch: 72\n",
      "0.552130401134491 -0.4350869935934367\n",
      "Mean Squared Error: 0.5934295058250427 -0.4910869760118095\n",
      "------------------epoch: 73\n",
      "0.5566808581352234 -0.3940517181579324\n",
      "Mean Squared Error: 0.5935778021812439 -0.45599489274741756\n",
      "------------------epoch: 74\n",
      "0.5465721487998962 -0.4082453160138162\n",
      "Mean Squared Error: 0.5923699736595154 -0.480957080977948\n",
      "------------------epoch: 75\n",
      "0.5476962924003601 -0.4061311601680533\n",
      "Mean Squared Error: 0.5891352891921997 -0.4552220018764339\n",
      "------------------epoch: 76\n",
      "0.5483589172363281 -0.37230699998620986\n",
      "Mean Squared Error: 0.5894841551780701 -0.4500002529532867\n",
      "------------------epoch: 77\n",
      "0.54884272813797 -0.33098642729231265\n",
      "Mean Squared Error: 0.5832352042198181 -0.3748875192277854\n",
      "------------------epoch: 78\n",
      "0.545100748538971 -0.3937443611661535\n",
      "Mean Squared Error: 0.5870245695114136 -0.496320744891537\n",
      "------------------epoch: 79\n",
      "0.5460926294326782 -0.413870863702938\n",
      "Mean Squared Error: 0.5855060815811157 -0.4811775487052625\n",
      "------------------epoch: 80\n",
      "0.5443106293678284 -0.4323990075259816\n",
      "Mean Squared Error: 0.5820399522781372 -0.48237491206730154\n",
      "------------------epoch: 81\n",
      "0.5398799180984497 -0.2608780614094217\n",
      "Mean Squared Error: 0.5849409699440002 -0.3550181929164664\n",
      "------------------epoch: 82\n",
      "0.543337345123291 -0.3109156779185631\n",
      "Mean Squared Error: 0.5829861760139465 -0.36483461196088807\n",
      "------------------epoch: 83\n",
      "0.5391378998756409 -0.3682253040666643\n",
      "Mean Squared Error: 0.589369535446167 -0.4415160258416795\n",
      "------------------epoch: 84\n",
      "0.5411096215248108 -0.3470431076779541\n",
      "Mean Squared Error: 0.5798814296722412 -0.42408450635467165\n",
      "------------------epoch: 85\n",
      "0.5397495031356812 -0.287221713121387\n",
      "Mean Squared Error: 0.592542827129364 -0.3974710665694219\n",
      "------------------epoch: 86\n",
      "0.5372881889343262 -0.3368688544763421\n",
      "Mean Squared Error: 0.5860305428504944 -0.41223203052862667\n",
      "------------------epoch: 87\n",
      "0.5329557657241821 -0.3389717335406628\n",
      "Mean Squared Error: 0.5821936130523682 -0.41642186944835435\n",
      "------------------epoch: 88\n",
      "0.5307002067565918 -0.2959263486150767\n",
      "Mean Squared Error: 0.5861178636550903 -0.40188704483123017\n",
      "------------------epoch: 89\n",
      "0.5321479439735413 -0.29394327120750763\n",
      "Mean Squared Error: 0.582510769367218 -0.3582533026223551\n",
      "------------------epoch: 90\n",
      "0.5275894403457642 -0.24717792166517194\n",
      "Mean Squared Error: 0.5824539661407471 -0.32093220037060144\n",
      "------------------epoch: 91\n",
      "0.5295286774635315 -0.23402010094750714\n",
      "Mean Squared Error: 0.5775143504142761 -0.30214429036522006\n",
      "------------------epoch: 92\n",
      "0.5305832028388977 -0.20460074854919297\n",
      "Mean Squared Error: 0.582541823387146 -0.3104631195235903\n",
      "------------------epoch: 93\n",
      "0.5319477319717407 -0.31585845569970594\n",
      "Mean Squared Error: 0.5749220252037048 -0.39373662808299703\n",
      "------------------epoch: 94\n",
      "0.5317695140838623 -0.33759649120727464\n",
      "Mean Squared Error: 0.5784896016120911 -0.40326495066124357\n",
      "------------------epoch: 95\n",
      "0.5312260389328003 -0.21569485649083098\n",
      "Mean Squared Error: 0.5780859589576721 -0.28524957877927926\n",
      "------------------epoch: 96\n",
      "0.5220486521720886 -0.25396471755002814\n",
      "Mean Squared Error: 0.5754266977310181 -0.33353926746247753\n",
      "------------------epoch: 97\n",
      "0.5297968983650208 -0.23785575502757728\n",
      "Mean Squared Error: 0.569993793964386 -0.30311601682938294\n",
      "------------------epoch: 98\n",
      "0.5223727822303772 -0.30657763221465806\n",
      "Mean Squared Error: 0.581312894821167 -0.422116928099469\n",
      "------------------epoch: 99\n",
      "0.5206742286682129 -0.1787367224255021\n",
      "Mean Squared Error: 0.5789592266082764 -0.2772361328093955\n",
      "------------------epoch: 100\n",
      "0.5222408771514893 -0.233894337987546\n",
      "Mean Squared Error: 0.5761098265647888 -0.3153696253345759\n",
      "------------------epoch: 101\n",
      "0.5211852192878723 -0.2176273692080415\n",
      "Mean Squared Error: 0.5775055885314941 -0.318209463995883\n",
      "------------------epoch: 102\n",
      "0.5189494490623474 -0.1844028418114787\n",
      "Mean Squared Error: 0.5665677189826965 -0.2934429183924925\n",
      "------------------epoch: 103\n",
      "0.5194764137268066 -0.26790227620246965\n",
      "Mean Squared Error: 0.5707438588142395 -0.3499832366394149\n",
      "------------------epoch: 104\n",
      "0.5173643827438354 -0.25495073887841135\n",
      "Mean Squared Error: 0.5731906294822693 -0.3446573077998172\n",
      "------------------epoch: 105\n",
      "0.526991605758667 -0.10084534033309356\n",
      "Mean Squared Error: 0.5773035883903503 -0.17401048892741944\n",
      "------------------epoch: 106\n",
      "0.5245010256767273 -0.3191594654069463\n",
      "Mean Squared Error: 0.5745291113853455 -0.4027934957084651\n",
      "------------------epoch: 107\n",
      "0.5204657316207886 -0.25097487739723934\n",
      "Mean Squared Error: 0.5704500079154968 -0.3421117512537222\n",
      "------------------epoch: 108\n",
      "0.5155217051506042 -0.19207465632667797\n",
      "Mean Squared Error: 0.5692549347877502 -0.27336263653934423\n",
      "------------------epoch: 109\n",
      "0.5180724859237671 -0.24678138223831514\n",
      "Mean Squared Error: 0.5722655653953552 -0.32412535876998927\n",
      "------------------epoch: 110\n",
      "0.5204570293426514 -0.15933207422457563\n",
      "Mean Squared Error: 0.5638133883476257 -0.25065481305946524\n",
      "------------------epoch: 111\n",
      "0.5134130120277405 -0.1975687796638288\n",
      "Mean Squared Error: 0.5707182884216309 -0.30313078760883694\n",
      "------------------epoch: 112\n",
      "0.5117325186729431 -0.21937106187298006\n",
      "Mean Squared Error: 0.5598841905593872 -0.3137994531004724\n",
      "------------------epoch: 113\n",
      "0.5115768313407898 -0.21127933474481497\n",
      "Mean Squared Error: 0.562588095664978 -0.2865469729301928\n",
      "------------------epoch: 114\n",
      "0.5083352327346802 -0.11539609257236272\n",
      "Mean Squared Error: 0.5697031021118164 -0.21327443168939575\n",
      "------------------epoch: 115\n",
      "0.5098149180412292 -0.15539632958471472\n",
      "Mean Squared Error: 0.5706318020820618 -0.26139089902381274\n",
      "------------------epoch: 116\n",
      "0.511572539806366 -0.14701240519837855\n",
      "Mean Squared Error: 0.5698273181915283 -0.28421285640033234\n",
      "------------------epoch: 117\n",
      "0.5054059624671936 -0.16966151439752797\n",
      "Mean Squared Error: 0.5599066615104675 -0.24730002460210776\n",
      "------------------epoch: 118\n",
      "0.5050947070121765 -0.17766382971406336\n",
      "Mean Squared Error: 0.5639144778251648 -0.3041180054638515\n",
      "------------------epoch: 119\n",
      "0.5100423097610474 -0.18349911466170465\n",
      "Mean Squared Error: 0.5623028874397278 -0.27967705497772877\n",
      "------------------epoch: 120\n",
      "0.4995611608028412 -0.06597579297576095\n",
      "Mean Squared Error: 0.5689759850502014 -0.18943965515060457\n",
      "------------------epoch: 121\n",
      "0.5015324950218201 -0.07744392082365104\n",
      "Mean Squared Error: 0.5642905831336975 -0.21115511909331874\n",
      "------------------epoch: 122\n",
      "0.5043914914131165 -0.2238571905047846\n",
      "Mean Squared Error: 0.5702449083328247 -0.32611498108105974\n",
      "------------------epoch: 123\n",
      "0.49547791481018066 -0.13725645447033252\n",
      "Mean Squared Error: 0.5606703162193298 -0.2429234819642896\n",
      "------------------epoch: 124\n",
      "0.5004677176475525 -0.08651577006192612\n",
      "Mean Squared Error: 0.5571956038475037 -0.1842823138374401\n",
      "------------------epoch: 125\n",
      "0.5026743412017822 -0.11119186207199494\n",
      "Mean Squared Error: 0.5643516182899475 -0.24121500085315173\n",
      "------------------epoch: 126\n",
      "0.5009639263153076 -0.13805958164301058\n",
      "Mean Squared Error: 0.5600835084915161 -0.22074970126901117\n",
      "------------------epoch: 127\n",
      "0.4988614022731781 -0.11113752011459588\n",
      "Mean Squared Error: 0.5607722997665405 -0.2150393276656366\n",
      "------------------epoch: 128\n",
      "0.4924617409706116 -0.07198279644545202\n",
      "Mean Squared Error: 0.5669112205505371 -0.1880891775568414\n",
      "------------------epoch: 129\n",
      "0.4982399642467499 -0.0909170483110262\n",
      "Mean Squared Error: 0.5599218010902405 -0.20386716131488525\n",
      "------------------epoch: 130\n",
      "0.4996385872364044 -0.15546737153421142\n",
      "Mean Squared Error: 0.5515785813331604 -0.27513909923816326\n",
      "------------------epoch: 131\n",
      "0.49567747116088867 -0.1244320509303527\n",
      "Mean Squared Error: 0.5599511861801147 -0.25320815973403055\n",
      "------------------epoch: 132\n",
      "0.4951363503932953 -0.05444947887541551\n",
      "Mean Squared Error: 0.5603005886077881 -0.16941923793328195\n",
      "------------------epoch: 133\n",
      "0.48968374729156494 -0.056841495542699016\n",
      "Mean Squared Error: 0.570044755935669 -0.19380492806848215\n",
      "------------------epoch: 134\n",
      "0.4982142150402069 -0.09308791469150646\n",
      "Mean Squared Error: 0.5673390030860901 -0.21140471152100226\n",
      "------------------epoch: 135\n",
      "0.49267497658729553 -0.1261361554210647\n",
      "Mean Squared Error: 0.5650270581245422 -0.2554898216248682\n",
      "------------------epoch: 136\n",
      "0.495496541261673 -0.15007745547222973\n",
      "Mean Squared Error: 0.5536353588104248 -0.2581967329719368\n",
      "------------------epoch: 137\n",
      "0.49511218070983887 -0.07038085303476027\n",
      "Mean Squared Error: 0.5616710186004639 -0.17566211177087876\n",
      "------------------epoch: 138\n",
      "0.49127820134162903 -0.03715923179482172\n",
      "Mean Squared Error: 0.558254599571228 -0.15751747891900458\n",
      "------------------epoch: 139\n",
      "0.5017779469490051 -0.14024229655640919\n",
      "Mean Squared Error: 0.568403959274292 -0.29379154039424327\n",
      "------------------epoch: 140\n",
      "0.4902072846889496 -0.0311667297449012\n",
      "Mean Squared Error: 0.5584014654159546 -0.1618926968544967\n",
      "------------------epoch: 141\n",
      "0.4830441474914551 -0.029612438932126395\n",
      "Mean Squared Error: 0.5582988262176514 -0.1831264045034795\n",
      "------------------epoch: 142\n",
      "0.48880690336227417 -0.13630579588764014\n",
      "Mean Squared Error: 0.5573033690452576 -0.2454082317672086\n",
      "------------------epoch: 143\n",
      "0.49233177304267883 -0.09139445695267989\n",
      "Mean Squared Error: 0.5594620108604431 -0.2223231938089547\n",
      "------------------epoch: 144\n",
      "0.4819433093070984 -0.07773737780559187\n",
      "Mean Squared Error: 0.5585338473320007 -0.22605061820723304\n",
      "------------------epoch: 145\n",
      "0.48207059502601624 0.00950773874533506\n",
      "Mean Squared Error: 0.5552669167518616 -0.14046774758469538\n",
      "------------------epoch: 146\n",
      "0.48536252975463867 -0.06693444118134462\n",
      "Mean Squared Error: 0.5615626573562622 -0.19967561072929985\n",
      "------------------epoch: 147\n",
      "0.4863026738166809 -0.06893448429209581\n",
      "Mean Squared Error: 0.558254063129425 -0.2032997363711735\n",
      "------------------epoch: 148\n",
      "0.4841492176055908 -0.047876778093456585\n",
      "Mean Squared Error: 0.5590890645980835 -0.17229812653393917\n",
      "------------------epoch: 149\n",
      "0.47365397214889526 -0.054675887282300106\n",
      "Mean Squared Error: 0.5573795437812805 -0.2204113886164627\n",
      "------------------epoch: 150\n",
      "0.48506247997283936 -0.01434195427517837\n",
      "Mean Squared Error: 0.559994637966156 -0.13233864507194282\n",
      "------------------epoch: 151\n",
      "0.4882698953151703 -0.07839961497114256\n",
      "Mean Squared Error: 0.5603088140487671 -0.2377853338735716\n",
      "------------------epoch: 152\n",
      "0.47946345806121826 0.06581328090871807\n",
      "Mean Squared Error: 0.5541702508926392 -0.07032721745401704\n",
      "------------------epoch: 153\n",
      "0.4816073477268219 -0.08614951893112699\n",
      "Mean Squared Error: 0.5507397055625916 -0.23029446113388907\n",
      "------------------epoch: 154\n",
      "0.47701016068458557 -0.09777554162404622\n",
      "Mean Squared Error: 0.5468543171882629 -0.22890884793453226\n",
      "------------------epoch: 155\n",
      "0.47884315252304077 0.018833527967705765\n",
      "Mean Squared Error: 0.5579504370689392 -0.11285813845208459\n",
      "------------------epoch: 156\n",
      "0.47519007325172424 -0.06408144260313664\n",
      "Mean Squared Error: 0.5593806505203247 -0.25347008746082555\n",
      "------------------epoch: 157\n",
      "0.4821903705596924 -0.0299091782581673\n",
      "Mean Squared Error: 0.5615381002426147 -0.17982242480483523\n",
      "------------------epoch: 158\n",
      "0.47637540102005005 0.03815986269261096\n",
      "Mean Squared Error: 0.5579932928085327 -0.09844496123514435\n",
      "------------------epoch: 159\n",
      "0.46831148862838745 -0.018048685595046576\n",
      "Mean Squared Error: 0.5598483681678772 -0.18319640365510903\n",
      "------------------epoch: 160\n",
      "0.48180973529815674 -0.09126358753273567\n",
      "Mean Squared Error: 0.5566985607147217 -0.2198893662897936\n",
      "------------------epoch: 161\n",
      "0.4764877259731293 0.02333054947235258\n",
      "Mean Squared Error: 0.5522462129592896 -0.11342918818299497\n",
      "------------------epoch: 162\n",
      "0.47311145067214966 -0.027898930084832907\n",
      "Mean Squared Error: 0.5641708970069885 -0.20788096516973154\n",
      "------------------epoch: 163\n",
      "0.4788062274456024 0.028520519478091755\n",
      "Mean Squared Error: 0.559898316860199 -0.14373563578695014\n",
      "------------------epoch: 164\n",
      "0.4784412980079651 -0.050392171118336826\n",
      "Mean Squared Error: 0.5534079074859619 -0.18565444130242792\n",
      "------------------epoch: 165\n",
      "0.4766896665096283 -0.07852606750657731\n",
      "Mean Squared Error: 0.5547052621841431 -0.23324225062546122\n",
      "------------------epoch: 166\n",
      "0.47925591468811035 0.0586352250771941\n",
      "Mean Squared Error: 0.5584313869476318 -0.10540986393853591\n",
      "------------------epoch: 167\n",
      "0.47082293033599854 -0.04970788250362834\n",
      "Mean Squared Error: 0.5551361441612244 -0.23143563271355605\n",
      "------------------epoch: 168\n",
      "0.4729270040988922 -0.03582580739819141\n",
      "Mean Squared Error: 0.5570272207260132 -0.18875840964414548\n",
      "------------------epoch: 169\n",
      "0.4790460169315338 0.07692847898213118\n",
      "Mean Squared Error: 0.5636963844299316 -0.0667294856395344\n",
      "------------------epoch: 170\n",
      "0.46821776032447815 -0.03198932826166434\n",
      "Mean Squared Error: 0.5537704825401306 -0.1815851819447709\n",
      "------------------epoch: 171\n",
      "0.4662996232509613 0.003918413955898314\n",
      "Mean Squared Error: 0.5474735498428345 -0.1580022944655004\n",
      "------------------epoch: 172\n",
      "0.4665803611278534 0.09028142306766707\n",
      "Mean Squared Error: 0.5646060705184937 -0.0690886717419048\n",
      "------------------epoch: 173\n",
      "0.46371951699256897 -0.05217931896753236\n",
      "Mean Squared Error: 0.5603301525115967 -0.21528367800342996\n",
      "------------------epoch: 174\n",
      "0.4662085771560669 -0.03671585360897267\n",
      "Mean Squared Error: 0.5523266196250916 -0.17749640220419916\n",
      "------------------epoch: 175\n",
      "0.4722192585468292 0.08108116228228102\n",
      "Mean Squared Error: 0.5587978959083557 -0.06754875614572642\n",
      "------------------epoch: 176\n",
      "0.47848209738731384 -0.033228154574997726\n",
      "Mean Squared Error: 0.5519093871116638 -0.16275929450720827\n",
      "------------------epoch: 177\n",
      "0.46310511231422424 0.018138577843057835\n",
      "Mean Squared Error: 0.54949951171875 -0.11501486950358641\n",
      "------------------epoch: 178\n",
      "0.4624258577823639 0.05040418632776\n",
      "Mean Squared Error: 0.5554664731025696 -0.11612686245333359\n",
      "------------------epoch: 179\n",
      "0.466378778219223 -0.04033905471135646\n",
      "Mean Squared Error: 0.5559738278388977 -0.21069670110064842\n",
      "------------------epoch: 180\n",
      "0.45672452449798584 0.04299937281549171\n",
      "Mean Squared Error: 0.5525668263435364 -0.15259660729491564\n",
      "------------------epoch: 181\n",
      "0.456248939037323 0.06186772993033052\n",
      "Mean Squared Error: 0.5504505038261414 -0.12618187995700492\n",
      "------------------epoch: 182\n",
      "0.4588165581226349 0.05998208683553008\n",
      "Mean Squared Error: 0.5484052896499634 -0.12095254851125903\n",
      "------------------epoch: 183\n",
      "0.4664486348628998 0.041876457404569245\n",
      "Mean Squared Error: 0.551922082901001 -0.1153082575934441\n",
      "------------------epoch: 184\n",
      "0.47452494502067566 0.05970433635850669\n",
      "Mean Squared Error: 0.5636729598045349 -0.1085515346032675\n",
      "------------------epoch: 185\n",
      "0.46682560443878174 0.013170110893086506\n",
      "Mean Squared Error: 0.5589672327041626 -0.18615199021201145\n",
      "------------------epoch: 186\n",
      "0.4592377543449402 0.04825419830165889\n",
      "Mean Squared Error: 0.5481204986572266 -0.12025493515556418\n",
      "------------------epoch: 187\n",
      "0.4550955295562744 0.007455195953274263\n",
      "Mean Squared Error: 0.5468460917472839 -0.1917227186937609\n",
      "------------------epoch: 188\n",
      "0.4612070322036743 -0.015495179447717167\n",
      "Mean Squared Error: 0.5536816716194153 -0.21507536361427126\n",
      "------------------epoch: 189\n",
      "0.45914149284362793 0.11088345477081507\n",
      "Mean Squared Error: 0.5537492036819458 -0.058656553134479594\n",
      "------------------epoch: 190\n",
      "0.4639686346054077 0.06997849448445892\n",
      "Mean Squared Error: 0.5498231053352356 -0.08008516288366851\n",
      "------------------epoch: 191\n",
      "0.45990410447120667 0.037256447814241644\n",
      "Mean Squared Error: 0.5424143671989441 -0.09705033733493762\n",
      "------------------epoch: 192\n",
      "0.4473402798175812 0.11146640488711757\n",
      "Mean Squared Error: 0.5496417284011841 -0.08922436355402752\n",
      "------------------epoch: 193\n",
      "0.4625003933906555 0.046655144867854825\n",
      "Mean Squared Error: 0.5543012619018555 -0.14385036242104166\n",
      "------------------epoch: 194\n",
      "0.45214417576789856 0.06031425898795495\n",
      "Mean Squared Error: 0.5477406978607178 -0.12398861560366825\n",
      "------------------epoch: 195\n",
      "0.4627898037433624 0.027237996420573896\n",
      "Mean Squared Error: 0.5472716093063354 -0.12200650771451205\n",
      "------------------epoch: 196\n",
      "0.45818087458610535 0.02936411010229978\n",
      "Mean Squared Error: 0.5532204508781433 -0.14765923106591416\n",
      "------------------epoch: 197\n",
      "0.45513805747032166 0.07913522571130438\n",
      "Mean Squared Error: 0.5472211241722107 -0.0859177509040121\n",
      "------------------epoch: 198\n",
      "0.45257648825645447 0.11310933132115486\n",
      "Mean Squared Error: 0.5489100217819214 -0.0467579098786608\n",
      "------------------epoch: 199\n",
      "0.45748353004455566 0.08559992834452745\n",
      "Mean Squared Error: 0.5573030114173889 -0.08721516535305152\n",
      "------------------epoch: 200\n",
      "0.4512386918067932 0.09767637675743213\n",
      "Mean Squared Error: 0.5514875650405884 -0.08927220718212081\n",
      "------------------epoch: 201\n",
      "0.45556920766830444 0.020862396961140672\n",
      "Mean Squared Error: 0.5457581877708435 -0.15379567944609707\n",
      "------------------epoch: 202\n",
      "0.4554802179336548 0.04594042336067106\n",
      "Mean Squared Error: 0.5527760982513428 -0.15440035134505647\n",
      "------------------epoch: 203\n",
      "0.459831178188324 0.1266836141427049\n",
      "Mean Squared Error: 0.55538409948349 -0.058771800031463206\n",
      "------------------epoch: 204\n",
      "0.4508492350578308 0.05405201821999861\n",
      "Mean Squared Error: 0.5544099807739258 -0.15754902627064427\n",
      "------------------epoch: 205\n",
      "0.45318594574928284 0.09630051489340374\n",
      "Mean Squared Error: 0.551724910736084 -0.09436251297970544\n",
      "------------------epoch: 206\n",
      "0.45091548562049866 0.11780348910725313\n",
      "Mean Squared Error: 0.5468559861183167 -0.03674563612578452\n",
      "------------------epoch: 207\n",
      "0.4539623558521271 0.07503950367641288\n",
      "Mean Squared Error: 0.5510568618774414 -0.09184859712315885\n",
      "------------------epoch: 208\n",
      "0.4525556266307831 0.07976262186047656\n",
      "Mean Squared Error: 0.5446619391441345 -0.07903979433405461\n",
      "------------------epoch: 209\n",
      "0.4492712616920471 0.08730283733774091\n",
      "Mean Squared Error: 0.5463982820510864 -0.09805017248799319\n",
      "------------------epoch: 210\n",
      "0.4434437155723572 0.06768959799865804\n",
      "Mean Squared Error: 0.550419807434082 -0.12623697404195688\n",
      "------------------epoch: 211\n",
      "0.4522349238395691 0.13596704626368272\n",
      "Mean Squared Error: 0.5502051711082458 -0.059770257971110574\n",
      "------------------epoch: 212\n",
      "0.4469868242740631 0.07643067005316018\n",
      "Mean Squared Error: 0.5444930791854858 -0.09581018132312513\n",
      "------------------epoch: 213\n",
      "0.4411472678184509 0.11133047576100019\n",
      "Mean Squared Error: 0.5396878719329834 -0.07359475125155335\n",
      "------------------epoch: 214\n",
      "0.438994437456131 0.10528598401230271\n",
      "Mean Squared Error: 0.5495782494544983 -0.09718180895188633\n",
      "------------------epoch: 215\n",
      "0.44337475299835205 0.15130839279738284\n",
      "Mean Squared Error: 0.5473074316978455 -0.02598107014344997\n",
      "------------------epoch: 216\n",
      "0.44568589329719543 0.10370838051969888\n",
      "Mean Squared Error: 0.5494227409362793 -0.09878945981678089\n",
      "------------------epoch: 217\n",
      "0.4402243196964264 0.1088445911336463\n",
      "Mean Squared Error: 0.5426768660545349 -0.07930380726844932\n",
      "------------------epoch: 218\n",
      "0.4458713233470917 0.08802513393696865\n",
      "Mean Squared Error: 0.5512920022010803 -0.115945870358241\n",
      "------------------epoch: 219\n",
      "0.45149070024490356 0.13360848704261785\n",
      "Mean Squared Error: 0.5441624522209167 -0.03484679394093315\n",
      "------------------epoch: 220\n",
      "0.4384094774723053 0.08456310002902168\n",
      "Mean Squared Error: 0.5536022186279297 -0.1648297770964331\n",
      "------------------epoch: 221\n",
      "0.4385760724544525 0.139109893660604\n",
      "Mean Squared Error: 0.5528100728988647 -0.0739187629399578\n",
      "------------------epoch: 222\n",
      "0.4421202540397644 0.16184078505144206\n",
      "Mean Squared Error: 0.5520427823066711 -0.030430567265571362\n",
      "------------------epoch: 223\n",
      "0.44959113001823425 0.07291013127388324\n",
      "Mean Squared Error: 0.5503636598587036 -0.12438099849400697\n",
      "------------------epoch: 224\n",
      "0.4565068185329437 0.10812739275258043\n",
      "Mean Squared Error: 0.5539757013320923 -0.05812532112565161\n",
      "------------------epoch: 225\n",
      "0.4350637197494507 0.05757270266824044\n",
      "Mean Squared Error: 0.5403063893318176 -0.15027153919436254\n",
      "------------------epoch: 226\n",
      "0.43628549575805664 0.08712881553740948\n",
      "Mean Squared Error: 0.5417739152908325 -0.10864991228817344\n",
      "------------------epoch: 227\n",
      "0.4497222304344177 0.15883405246602667\n",
      "Mean Squared Error: 0.553451418876648 -0.009992009169400795\n",
      "------------------epoch: 228\n",
      "0.453050434589386 0.09180684444489517\n",
      "Mean Squared Error: 0.5518876314163208 -0.11105739721731722\n",
      "------------------epoch: 229\n",
      "0.43905529379844666 0.13909739239455332\n",
      "Mean Squared Error: 0.5517401099205017 -0.04068346388494337\n",
      "------------------epoch: 230\n",
      "0.43546226620674133 0.14098836734718379\n",
      "Mean Squared Error: 0.5485790967941284 -0.0730339800510571\n",
      "------------------epoch: 231\n",
      "0.4467315971851349 0.10472529995753932\n",
      "Mean Squared Error: 0.5499793291091919 -0.09397461150193931\n",
      "------------------epoch: 232\n",
      "0.439781129360199 0.1338123811169034\n",
      "Mean Squared Error: 0.5433045029640198 -0.052343588566944765\n",
      "------------------epoch: 233\n",
      "0.4389301538467407 0.06052425706863074\n",
      "Mean Squared Error: 0.5490266680717468 -0.15201115745206506\n",
      "------------------epoch: 234\n",
      "0.44025465846061707 0.13484134407949955\n",
      "Mean Squared Error: 0.5438771843910217 -0.06672015576046308\n",
      "------------------epoch: 235\n",
      "0.43794625997543335 0.17004080565715574\n",
      "Mean Squared Error: 0.5528402924537659 -0.01864215091659993\n",
      "------------------epoch: 236\n",
      "0.4367523789405823 0.14820363899620392\n",
      "Mean Squared Error: 0.5451157689094543 -0.06896362850727189\n",
      "------------------epoch: 237\n",
      "0.44411537051200867 0.11467612677610539\n",
      "Mean Squared Error: 0.540057897567749 -0.059177905676454534\n",
      "------------------epoch: 238\n",
      "0.4504088759422302 0.09652455824115236\n",
      "Mean Squared Error: 0.5471606850624084 -0.07766933867021097\n",
      "------------------epoch: 239\n",
      "0.43894168734550476 0.11855887851237967\n",
      "Mean Squared Error: 0.5484912991523743 -0.12090222777050941\n",
      "------------------epoch: 240\n",
      "0.4383717179298401 0.08914959689022939\n",
      "Mean Squared Error: 0.5474542379379272 -0.129008325895972\n",
      "------------------epoch: 241\n",
      "0.4399767518043518 0.12296026072146948\n",
      "Mean Squared Error: 0.5460838079452515 -0.0730076151411021\n",
      "------------------epoch: 242\n",
      "0.44057244062423706 0.20191664375188523\n",
      "Mean Squared Error: 0.5524086952209473 0.022050768201038795\n",
      "------------------epoch: 243\n",
      "0.43445998430252075 0.1847807279521091\n",
      "Mean Squared Error: 0.5509559512138367 -0.03801766814355645\n",
      "------------------epoch: 244\n",
      "0.43635034561157227 0.12773058713821717\n",
      "Mean Squared Error: 0.5552645921707153 -0.08722876731137297\n",
      "------------------epoch: 245\n",
      "0.4363452196121216 0.16183215403001894\n",
      "Mean Squared Error: 0.5475361347198486 -0.0561015541322456\n",
      "------------------epoch: 246\n",
      "0.43433159589767456 0.06699439955871289\n",
      "Mean Squared Error: 0.541594386100769 -0.17530669303449797\n",
      "------------------epoch: 247\n",
      "0.42779791355133057 0.07940405284338581\n",
      "Mean Squared Error: 0.5408269166946411 -0.1240304015133935\n",
      "------------------epoch: 248\n",
      "0.4358704686164856 0.1869059829670986\n",
      "Mean Squared Error: 0.5467114448547363 -0.02883934814532596\n",
      "------------------epoch: 249\n",
      "0.43494462966918945 0.16524563393281488\n",
      "Mean Squared Error: 0.548237144947052 -0.05316187402433936\n",
      "------------------epoch: 250\n",
      "0.43945929408073425 0.1534928136478153\n",
      "Mean Squared Error: 0.5448862910270691 -0.04107391527535498\n",
      "------------------epoch: 251\n",
      "0.4438125491142273 0.16068839784726074\n",
      "Mean Squared Error: 0.5506306886672974 -0.025150021695363067\n",
      "------------------epoch: 252\n",
      "0.44441521167755127 0.06554902250421402\n",
      "Mean Squared Error: 0.5527681708335876 -0.1466775742336841\n",
      "------------------epoch: 253\n",
      "0.43364524841308594 0.20414831763707553\n",
      "Mean Squared Error: 0.5530155897140503 -0.003082676608546109\n",
      "------------------epoch: 254\n",
      "0.435167521238327 0.17245449462482476\n",
      "Mean Squared Error: 0.5436159372329712 -0.013515004249018858\n",
      "------------------epoch: 255\n",
      "0.42796221375465393 0.08120077315756102\n",
      "Mean Squared Error: 0.5458934307098389 -0.1401362555760215\n",
      "------------------epoch: 256\n",
      "0.4229435324668884 0.13372842963495823\n",
      "Mean Squared Error: 0.5459571480751038 -0.09691505360102637\n",
      "------------------epoch: 257\n",
      "0.4344201385974884 0.22347814209267491\n",
      "Mean Squared Error: 0.5567560195922852 0.007504511283915494\n",
      "------------------epoch: 258\n",
      "0.4298146665096283 0.15911697313707884\n",
      "Mean Squared Error: 0.5491968393325806 -0.0663493098022303\n",
      "------------------epoch: 259\n",
      "0.42554235458374023 0.16232282764020167\n",
      "Mean Squared Error: 0.5469368696212769 -0.05210119434925908\n",
      "------------------epoch: 260\n",
      "0.4378250539302826 0.19235534182893033\n",
      "Mean Squared Error: 0.5473201870918274 -0.004484660904650717\n",
      "------------------epoch: 261\n",
      "0.43906718492507935 0.09308500990462731\n",
      "Mean Squared Error: 0.5468127727508545 -0.12345175367961958\n",
      "------------------epoch: 262\n",
      "0.43036675453186035 0.14790765864690403\n",
      "Mean Squared Error: 0.5434561371803284 -0.07565530129955711\n",
      "------------------epoch: 263\n",
      "0.4211936593055725 0.16835718758753315\n",
      "Mean Squared Error: 0.5417857766151428 -0.050498226422075465\n",
      "------------------epoch: 264\n",
      "0.4212297201156616 0.1716766119671581\n",
      "Mean Squared Error: 0.5437371730804443 -0.05148587650929515\n",
      "------------------epoch: 265\n",
      "0.43094050884246826 0.13152248094942476\n",
      "Mean Squared Error: 0.5457696914672852 -0.08353009168360748\n",
      "------------------epoch: 266\n",
      "0.42001157999038696 0.25404904705858466\n",
      "Mean Squared Error: 0.553878903388977 0.01715394563333461\n",
      "------------------epoch: 267\n",
      "0.4293160140514374 0.20769108651335555\n",
      "Mean Squared Error: 0.5477030873298645 -0.017846484589910894\n",
      "------------------epoch: 268\n",
      "0.4256121516227722 0.13422979273639446\n",
      "Mean Squared Error: 0.5447046756744385 -0.10101861146811442\n",
      "------------------epoch: 269\n",
      "0.422883003950119 0.1730699790321487\n",
      "Mean Squared Error: 0.5458131432533264 -0.04479302362474691\n",
      "------------------epoch: 270\n",
      "0.4322563111782074 0.179662841427639\n",
      "Mean Squared Error: 0.5489747524261475 -0.0505833403489091\n",
      "------------------epoch: 271\n",
      "0.4290243089199066 0.20854601367528214\n",
      "Mean Squared Error: 0.5480239987373352 -0.00646213548009178\n",
      "------------------epoch: 272\n",
      "0.4211822748184204 0.16895901216078524\n",
      "Mean Squared Error: 0.5493484139442444 -0.07205955640336281\n",
      "------------------epoch: 273\n",
      "0.4307221472263336 0.17319517259606132\n",
      "Mean Squared Error: 0.542725682258606 -0.00915240473179102\n",
      "------------------epoch: 274\n",
      "0.4190836250782013 0.15833058839761005\n",
      "Mean Squared Error: 0.5420523881912231 -0.07197715427226048\n",
      "------------------epoch: 275\n",
      "0.4284736216068268 0.13267878893759\n",
      "Mean Squared Error: 0.5464117527008057 -0.08599654505623211\n",
      "------------------epoch: 276\n",
      "0.4220709800720215 0.22468867720098906\n",
      "Mean Squared Error: 0.5419649481773376 0.016203139207304096\n",
      "------------------epoch: 277\n",
      "0.4248644709587097 0.24066115591966886\n",
      "Mean Squared Error: 0.5483284592628479 0.005726721627376641\n",
      "------------------epoch: 278\n",
      "0.4212058484554291 0.11817532895305338\n",
      "Mean Squared Error: 0.5496701002120972 -0.13180386965728585\n",
      "------------------epoch: 279\n",
      "0.43139395117759705 0.16200613844753387\n",
      "Mean Squared Error: 0.5476351380348206 -0.024939218500943383\n",
      "------------------epoch: 280\n",
      "0.41856664419174194 0.16153537546150942\n",
      "Mean Squared Error: 0.5403553247451782 -0.06317237978234713\n",
      "------------------epoch: 281\n",
      "0.4268626570701599 0.16593900489011937\n",
      "Mean Squared Error: 0.5410696268081665 -0.03085078814329134\n",
      "------------------epoch: 282\n",
      "0.41719552874565125 0.2556696801218409\n",
      "Mean Squared Error: 0.5476195812225342 0.032530840798364546\n",
      "------------------epoch: 283\n",
      "0.4145858585834503 0.23995335588890354\n",
      "Mean Squared Error: 0.5466141104698181 -0.00014154541541833154\n",
      "------------------epoch: 284\n",
      "0.4168813228607178 0.23051040441887938\n",
      "Mean Squared Error: 0.5424387454986572 0.019878456199555306\n",
      "------------------epoch: 285\n",
      "0.41688272356987 0.18742124885502542\n",
      "Mean Squared Error: 0.5511307716369629 -0.03356836417981479\n",
      "------------------epoch: 286\n",
      "0.4233565330505371 0.16176936179210355\n",
      "Mean Squared Error: 0.5436115264892578 -0.03245801704457918\n",
      "------------------epoch: 287\n",
      "0.42746493220329285 0.14284123756281797\n",
      "Mean Squared Error: 0.5424320697784424 -0.0779784085353894\n",
      "------------------epoch: 288\n",
      "0.42442598938941956 0.1875476375603543\n",
      "Mean Squared Error: 0.5409067869186401 -0.04303660528784903\n",
      "------------------epoch: 289\n",
      "0.4207056760787964 0.24502855885924812\n",
      "Mean Squared Error: 0.5450929999351501 0.006272520738899168\n",
      "------------------epoch: 290\n",
      "0.41528716683387756 0.21839303256104758\n",
      "Mean Squared Error: 0.5501333475112915 0.0015445406889323943\n",
      "------------------epoch: 291\n",
      "0.42498210072517395 0.2445426245297535\n",
      "Mean Squared Error: 0.5469589233398438 0.013337564870755991\n",
      "------------------epoch: 292\n",
      "0.42430877685546875 0.10437060302335355\n",
      "Mean Squared Error: 0.5413843989372253 -0.12116459644115274\n",
      "------------------epoch: 293\n",
      "0.4217921495437622 0.19207876292655357\n",
      "Mean Squared Error: 0.5454972386360168 -0.06122984113998475\n",
      "------------------epoch: 294\n",
      "0.4203214645385742 0.17391368247234706\n",
      "Mean Squared Error: 0.5396774411201477 -0.06276238950140867\n",
      "------------------epoch: 295\n",
      "0.4152354598045349 0.16183249668249844\n",
      "Mean Squared Error: 0.5490438342094421 -0.10242670430109091\n",
      "------------------epoch: 296\n",
      "0.4136395752429962 0.2474799433128867\n",
      "Mean Squared Error: 0.5387766361236572 0.03745271007556095\n",
      "------------------epoch: 297\n",
      "0.40118661522865295 0.2944705388131119\n",
      "Mean Squared Error: 0.559454083442688 0.03947435719198156\n",
      "------------------epoch: 298\n",
      "0.4193100929260254 0.1803605804992393\n",
      "Mean Squared Error: 0.5509253740310669 -0.061834245335322446\n",
      "------------------epoch: 299\n",
      "0.42807045578956604 0.22836041932739126\n",
      "Mean Squared Error: 0.5493119359016418 -0.02056641881674892\n"
     ]
    }
   ],
   "source": [
    "#optimizer = optim.SGD(GNN.parameters(), lr=0.01,momentum = 0.9,weight_decay=0.00005)\n",
    "for epoch in range(200):\n",
    "    GNN.train()\n",
    "    predictions = GNN(graph, node_features)\n",
    "    loss = loss_fn(predictions[idx_train], labels[idx_train])\n",
    "    r2_train = r2_fun(predictions[idx_train], labels[idx_train])\n",
    "    print('------------------epoch:', epoch)\n",
    "    print(loss.item(),r2_train.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    mse = F.mse_loss(predictions[idx_test], labels[idx_test])\n",
    "    r1 = r2_fun(predictions[idx_test], labels[idx_test])\n",
    "    print('Mean Squared Error:', mse.item(), r1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a6229f5-d115-448c-9f68-01857c96a813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23140, 1)\n",
      "Mean Squared Error: 0.49455630562320785 3.5159402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "GNN.eval()\n",
    "output= GNN(graph,node_features)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "s_y = dataset.ss_y\n",
    "y_pre = s_y.inverse_transform(output.detach().numpy())\n",
    "y_ture = s_y.inverse_transform(labels.detach().numpy())\n",
    "print(y_pre.shape)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_ture[idx_test], y_pre[idx_test])\n",
    "mse = mean_squared_error(y_ture[idx_test], y_pre[idx_test])\n",
    "mae = mean_absolute_error(y_ture[idx_test], y_pre[idx_test])\n",
    "\n",
    "print(\"Mean Squared Error:\", r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "198b60ae-4b7b-42eb-bd50-8c7baccaa894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--fastmode', action='store_true', default=False,\n",
    "                    help='Validate during training pass.')\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=200,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.008,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-5,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--num_heads', type=int, default=8,\n",
    "                    help='Attention heads.')\n",
    "parser.add_argument('--l_nums', type=int, default=3,\n",
    "                    help='Number of EGATLayer.')\n",
    "parser.add_argument('--lamda', type=float, default=0.85,\n",
    "                    help='The node feature ratio.')\n",
    "args =parser.parse_known_args()[0]\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "# Load data\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    device = torch.device('cuda:0')\n",
    "# Model and optimizer\n",
    "model = EGAT(node_feats=node_features.shape[1],\n",
    "            edge_feats=edge_features.shape[1],\n",
    "            f_h = 128,\n",
    "            f_e = 128,\n",
    "            lamda = args.lamda,\n",
    "            num_heads = args.num_heads,\n",
    "            dropout=args.dropout,\n",
    "            pred_hid = 128, \n",
    "            l_num = args.l_nums, \n",
    "             )\n",
    "optimizer = optim.Adam(model.parameters(),lr=args.lr, weight_decay=args.weight_decay)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01,momentum = 0.9,weight_decay=args.weight_decay)\n",
    "if args.cuda:\n",
    "    #print(\"pppppppppppppppppppppppppppp\")\n",
    "    graph = graph.to(device)\n",
    "    model = model.to(device)\n",
    "    node_features = node_features.to(device)\n",
    "    edge_features = edge_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "    idx_train = idx_train.to(device)\n",
    "    idx_val = idx_val.to(device)\n",
    "    idx_test = idx_test.to(device)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(graph, node_features, edge_features)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    loss_train = loss_func(output[idx_train], labels[idx_train])\n",
    "    print(\"loss------------------------------------------------------111\")\n",
    "    r2_train = r2_fun(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if not args.fastmode:\n",
    "        model.eval()\n",
    "        output = model(graph, node_features, edge_features)\n",
    "\n",
    "    #loss_val = F.cross_entropy(output[idx_val], labels[idx_val]).to(device)\n",
    "    loss_val = loss_func(output[idx_test],labels[idx_test])\n",
    "    r2_val = r2_fun(output[idx_test], labels[idx_test])\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'r2_train: {:.4f}'.format(r2_train.item()),\n",
    "         'r2_val: {:.4f}'.format(r2_val.item()))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(graph, node_features, edge_features)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    loss_test = loss_func(output[idx_test], labels[idx_test])\n",
    "    r2_test = r2_fun(output[idx_test], labels[idx_test])\n",
    "    \n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "         \"r2_loss= {:.4f}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07e07b1d-a4a9-4999-bcaa-797f501f0435",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0001 loss_train: 0.7938 loss_val: 0.9735 r2_train: -3.3271 r2_val: -0.3756\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0002 loss_train: 0.9631 loss_val: 0.7381 r2_train: -0.3761 r2_val: -2.3646\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0003 loss_train: 0.7285 loss_val: 0.7549 r2_train: -2.3437 r2_val: -5.9210\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0004 loss_train: 0.7419 loss_val: 0.7832 r2_train: -5.9265 r2_val: -4.6476\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0005 loss_train: 0.7632 loss_val: 0.7453 r2_train: -4.5665 r2_val: -3.2613\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0006 loss_train: 0.7253 loss_val: 0.7128 r2_train: -3.2167 r2_val: -2.0742\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0007 loss_train: 0.6925 loss_val: 0.7094 r2_train: -1.9822 r2_val: -1.3036\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0008 loss_train: 0.6899 loss_val: 0.7118 r2_train: -1.2606 r2_val: -1.1030\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0009 loss_train: 0.6951 loss_val: 0.7016 r2_train: -1.0482 r2_val: -1.2697\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0010 loss_train: 0.6850 loss_val: 0.6935 r2_train: -1.2400 r2_val: -1.5512\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0011 loss_train: 0.6806 loss_val: 0.6933 r2_train: -1.5809 r2_val: -1.6853\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0012 loss_train: 0.6784 loss_val: 0.6936 r2_train: -1.6692 r2_val: -1.5591\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0013 loss_train: 0.6755 loss_val: 0.6926 r2_train: -1.5468 r2_val: -1.3659\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0014 loss_train: 0.6727 loss_val: 0.6904 r2_train: -1.3518 r2_val: -1.2362\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0015 loss_train: 0.6679 loss_val: 0.6877 r2_train: -1.1875 r2_val: -1.2051\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0016 loss_train: 0.6653 loss_val: 0.6843 r2_train: -1.1446 r2_val: -1.2518\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0017 loss_train: 0.6636 loss_val: 0.6821 r2_train: -1.2062 r2_val: -1.4177\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0018 loss_train: 0.6604 loss_val: 0.6798 r2_train: -1.3327 r2_val: -1.4909\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0019 loss_train: 0.6611 loss_val: 0.6774 r2_train: -1.4702 r2_val: -1.3923\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0020 loss_train: 0.6567 loss_val: 0.6758 r2_train: -1.3611 r2_val: -1.2288\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0021 loss_train: 0.6527 loss_val: 0.6749 r2_train: -1.2163 r2_val: -1.1193\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0022 loss_train: 0.6528 loss_val: 0.6758 r2_train: -1.0922 r2_val: -1.1181\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0023 loss_train: 0.6474 loss_val: 0.6644 r2_train: -1.0559 r2_val: -1.1899\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0024 loss_train: 0.6412 loss_val: 0.6596 r2_train: -1.1392 r2_val: -1.2205\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0025 loss_train: 0.6385 loss_val: 0.6558 r2_train: -1.1604 r2_val: -1.1449\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0026 loss_train: 0.6369 loss_val: 0.6523 r2_train: -1.0883 r2_val: -1.0113\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0027 loss_train: 0.6305 loss_val: 0.6507 r2_train: -0.9717 r2_val: -0.9470\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0028 loss_train: 0.6273 loss_val: 0.6473 r2_train: -0.9058 r2_val: -0.9991\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0029 loss_train: 0.6244 loss_val: 0.6421 r2_train: -0.9610 r2_val: -1.0460\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0030 loss_train: 0.6204 loss_val: 0.6406 r2_train: -1.0095 r2_val: -0.9579\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0031 loss_train: 0.6192 loss_val: 0.6385 r2_train: -0.9180 r2_val: -0.7782\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0032 loss_train: 0.6134 loss_val: 0.6412 r2_train: -0.7504 r2_val: -0.7260\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0033 loss_train: 0.6123 loss_val: 0.6322 r2_train: -0.6796 r2_val: -0.8788\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0034 loss_train: 0.6065 loss_val: 0.6275 r2_train: -0.8321 r2_val: -0.9341\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0035 loss_train: 0.6024 loss_val: 0.6255 r2_train: -0.8854 r2_val: -0.7435\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0036 loss_train: 0.5987 loss_val: 0.6218 r2_train: -0.6768 r2_val: -0.6347\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0037 loss_train: 0.5933 loss_val: 0.6184 r2_train: -0.5947 r2_val: -0.7054\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0038 loss_train: 0.5892 loss_val: 0.6141 r2_train: -0.6550 r2_val: -0.7366\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0039 loss_train: 0.5845 loss_val: 0.6076 r2_train: -0.6623 r2_val: -0.6179\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0040 loss_train: 0.5789 loss_val: 0.6112 r2_train: -0.5639 r2_val: -0.6832\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0041 loss_train: 0.5797 loss_val: 0.6060 r2_train: -0.6238 r2_val: -0.6621\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0042 loss_train: 0.5790 loss_val: 0.6012 r2_train: -0.6129 r2_val: -0.5097\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0043 loss_train: 0.5712 loss_val: 0.6072 r2_train: -0.4490 r2_val: -0.6969\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0044 loss_train: 0.5794 loss_val: 0.6049 r2_train: -0.6727 r2_val: -0.4022\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0045 loss_train: 0.5753 loss_val: 0.5930 r2_train: -0.3460 r2_val: -0.5337\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0046 loss_train: 0.5652 loss_val: 0.5950 r2_train: -0.4836 r2_val: -0.5966\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0047 loss_train: 0.5672 loss_val: 0.5856 r2_train: -0.5714 r2_val: -0.4481\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0048 loss_train: 0.5575 loss_val: 0.5886 r2_train: -0.4004 r2_val: -0.4235\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0049 loss_train: 0.5602 loss_val: 0.5774 r2_train: -0.3801 r2_val: -0.4841\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0050 loss_train: 0.5485 loss_val: 0.5738 r2_train: -0.4448 r2_val: -0.4049\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0051 loss_train: 0.5470 loss_val: 0.5710 r2_train: -0.3735 r2_val: -0.4005\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0052 loss_train: 0.5434 loss_val: 0.5725 r2_train: -0.3730 r2_val: -0.3487\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0053 loss_train: 0.5400 loss_val: 0.5664 r2_train: -0.3056 r2_val: -0.2882\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0054 loss_train: 0.5361 loss_val: 0.5680 r2_train: -0.2507 r2_val: -0.4727\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0055 loss_train: 0.5385 loss_val: 0.5603 r2_train: -0.4138 r2_val: -0.2181\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0056 loss_train: 0.5297 loss_val: 0.5666 r2_train: -0.1648 r2_val: -0.2963\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0057 loss_train: 0.5352 loss_val: 0.5583 r2_train: -0.2438 r2_val: -0.2043\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0058 loss_train: 0.5252 loss_val: 0.5663 r2_train: -0.1465 r2_val: -0.5619\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0059 loss_train: 0.5393 loss_val: 0.5972 r2_train: -0.5298 r2_val: 0.0367\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0060 loss_train: 0.5638 loss_val: 0.5915 r2_train: 0.0810 r2_val: -1.1282\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0061 loss_train: 0.5657 loss_val: 0.5723 r2_train: -1.0248 r2_val: -0.3949\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0062 loss_train: 0.5374 loss_val: 0.5824 r2_train: -0.3642 r2_val: 0.0106\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0063 loss_train: 0.5482 loss_val: 0.5657 r2_train: 0.0433 r2_val: -0.4782\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0064 loss_train: 0.5339 loss_val: 0.5736 r2_train: -0.4433 r2_val: -0.8986\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0065 loss_train: 0.5533 loss_val: 0.5472 r2_train: -0.8588 r2_val: -0.4007\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0066 loss_train: 0.5198 loss_val: 0.6081 r2_train: -0.3826 r2_val: -0.2203\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0067 loss_train: 0.5455 loss_val: 0.5649 r2_train: -0.0903 r2_val: -0.3157\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0068 loss_train: 0.5339 loss_val: 0.5553 r2_train: -0.2579 r2_val: -0.5186\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0069 loss_train: 0.5206 loss_val: 0.5907 r2_train: -0.5240 r2_val: -0.5236\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0070 loss_train: 0.6242 loss_val: 0.5431 r2_train: -0.5895 r2_val: -0.4602\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0071 loss_train: 0.5186 loss_val: 0.5965 r2_train: -0.3805 r2_val: -0.4464\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0072 loss_train: 0.5636 loss_val: 0.5961 r2_train: -0.4113 r2_val: -0.3669\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0073 loss_train: 0.5650 loss_val: 0.5631 r2_train: -0.2974 r2_val: -0.4144\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0074 loss_train: 0.5183 loss_val: 0.5521 r2_train: -0.2778 r2_val: -0.5543\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0075 loss_train: 0.5284 loss_val: 0.5638 r2_train: -0.4549 r2_val: -0.5596\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0076 loss_train: 0.5563 loss_val: 0.5492 r2_train: -0.5589 r2_val: -0.3954\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0077 loss_train: 0.5408 loss_val: 0.5381 r2_train: -0.3463 r2_val: -0.2743\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0078 loss_train: 0.5241 loss_val: 0.5470 r2_train: -0.3165 r2_val: -0.2586\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0079 loss_train: 0.5272 loss_val: 0.5334 r2_train: -0.2602 r2_val: -0.2883\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0080 loss_train: 0.5071 loss_val: 0.5408 r2_train: -0.1981 r2_val: -0.3686\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0081 loss_train: 0.5046 loss_val: 0.5316 r2_train: -0.2689 r2_val: -0.2690\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0082 loss_train: 0.5031 loss_val: 0.5333 r2_train: -0.1904 r2_val: -0.1064\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0083 loss_train: 0.5008 loss_val: 0.5267 r2_train: -0.1361 r2_val: -0.0854\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0084 loss_train: 0.5355 loss_val: 0.5319 r2_train: -0.0627 r2_val: -0.3007\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0085 loss_train: 0.5042 loss_val: 0.5579 r2_train: -0.2614 r2_val: -0.4069\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0086 loss_train: 0.5204 loss_val: 0.5367 r2_train: -0.3971 r2_val: 0.0348\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0087 loss_train: 0.5033 loss_val: 0.5311 r2_train: 0.0524 r2_val: 0.0566\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0088 loss_train: 0.5157 loss_val: 0.5290 r2_train: 0.1253 r2_val: -0.3529\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0089 loss_train: 0.5025 loss_val: 0.5342 r2_train: -0.2377 r2_val: -0.6438\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0090 loss_train: 0.5301 loss_val: 0.5177 r2_train: -0.7419 r2_val: -0.2578\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0091 loss_train: 0.4927 loss_val: 0.5393 r2_train: -0.2256 r2_val: 0.0096\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0092 loss_train: 0.5130 loss_val: 0.5491 r2_train: 0.0623 r2_val: -0.0650\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0093 loss_train: 0.4936 loss_val: 0.5177 r2_train: -0.0224 r2_val: -0.2333\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0094 loss_train: 0.4908 loss_val: 0.5126 r2_train: -0.2618 r2_val: -0.2889\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0095 loss_train: 0.4908 loss_val: 0.5086 r2_train: -0.2908 r2_val: -0.1172\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0096 loss_train: 0.4859 loss_val: 0.5091 r2_train: -0.0282 r2_val: -0.0032\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0097 loss_train: 0.4837 loss_val: 0.5164 r2_train: 0.0152 r2_val: -0.1617\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0098 loss_train: 0.4851 loss_val: 0.5178 r2_train: -0.1026 r2_val: -0.1290\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0099 loss_train: 0.4779 loss_val: 0.5036 r2_train: -0.0609 r2_val: -0.0365\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0100 loss_train: 0.4774 loss_val: 0.5047 r2_train: 0.0046 r2_val: 0.0183\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0101 loss_train: 0.4831 loss_val: 0.5017 r2_train: 0.0484 r2_val: 0.0341\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0102 loss_train: 0.4734 loss_val: 0.5074 r2_train: 0.0748 r2_val: -0.1035\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0103 loss_train: 0.4832 loss_val: 0.5063 r2_train: -0.0398 r2_val: -0.1844\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0104 loss_train: 0.4774 loss_val: 0.4996 r2_train: -0.1388 r2_val: 0.0283\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0105 loss_train: 0.4708 loss_val: 0.5036 r2_train: 0.0662 r2_val: 0.0818\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0106 loss_train: 0.4748 loss_val: 0.4969 r2_train: 0.1338 r2_val: -0.1656\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0107 loss_train: 0.4725 loss_val: 0.4984 r2_train: -0.1310 r2_val: -0.1858\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0108 loss_train: 0.4690 loss_val: 0.4923 r2_train: -0.1326 r2_val: 0.0326\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0109 loss_train: 0.4818 loss_val: 0.4987 r2_train: 0.0079 r2_val: 0.0700\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0110 loss_train: 0.4766 loss_val: 0.4927 r2_train: 0.0784 r2_val: 0.0023\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0111 loss_train: 0.4637 loss_val: 0.5085 r2_train: 0.0198 r2_val: -0.1222\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0112 loss_train: 0.4755 loss_val: 0.4879 r2_train: -0.0832 r2_val: -0.0469\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0113 loss_train: 0.4572 loss_val: 0.4944 r2_train: 0.0088 r2_val: 0.0010\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0114 loss_train: 0.4646 loss_val: 0.4846 r2_train: 0.0549 r2_val: 0.0710\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0115 loss_train: 0.4534 loss_val: 0.4927 r2_train: 0.1000 r2_val: 0.0004\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0116 loss_train: 0.4559 loss_val: 0.4849 r2_train: 0.0900 r2_val: -0.0910\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0117 loss_train: 0.4586 loss_val: 0.4968 r2_train: -0.0670 r2_val: 0.0258\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0118 loss_train: 0.4638 loss_val: 0.4862 r2_train: 0.1053 r2_val: 0.0426\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0119 loss_train: 0.4581 loss_val: 0.5083 r2_train: 0.0956 r2_val: -0.0102\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0120 loss_train: 0.4953 loss_val: 0.5043 r2_train: -0.0007 r2_val: -0.1334\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0121 loss_train: 0.4650 loss_val: 0.5249 r2_train: -0.0691 r2_val: -0.0513\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0122 loss_train: 0.4900 loss_val: 0.4985 r2_train: -0.0077 r2_val: 0.0981\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0123 loss_train: 0.4651 loss_val: 0.5159 r2_train: 0.1373 r2_val: -0.1651\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0124 loss_train: 0.4833 loss_val: 0.5022 r2_train: -0.1072 r2_val: -0.2628\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0125 loss_train: 0.4665 loss_val: 0.5045 r2_train: -0.1805 r2_val: -0.0524\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0126 loss_train: 0.4674 loss_val: 0.4970 r2_train: 0.0163 r2_val: 0.0951\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0127 loss_train: 0.4625 loss_val: 0.4942 r2_train: 0.1356 r2_val: 0.0335\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0128 loss_train: 0.4646 loss_val: 0.5050 r2_train: 0.0854 r2_val: -0.3004\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0129 loss_train: 0.4695 loss_val: 0.4959 r2_train: -0.2243 r2_val: -0.2598\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0130 loss_train: 0.4621 loss_val: 0.4923 r2_train: -0.1714 r2_val: 0.0314\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0131 loss_train: 0.4578 loss_val: 0.4865 r2_train: 0.0920 r2_val: 0.1676\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0132 loss_train: 0.4510 loss_val: 0.4869 r2_train: 0.2259 r2_val: 0.0845\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0133 loss_train: 0.4505 loss_val: 0.4931 r2_train: 0.1508 r2_val: -0.1565\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0134 loss_train: 0.4527 loss_val: 0.4793 r2_train: -0.0777 r2_val: -0.0557\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0135 loss_train: 0.4460 loss_val: 0.4960 r2_train: 0.0145 r2_val: 0.2270\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0136 loss_train: 0.4572 loss_val: 0.4960 r2_train: 0.2546 r2_val: 0.1093\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0137 loss_train: 0.4688 loss_val: 0.5280 r2_train: 0.1287 r2_val: 0.0765\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0138 loss_train: 0.5120 loss_val: 0.4995 r2_train: 0.1363 r2_val: -0.2646\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0139 loss_train: 0.4759 loss_val: 0.5539 r2_train: -0.2087 r2_val: -0.2473\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0140 loss_train: 0.5032 loss_val: 0.5084 r2_train: -0.1689 r2_val: 0.0636\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0141 loss_train: 0.4866 loss_val: 0.5186 r2_train: 0.0862 r2_val: -0.0156\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0142 loss_train: 0.4793 loss_val: 0.5181 r2_train: 0.0428 r2_val: -0.2574\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0143 loss_train: 0.4736 loss_val: 0.5160 r2_train: -0.1815 r2_val: -0.2223\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0144 loss_train: 0.4849 loss_val: 0.5052 r2_train: -0.1645 r2_val: -0.0740\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0145 loss_train: 0.4700 loss_val: 0.5169 r2_train: -0.0207 r2_val: -0.0469\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0146 loss_train: 0.4782 loss_val: 0.4989 r2_train: 0.0132 r2_val: -0.0441\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0147 loss_train: 0.4612 loss_val: 0.4945 r2_train: 0.0174 r2_val: -0.1024\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0148 loss_train: 0.4559 loss_val: 0.5039 r2_train: -0.0220 r2_val: -0.0893\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0149 loss_train: 0.4671 loss_val: 0.4848 r2_train: -0.0245 r2_val: 0.0340\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0150 loss_train: 0.4473 loss_val: 0.4874 r2_train: 0.0910 r2_val: 0.1062\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0151 loss_train: 0.4548 loss_val: 0.4846 r2_train: 0.1476 r2_val: 0.0168\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0152 loss_train: 0.4501 loss_val: 0.4895 r2_train: 0.0562 r2_val: -0.0970\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0153 loss_train: 0.4500 loss_val: 0.4733 r2_train: -0.0375 r2_val: 0.0936\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0154 loss_train: 0.4344 loss_val: 0.5007 r2_train: 0.1476 r2_val: 0.2182\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0155 loss_train: 0.4557 loss_val: 0.4776 r2_train: 0.2799 r2_val: 0.1321\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0156 loss_train: 0.4359 loss_val: 0.4797 r2_train: 0.1924 r2_val: -0.0469\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0157 loss_train: 0.4403 loss_val: 0.4756 r2_train: 0.0222 r2_val: 0.0324\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0158 loss_train: 0.4396 loss_val: 0.4793 r2_train: 0.1058 r2_val: 0.0942\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0159 loss_train: 0.4379 loss_val: 0.4871 r2_train: 0.1904 r2_val: 0.0491\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0160 loss_train: 0.4369 loss_val: 0.4807 r2_train: 0.1398 r2_val: 0.0902\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0161 loss_train: 0.4389 loss_val: 0.4780 r2_train: 0.1549 r2_val: 0.1443\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0162 loss_train: 0.4449 loss_val: 0.4667 r2_train: 0.2238 r2_val: 0.0816\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0163 loss_train: 0.4290 loss_val: 0.4797 r2_train: 0.1457 r2_val: -0.0446\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0164 loss_train: 0.4381 loss_val: 0.4706 r2_train: 0.0006 r2_val: 0.0283\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0165 loss_train: 0.4338 loss_val: 0.4686 r2_train: 0.0502 r2_val: 0.1676\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0166 loss_train: 0.4275 loss_val: 0.4781 r2_train: 0.2281 r2_val: 0.1792\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0167 loss_train: 0.4396 loss_val: 0.4652 r2_train: 0.2398 r2_val: 0.0889\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0168 loss_train: 0.4228 loss_val: 0.4933 r2_train: 0.1706 r2_val: -0.1025\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0169 loss_train: 0.4498 loss_val: 0.4629 r2_train: -0.0180 r2_val: 0.0410\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0170 loss_train: 0.4202 loss_val: 0.4827 r2_train: 0.1252 r2_val: 0.1192\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0171 loss_train: 0.4601 loss_val: 0.4636 r2_train: 0.1596 r2_val: 0.1226\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0172 loss_train: 0.4209 loss_val: 0.4763 r2_train: 0.1934 r2_val: 0.0051\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0173 loss_train: 0.4375 loss_val: 0.4752 r2_train: 0.0790 r2_val: 0.0193\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0174 loss_train: 0.4286 loss_val: 0.4648 r2_train: 0.1007 r2_val: 0.1210\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0175 loss_train: 0.4252 loss_val: 0.4710 r2_train: 0.1921 r2_val: 0.1534\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0176 loss_train: 0.4256 loss_val: 0.4632 r2_train: 0.2217 r2_val: 0.0797\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0177 loss_train: 0.4219 loss_val: 0.4725 r2_train: 0.1610 r2_val: 0.0185\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0178 loss_train: 0.4250 loss_val: 0.4776 r2_train: 0.0936 r2_val: 0.1190\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0179 loss_train: 0.4226 loss_val: 0.4589 r2_train: 0.2197 r2_val: 0.1997\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0180 loss_train: 0.4129 loss_val: 0.4677 r2_train: 0.2598 r2_val: 0.1772\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0181 loss_train: 0.4271 loss_val: 0.4558 r2_train: 0.2439 r2_val: 0.1399\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0182 loss_train: 0.4099 loss_val: 0.4689 r2_train: 0.2165 r2_val: 0.0588\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0183 loss_train: 0.4216 loss_val: 0.4571 r2_train: 0.1288 r2_val: 0.1350\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0184 loss_train: 0.4087 loss_val: 0.4648 r2_train: 0.2135 r2_val: 0.2333\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0185 loss_train: 0.4217 loss_val: 0.4584 r2_train: 0.2938 r2_val: 0.1846\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0186 loss_train: 0.4104 loss_val: 0.4598 r2_train: 0.2563 r2_val: 0.1157\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0187 loss_train: 0.4073 loss_val: 0.4651 r2_train: 0.2093 r2_val: 0.1208\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0188 loss_train: 0.4131 loss_val: 0.4644 r2_train: 0.2126 r2_val: 0.0899\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0189 loss_train: 0.4117 loss_val: 0.4635 r2_train: 0.1861 r2_val: 0.2250\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0190 loss_train: 0.4092 loss_val: 0.4571 r2_train: 0.2907 r2_val: 0.2030\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0191 loss_train: 0.4027 loss_val: 0.4634 r2_train: 0.2716 r2_val: 0.1013\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0192 loss_train: 0.4048 loss_val: 0.4510 r2_train: 0.2063 r2_val: 0.1274\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0193 loss_train: 0.3991 loss_val: 0.4588 r2_train: 0.2108 r2_val: 0.1902\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0194 loss_train: 0.4033 loss_val: 0.4539 r2_train: 0.2727 r2_val: 0.2287\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0195 loss_train: 0.4000 loss_val: 0.4564 r2_train: 0.2910 r2_val: 0.1853\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0196 loss_train: 0.4007 loss_val: 0.4655 r2_train: 0.2722 r2_val: 0.1215\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0197 loss_train: 0.4088 loss_val: 0.4839 r2_train: 0.2182 r2_val: 0.2573\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0198 loss_train: 0.4355 loss_val: 0.4998 r2_train: 0.3261 r2_val: -0.0360\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0199 loss_train: 0.4409 loss_val: 0.4791 r2_train: 0.0688 r2_val: 0.1657\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "loss------------------------------------------------------111\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "Epoch: 0200 loss_train: 0.4171 loss_val: 0.4674 r2_train: 0.2512 r2_val: 0.1650\n",
      "Optimization Finished!\n",
      "Total time elapsed: 1471.8028s\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01,momentum = 0.9,weight_decay=0.00005)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.004,weight_decay=0.0005)\n",
    "#print(\"oooooooooooooooooooo\")\n",
    "print(graph.device)\n",
    "#print(graph.is_cuda)\n",
    "t_total = time.time()\n",
    "for epoch in range(200):\n",
    "    train(epoch)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "print('----------')\n",
    "# Testing\n",
    "#test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bb7b552-0d9c-483c-aa90-c7913a96c514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "(23140, 1)\n",
      "Mean Squared Error: 0.5204055268636971 3.4052584\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(graph, node_features, edge_features)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "s_y = dataset.ss_y\n",
    "y_pre = s_y.inverse_transform(output.detach().numpy())\n",
    "y_ture = s_y.inverse_transform(labels.detach().numpy())\n",
    "print(y_pre.shape)\n",
    "\n",
    "r2 = r2_score(y_ture[idx_test], y_pre[idx_test])\n",
    "mse = mean_squared_error(y_ture[idx_test], y_pre[idx_test])\n",
    "mae = mean_absolute_error(y_ture[idx_test], y_pre[idx_test])\n",
    "print(\"Mean Squared Error:\", r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fa465-0c54-41f0-9396-80e20957396d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "909e2bc4-8515-469b-9218-4a8a59bdfefc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([23140, 17])\n"
     ]
    }
   ],
   "source": [
    "#IG explanation\n",
    "baseline = torch.zeros_like(node_features)\n",
    "baseline[:,-1] = 0\n",
    "baseline[:,-2] = 0\n",
    "print(baseline[:5])\n",
    "print(baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efc29f0c-562e-4ab8-9342-cdebe7c49528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n",
      "torch.Size([139802, 128])\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from functools import partial\n",
    "ig = IntegratedGradients(partial(model, graph, e_in = edge_features))\n",
    "mask = ig.attribute(node_features.float(),baselines = baseline,internal_batch_size=128, n_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d47392-0802-43ef-8e96-80ed029e7d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
